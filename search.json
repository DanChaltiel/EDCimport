[{"path":"https://danchaltiel.github.io/EDCimport/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Dan Chaltiel. Author, maintainer.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Chaltiel D (2025). EDCimport: Import Data EDC Software. R package version 0.5.2.9013, https://danchaltiel.github.io/EDCimport/, https://github.com/DanChaltiel/EDCimport.","code":"@Manual{,   title = {EDCimport: Import Data from EDC Software},   author = {Dan Chaltiel},   year = {2025},   note = {R package version 0.5.2.9013, https://danchaltiel.github.io/EDCimport/},   url = {https://github.com/DanChaltiel/EDCimport}, }"},{"path":"https://danchaltiel.github.io/EDCimport/index.html","id":"edcimport","dir":"","previous_headings":"","what":"Import Data from EDC Software","title":"Import Data from EDC Software","text":"EDCimport package designed easily import data EDC software TrialMaster.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Import Data from EDC Software","text":"also need 7-zip installed, preferably added PATH. [!WARNING] package developed work Windows unlikely work OS. welcome submit PR manage get work Mac Linux.","code":"# Install last version available on CRAN (once published) install.packages(\"EDCimport\")  # Install development version on Github devtools::install_github(\"DanChaltiel/EDCimport\")"},{"path":"https://danchaltiel.github.io/EDCimport/index.html","id":"load-the-data","dir":"","previous_headings":"Installation","what":"Load the data","title":"Import Data from EDC Software","text":"Inside TrialMaster, request export type SAS Xport, checkbox “Include Codelists” ticked. export generate .zip archive. , simply use read_trialmaster() archive password () retrieve data archive: resulting object tm list containing datasets, plus metadatas. can now use load_list() import list global environment use tables: many options available (e.g. colnames cleaning & table splitting), see ?read_trialmaster details.","code":"library(EDCimport) tm = read_trialmaster(\"path/to/my/archive.zip\", pw=\"foobar\") load_list(tm) #this also removes `tm` to save memory mean(dataset1$column5)"},{"path":"https://danchaltiel.github.io/EDCimport/index.html","id":"database-management-tools","dir":"","previous_headings":"Installation","what":"Database management tools","title":"Import Data from EDC Software","text":"EDCimport include set useful tools help using imported database. See References complete list.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/index.html","id":"database-summary","dir":"","previous_headings":"Installation > Database management tools","what":"Database summary","title":"Import Data from EDC Software","text":"Reading database using read_trialmaster() generates .lookup dataframe, contains dataset number rows, columns, patients, CRF name. .lookup used many tools inside EDCimport, careful modify delete .","code":""},{"path":"https://danchaltiel.github.io/EDCimport/index.html","id":"search-the-whole-database","dir":"","previous_headings":"Installation > Database management tools","what":"Search the whole database","title":"Import Data from EDC Software","text":"Using find_keyword(), can run global search database. instance, say remember dataset column located “date ECG”. find_keyword() search every column name label give answer:","code":"find_keyword(\"date\") #> # A tibble: 10 x 3 #>    dataset names   labels                       #>    <chr>   <chr>   <chr>                        #>  1 pat     PTRNDT  Randomization Date           #>  2 pat     RGSTDT  Registration Date            #>  3 site    INVDAT  Deactivation date            #>  4 site    TRGTDT  Target Enroll Date           #>  5 trial   TRSPDT  End Date                     #>  6 trial   TRSTDT  Start Date                   #>  7 visit   VISIT2  Visit Date                   #>  8 visit   EEXPVDT Earliest Expected Visit Date #>  9 vs      ECGDAT  Date of ECG                  #> 10 vs      VISITDT Visit Date"},{"path":"https://danchaltiel.github.io/EDCimport/index.html","id":"swimmer-plot","dir":"","previous_headings":"Installation","what":"Swimmer Plot","title":"Import Data from EDC Software","text":"edc_swimmerplot() function create swimmer plot date variables whole database. 2 arguments interest: group, grouping variable (e.g. treatment arm) origin, date variable acting time zero (e.g. date enrollment) outputs plotly interactive graph can select dates interest zoom mouse.  Note modification made running read_trialmaster() taken account. instance, mutating column .Date() one tables add new group plot.","code":"edc_swimmerplot() edc_swimmerplot(group=\"enrolres$arm\") edc_swimmerplot(origin=\"enrolres$enroldt\")"},{"path":"https://danchaltiel.github.io/EDCimport/reference/EDCimport-package.html","id":null,"dir":"Reference","previous_headings":"","what":"EDCimport: Import Data from EDC Software — EDCimport-package","title":"EDCimport: Import Data from EDC Software — EDCimport-package","text":"convenient toolbox import data exported Electronic Data Capture (EDC) software 'TrialMaster'.","code":""},{"path":[]},{"path":"https://danchaltiel.github.io/EDCimport/reference/EDCimport-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"EDCimport: Import Data from EDC Software — EDCimport-package","text":"Maintainer: Dan Chaltiel dan.chaltiel@gmail.com (ORCID)","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/assert_no_duplicate.html","id":null,"dir":"Reference","previous_headings":"","what":"Assert that a dataframe has one row per patient — assert_no_duplicate","title":"Assert that a dataframe has one row per patient — assert_no_duplicate","text":"Check duplicate column holding patient ID pipeable style.  Mostly useful joining two datasets.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/assert_no_duplicate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Assert that a dataframe has one row per patient — assert_no_duplicate","text":"","code":"assert_no_duplicate(df, by = NULL, id_col = get_subjid_cols())"},{"path":"https://danchaltiel.github.io/EDCimport/reference/assert_no_duplicate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Assert that a dataframe has one row per patient — assert_no_duplicate","text":"df dataframe (optional) grouping columns id_col name columns holding patient ID","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/assert_no_duplicate.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Assert that a dataframe has one row per patient — assert_no_duplicate","text":"df dataset, unchanged","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/assert_no_duplicate.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Assert that a dataframe has one row per patient — assert_no_duplicate","text":"","code":"if (FALSE) { # \\dontrun{ #without duplicate => no error, continue the pipeline tibble(subjid=c(1:10)) %>% assert_no_duplicate() %>% nrow()  #with duplicate => throws an error tibble(subjid=c(1:10, 1:2)) %>% assert_no_duplicate() %>% nrow()  #By groups df = tibble(subjid=rep(1:10, 4), visit=rep(c(\"V1\", \"V2\"), 2, each=10),              group=rep(c(\"A\", \"B\"), each=20)) df %>% assert_no_duplicate() #error df %>% assert_no_duplicate(by=c(visit, group)) #no error } # }"},{"path":"https://danchaltiel.github.io/EDCimport/reference/build_lookup.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate a lookup table — build_lookup","title":"Generate a lookup table — build_lookup","text":"Generate lookup table","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/build_lookup.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate a lookup table — build_lookup","text":"","code":"build_lookup(data_list)"},{"path":"https://danchaltiel.github.io/EDCimport/reference/build_lookup.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate a lookup table — build_lookup","text":"data_list list containing least 1 dataframe","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/build_lookup.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate a lookup table — build_lookup","text":"dataframe summarizing column names labels","code":""},{"path":[]},{"path":"https://danchaltiel.github.io/EDCimport/reference/build_lookup.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate a lookup table — build_lookup","text":"","code":"x = edc_example() x$.lookup=NULL lk = build_lookup(x) lk #> ── Lookup table (extraction of 2024-01-01)  ──────────────────────────────────── #>   dataset     nrow  ncol #>   <chr>      <dbl> <dbl> #> 1 enrol         50     5 #> 2 db2           50     5 #> 3 db3           50     6 #> 4 short         50     4 #> 5 db1          100     6 #> 6 long_mixed   100     5 #> 7 long_pure    150     4 #> 8 ae           175     6 lk %>% tidyr::unnest(c(names, labels))   #> # A tibble: 41 × 5 #>    dataset  nrow  ncol names          labels       #>    <chr>   <dbl> <dbl> <chr>          <named list> #>  1 enrol      50     5 subjid         <chr [1]>    #>  2 enrol      50     5 age            <chr [1]>    #>  3 enrol      50     5 date_naissance <chr [1]>    #>  4 enrol      50     5 arm            <chr [1]>    #>  5 enrol      50     5 crfname        <chr [1]>    #>  6 db2        50     5 subjid         <chr [1]>    #>  7 db2        50     5 date4          <chr [1]>    #>  8 db2        50     5 date5          <chr [1]>    #>  9 db2        50     5 date6          <chr [1]>    #> 10 db2        50     5 crfname        <chr [1]>    #> # ℹ 31 more rows"},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_crf_plot.html","id":null,"dir":"Reference","previous_headings":"","what":"Show the current CRF status distribution — edc_crf_plot","title":"Show the current CRF status distribution — edc_crf_plot","text":"Generate barplot showing distribution CRF status (Complete, Incomplete, ...) dataset database.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_crf_plot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Show the current CRF status distribution — edc_crf_plot","text":"","code":"edc_crf_plot(   crfstat_col = \"CRFSTAT\",   ...,   details = FALSE,   pal = edc_pal_crf(),   crfstat_lvls = names(pal),   x_label = \"{dataset}\",   treat_as_worst = NULL )  edc_pal_crf()"},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_crf_plot.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Show the current CRF status distribution — edc_crf_plot","text":"ggsci:::ggsci_db$lancet[[\"lanonc\"]] %>% dput()","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_crf_plot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Show the current CRF status distribution — edc_crf_plot","text":"crfstat_col column name CRF status ... unused details whether show CRF status levels. FALSE (default), recode status \"Complete\", \"Incomplete\", \"Data\". pal palette, defaulting helper EDCimport:::edc_pal_crf() crfstat_lvls CRF status levels, \"best\" \"worst\". plot ordered \"worst\" level. x_label glue pattern determining tick label x axis. Available variables c(\"nrow\", \"ncol\", \"n_id\", \"rows_per_id\", \"crfname\"), taken edc_lookup(). treat_as_worst regex levels treated worst ordering","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_crf_plot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Show the current CRF status distribution — edc_crf_plot","text":"ggplot","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_crf_plot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Show the current CRF status distribution — edc_crf_plot","text":"","code":"if (FALSE) { # \\dontrun{ #import a TM database and use load_list(), then: edc_crf_plot() + ggtitle(date_extraction) edc_crf_plot(pal=rev(edc_pal_crf())) edc_crf_plot(details=TRUE, treat_as_worst=\"No Data\") edc_crf_plot(x_label=\"{crfname} (N={n_id}, n={nrow})\")  p = edc_crf_plot(details=TRUE) p$data$crfstat %>% unique() #> [1] \"Incomplete\"        \"No Data Locked\"    \"No Data\"           \"Signed\"            #> [5] \"Partial Monitored\" \"Monitored\"         \"Complete Locked\"   \"Complete\"  } # }"},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_data_warn.html","id":null,"dir":"Reference","previous_headings":"","what":"Standardized warning system — edc_data_warn","title":"Standardized warning system — edc_data_warn","text":"checking data, filter dataset get problematic rows.  , use either: edc_data_warn() generate standardized warning can forwarded datamanager edc_data_stop() abort script problem serious Database issues traced separate file, identifying row number, file shared data-manager.  Use edc_data_warnings() generate table file.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_data_warn.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Standardized warning system — edc_data_warn","text":"","code":"edc_data_warn(   df,   message,   ...,   issue_n = \"xx\",   max_subjid = 5,   csv_path = FALSE,   col_subjid = get_subjid_cols() )  edc_data_stop(df, message, ..., issue_n, max_subjid, csv_path, col_subjid)  edc_data_warnings()"},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_data_warn.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Standardized warning system — edc_data_warn","text":"df filtered dataframe message message. Can use cli formats. df can accessed using .data special keyword (see example) ... unused issue_n identifying row number max_subjid max number subject ID show message csv_path path save df csv file can shared DM details. col_subjid column name subject ID. Set NULL ignore.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_data_warn.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Standardized warning system — edc_data_warn","text":"df invisibly","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_data_warn.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Standardized warning system — edc_data_warn","text":"","code":"library(dplyr) #>  #> Attaching package: ‘dplyr’ #> The following objects are masked from ‘package:stats’: #>  #>     filter, lag #> The following objects are masked from ‘package:base’: #>  #>     intersect, setdiff, setequal, union tm = edc_example() #> Warning: Option \"edc_lookup\" has been overwritten. load_list(tm) enrol %>%    filter(age>70) %>%    edc_data_warn(\"Age should not be >70\", issue_n=1) #> Warning: Datasets from this lookup are not available in the global environment. #> ℹ Did you forget to use `EDCimport::load_list(tm)` to load the tables? #> This warning is displayed once per session. #> Warning: Issue #01: Age should not be >70 (2 patients: #9 and #12)  enrol %>%    filter(age<25) %>%    edc_data_warn(\"Age should not be <25\", issue_n=2) #> Warning: Issue #02: Age should not be <25 (1 patient: #18)  db1 %>%    filter(n()>1, .by=subjid) %>%    edc_data_warn(\"There are duplicated patients in `db1` ({nrow(.data)} rows)\", issue_n=3) #> Warning: Issue #03: There are duplicated patients in `db1` (100 rows) (50 patients: #1, #> #2, #3, #4, #5, …)  enrol %>%    filter(age<25) %>%    edc_data_warn(\"Age should not be <25\", issue_n=NULL) #> Warning: Age should not be <25 (1 patient: #18)    edc_data_warnings() #> # A tibble: 4 × 4 #>   issue_n message                                           subjid     fun      #>   <chr>   <chr>                                             <list>     <chr>    #> 1 01      Age should not be >70                             <chr [2]>  cli_warn #> 2 02      Age should not be <25                             <chr [1]>  cli_warn #> 3 03      There are duplicated patients in `db1` (100 rows) <chr [50]> cli_warn #> 4 NA      Age should not be <25                             <chr [1]>  cli_warn  if (FALSE) { # \\dontrun{ enrol %>%    filter(age<25) %>%    edc_data_warn(\"Age should not be <25\", csv_path=\"check/check_age_25.csv\")    enrol %>%    filter(age<25) %>%    edc_data_stop(\"Age should *never* be <25\") } # }"},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_db_to_excel.html","id":null,"dir":"Reference","previous_headings":"","what":"Save the database as an Excel file — edc_db_to_excel","title":"Save the database as an Excel file — edc_db_to_excel","text":"RStudio good showing data, can convenient browse database using MS Excel. function turns whole TM export (named list datasets) Excel workbook, one tab dataset. Use edc_db_to_excel() create file edc_browse_excel() open .","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_db_to_excel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Save the database as an Excel file — edc_db_to_excel","text":"","code":"edc_db_to_excel(   filename = tempfile(fileext = \".xlsx\"),   ...,   datasets = get_datasets(),   overwrite = FALSE,   open = FALSE )  edc_browse_excel()"},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_db_to_excel.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Save the database as an Excel file — edc_db_to_excel","text":"filename path Excel output file. Default temporary file. Use special value TRUE save \"data/database_{date_extraction}.xlsx\". ... unused datasets named list dataframes. Default TM export. overwrite whether overwrite existing file. Default FALSE. open whether open Excel file afterward. Default FALSE.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_db_to_excel.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Save the database as an Excel file — edc_db_to_excel","text":"nothing","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_db_to_excel.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Save the database as an Excel file — edc_db_to_excel","text":"","code":"if (FALSE) { # \\dontrun{   tm = edc_example()   load_list(tm)     edc_db_to_excel() #default arguments are usually OK   edc_db_to_excel(filename=TRUE) } # }"},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_example.html","id":null,"dir":"Reference","previous_headings":"","what":"Example database — edc_example","title":"Example database — edc_example","text":"list tables simulates extraction clinical database. Used EDCimport examples tests.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_example.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Example database — edc_example","text":"","code":"edc_example(N = 50, seed = 42, outdated = FALSE)"},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_example.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Example database — edc_example","text":"N number patients seed random seed outdated whether simulate times data extraction date","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_example.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Example database — edc_example","text":"list tables class edc_database.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_inform_code.html","id":null,"dir":"Reference","previous_headings":"","what":"Shows how many code you wrote — edc_inform_code","title":"Shows how many code you wrote — edc_inform_code","text":"Shows many code wrote","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_inform_code.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Shows how many code you wrote — edc_inform_code","text":"","code":"edc_inform_code(main = \"main.R\", Rdir = \"R/\")"},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_inform_code.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Shows how many code you wrote — edc_inform_code","text":"main main R file, sources ones Rdir R directory, sourced R files located","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_inform_code.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Shows how many code you wrote — edc_inform_code","text":"Nothing","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_left_join.html","id":null,"dir":"Reference","previous_headings":"","what":"Join within the EDCimport framework — edc_left_join","title":"Join within the EDCimport framework — edc_left_join","text":"Perform join default Subject ID default suffix name y dataset. See [dplyr::mutate-joins] description join logic.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_left_join.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Join within the EDCimport framework — edc_left_join","text":"","code":"edc_left_join(   x,   y,   by = NULL,   suffix = NULL,   cols = everything(),   remove_dups = TRUE )"},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_left_join.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Join within the EDCimport framework — edc_left_join","text":"x, y Data frames join key join . Defaults get_subjid_cols() suffix disambiguation suffix. Defaults actual name y dataset. cols columns select y joining. remove_dups Whether remove columns y already exist x.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_left_join.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Join within the EDCimport framework — edc_left_join","text":"dataframe","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_left_join.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Join within the EDCimport framework — edc_left_join","text":"","code":"tm = edc_example() #> Warning: Option \"edc_lookup\" has been overwritten. attach(tm) db2$common = db1$common = \"Common\" x = enrol %>%    edc_left_join(db2) %>%    edc_right_join(db1)    #crfname get a suffix, common  names(x) #>  [1] \"subjid\"                            \"age\"                               #>  [3] \"date_naissance\"                    \"arm\"                               #>  [5] \"crfname\"                           \"date4\"                             #>  [7] \"date5\"                             \"date6\"                             #>  [9] \"crfname_<tibble[,6]>\"              \"common\"                            #> [11] \"date1\"                             \"date2\"                             #> [13] \"date3\"                             \"x\"                                 #> [15] \"crfname_<tibble[,6]>_<tibble[,6]>\""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_lookup.html","id":null,"dir":"Reference","previous_headings":"","what":"Retrieve the lookup table from options — edc_lookup","title":"Retrieve the lookup table from options — edc_lookup","text":"Retrieve lookup table options","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_lookup.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Retrieve the lookup table from options — edc_lookup","text":"","code":"edc_lookup(..., check = TRUE)"},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_lookup.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Retrieve the lookup table from options — edc_lookup","text":"... passed dplyr::arrange() check whether check internal consistency","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_lookup.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Retrieve the lookup table from options — edc_lookup","text":"lookup dataframe summarizing database import","code":""},{"path":[]},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_lookup.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Retrieve the lookup table from options — edc_lookup","text":"","code":"tm = edc_example() #> Warning: Option \"edc_lookup\" has been overwritten. load_list(tm) edc_lookup() #> ── Lookup table (extraction of 2024-01-01)  ──────────────────────────────────── #>   dataset     nrow  ncol #>   <chr>      <dbl> <dbl> #> 1 enrol         50     5 #> 2 db2           50     5 #> 3 db3           50     6 #> 4 short         50     4 #> 5 db1          100     6 #> 6 long_mixed   100     5 #> 7 long_pure    150     4 #> 8 ae           175     6 edc_lookup(dataset) #> ── Lookup table (extraction of 2024-01-01)  ──────────────────────────────────── #>   dataset     nrow  ncol #>   <chr>      <dbl> <dbl> #> 1 ae           175     6 #> 2 db1          100     6 #> 3 db2           50     5 #> 4 db3           50     6 #> 5 enrol         50     5 #> 6 long_mixed   100     5 #> 7 long_pure    150     4 #> 8 short         50     4"},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_options.html","id":null,"dir":"Reference","previous_headings":"","what":"Set global options for EDCimport — edc_options","title":"Set global options for EDCimport — edc_options","text":"Use function manage EDCimport parameters globally taking advantage autocompletion.  Use edc_peek_options() see option currently set edc_reset_options() set options back default.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_options.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set global options for EDCimport — edc_options","text":"","code":"edc_options(   ...,   trialmaster_pw,   path_7zip,   edc_lookup,   edc_subjid_ref,   edc_plotly,   edc_fct_yesno,   edc_cols_subjid,   edc_cols_meta,   edc_cols_id,   edc_cols_crfname,   edc_meta_cols_pct,   edc_warn_max_subjid,   edc_read_verbose,   edc_correction_verbose,   edc_get_key_cols_verbose,   edc_lookup_overwrite_warn,   .local = FALSE )"},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_options.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set global options for EDCimport — edc_options","text":"... unused trialmaster_pw password trialmaster zip archive. instance, can use edc_options(trialmaster_pw=\"my_pwd\") console per session, write password clear R code path_7zip path 7zip executable. Default \"C:/Program Files/7-Zip/\". edc_lookup (Internal) reference lookup table (usually .lookup). usually changed manually. edc_subjid_ref used edc_warn_patient_diffs vector reference subject IDs. usually write edc_options(edc_subjid_ref=enrolres$subjid). edc_plotly used edc_swimmerplot whether use plotly visualize plot. edc_fct_yesno used fct_yesno list values considered Yes/values. Defaults get_yesno_lvl(). edc_cols_subjid, edc_cols_meta used get_key_cols name columns holding subject id (default c(\"ptno\", \"subjid\")) CRF form name (default c(\"crfname\")). case-insensitive. edc_cols_id, edc_cols_crfname deprecated edc_meta_cols_pct minimal proportion datasets column reach considered \"meta\" edc_warn_max_subjid max number subject IDs show edc_data_warn edc_read_verbose, edc_correction_verbose, edc_get_key_cols_verbose verbosity output functions read_trialmaster read_all_xpt, manual_correction, get_key_cols. example, set edc_options(edc_read_verbose=0) silence first 2. edc_lookup_overwrite_warn default TRUE. Whether warning overwriting .lookup (like reading 2 databases successively) .local TRUE, effect apply local frame (internally using rlang::local_options())","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_options.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Set global options for EDCimport — edc_options","text":"Nothing, called side effects","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_patient_gridplot.html","id":null,"dir":"Reference","previous_headings":"","what":"Patient gridplot — edc_patient_gridplot","title":"Patient gridplot — edc_patient_gridplot","text":"Draw gridplot giving, patient dataset, whether patient present dataset. Data drawn get_datasets.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_patient_gridplot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Patient gridplot — edc_patient_gridplot","text":"","code":"edc_patient_gridplot(   sort_rows = TRUE,   sort_cols = TRUE,   gradient = FALSE,   axes_flip = FALSE,   show_grid = TRUE,   preprocess = NULL,   palette = c(Yes = \"#00468BFF\", No = \"#ED0000FF\") )"},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_patient_gridplot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Patient gridplot — edc_patient_gridplot","text":"sort_rows whether sort patients \"present datasets\" \"present least datasets\" sort_cols whether sort datasets \"containing patients\" \"containing least patients\" gradient whether add color gradient repeating measures axes_flip whether flip axes, patients Y axis datasets X axis show_grid whether show grid preprocess function preprocess patient ID, e.g. .numeric, custom function string replacement palette colors use","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_patient_gridplot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Patient gridplot — edc_patient_gridplot","text":"ggplot object","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_patient_gridplot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Patient gridplot — edc_patient_gridplot","text":"","code":"if (FALSE) { # \\dontrun{   tm = read_trialmaster(\"path/to/archive.zip\")   load_list(tm)   edc_patient_gridplot(sort_rows=FALSE, sort_cols=FALSE)   edc_patient_gridplot(axes_flip=TRUE, show_grid=TRUE,                        preprocess=~str_remove(.x, \"\\\\D*\")) #remove all non-digits } # }"},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_peek_options.html","id":null,"dir":"Reference","previous_headings":"","what":"See which EDCimport option is currently set. — edc_peek_options","title":"See which EDCimport option is currently set. — edc_peek_options","text":"See EDCimport option currently set.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_peek_options.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"See which EDCimport option is currently set. — edc_peek_options","text":"","code":"edc_peek_options(keep_null = FALSE)"},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_peek_options.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"See which EDCimport option is currently set. — edc_peek_options","text":"keep_null set TRUE get list","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_peek_options.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"See which EDCimport option is currently set. — edc_peek_options","text":"named list EDCimport options","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_population_plot.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot the populations — edc_population_plot","title":"Plot the populations — edc_population_plot","text":"RCT, usually several populations analysis, function allow show patient population graphically.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_population_plot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot the populations — edc_population_plot","text":"","code":"edc_population_plot(x, id_per_row = 50, ref = \"first\")"},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_population_plot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot the populations — edc_population_plot","text":"x named list subject ID. id_per_row number patients per rows. ref whole population. Default first member x.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_population_plot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot the populations — edc_population_plot","text":"ggplot","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_population_plot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot the populations — edc_population_plot","text":"","code":"#in real word code, use filter and pull to get these vectors pop_total = c(1:180) %>% setdiff(55) #screen failure, no patient 55 pop_itt = pop_total %>% setdiff(10) #patient 10 has had the wrong treatment pop_safety = pop_total %>% setdiff(c(40,160)) #patients 40 and 160 didn't receive any treatment pop_m_itt = pop_total %>% setdiff(c(40,160,80)) #patient 80 had a wrong inclusion criterion pop_evaluable = pop_total %>% setdiff(c(40,160,101,147,186)) #patients with no recist evaluation  l = list(   \"Total population\"=pop_total,   \"ITT population\"=pop_itt,   \"Safety population\"=pop_safety,   \"mITT population\"=pop_m_itt,   \"Evaluable population\"=pop_evaluable ) edc_population_plot(l)  edc_population_plot(l[-1], ref=pop_total)  edc_population_plot(l, ref=1:200)  edc_population_plot(l, id_per_row=60)"},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_reset_options.html","id":null,"dir":"Reference","previous_headings":"","what":"Reset all EDCimport options. — edc_reset_options","title":"Reset all EDCimport options. — edc_reset_options","text":"Reset EDCimport options.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_reset_options.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reset all EDCimport options. — edc_reset_options","text":"","code":"edc_reset_options(   except = c(\"edc_lookup\", \"trialmaster_pw\", \"path_7zip\"),   quiet = FALSE )"},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_reset_options.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reset all EDCimport options. — edc_reset_options","text":"except options reset default quiet set TRUE remove message.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_reset_options.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Reset all EDCimport options. — edc_reset_options","text":"Nothing, called side effects","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_swimmerplot.html","id":null,"dir":"Reference","previous_headings":"","what":"Swimmer plot of all dates columns — edc_swimmerplot","title":"Swimmer plot of all dates columns — edc_swimmerplot","text":"Join tables id date columns build ggplot (plotly plotly=TRUE) showing dates patients. allows outliers easily identified.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_swimmerplot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Swimmer plot of all dates columns — edc_swimmerplot","text":"","code":"edc_swimmerplot(   ...,   group = NULL,   origin = NULL,   id_lim = NULL,   exclude = NULL,   id = get_subjid_cols(),   time_unit = c(\"days\", \"weeks\", \"months\", \"years\"),   aes_color = c(\"variable\", \"label\"),   plotly = getOption(\"edc_plotly\", FALSE),   .lookup = \"deprecated\" )"},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_swimmerplot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Swimmer plot of all dates columns — edc_swimmerplot","text":"... used group grouping variable, given \"dataset$column\" origin variable consider time 0, given \"dataset$column\" id_lim numeric vector length 2 providing minimum maximum id subset . exclude character vector variables exclude, form dataset$column. Can regex, $ symbols count. Case-insensitive. id patient identifier. coerced numeric possible. time_unit origin!=NULL, unit measure time. One c(\"days\", \"weeks\", \"months\", \"years\"). aes_color either variable (\"{dataset} - {column}\") label (column label) plotly whether use {plotly} get interactive plot .lookup deprecated","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_swimmerplot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Swimmer plot of all dates columns — edc_swimmerplot","text":"either plotly ggplot","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_swimmerplot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Swimmer plot of all dates columns — edc_swimmerplot","text":"","code":"#tm = read_trialmaster(\"filename.zip\", pw=\"xx\") tm = edc_example() #> Warning: Option \"edc_lookup\" has been overwritten. load_list(tm) p = edc_swimmerplot(id_lim=c(5,45)) p2 = edc_swimmerplot(origin=\"enrol$date_naissance\", time_unit=\"weeks\",                       exclude=c(\"DB1$DATE2\", \"db3$.*\")) p3 = edc_swimmerplot(group=\"enrol$arm\", aes_color=\"label\") if (FALSE) { # \\dontrun{ #save the plotly plot as HTML to share it save_plotly(p, \"edc_swimmerplot.html\") } # }"},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_warn_extraction_date.html","id":null,"dir":"Reference","previous_headings":"","what":"Warn if extraction is too old — edc_warn_extraction_date","title":"Warn if extraction is too old — edc_warn_extraction_date","text":"Warn extraction old","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_warn_extraction_date.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Warn if extraction is too old — edc_warn_extraction_date","text":"","code":"edc_warn_extraction_date(max_days = 30)"},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_warn_extraction_date.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Warn if extraction is too old — edc_warn_extraction_date","text":"max_days max acceptable age data","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_warn_extraction_date.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Warn if extraction is too old — edc_warn_extraction_date","text":"nothing","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_warn_extraction_date.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Warn if extraction is too old — edc_warn_extraction_date","text":"","code":"tm = edc_example() #> Warning: Option \"edc_lookup\" has been overwritten. load_list(tm) edc_warn_extraction_date() #> Warning: - OUTDATED - Data extraction is 392 days old."},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_warn_patient_diffs.html","id":null,"dir":"Reference","previous_headings":"","what":"Check the validity of the subject ID column — edc_warn_patient_diffs","title":"Check the validity of the subject ID column — edc_warn_patient_diffs","text":"Compare subject ID vector study's reference subject ID (usually something like enrolres$subjid), warn patient missing extra. check_subjid() old, deprecated name.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_warn_patient_diffs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check the validity of the subject ID column — edc_warn_patient_diffs","text":"","code":"edc_warn_patient_diffs(   x,   ref = getOption(\"edc_subjid_ref\"),   issue_n = \"xx\",   data_name = NULL,   col_subjid = get_subjid_cols() )"},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_warn_patient_diffs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check the validity of the subject ID column — edc_warn_patient_diffs","text":"x subject ID vector check, dataframe ID column guessed ref reference subject ID. usually set edc_options(edc_subjid_ref=xxx). See example. issue_n identifying row number data_name name data (warning message) col_subjid name subject ID column x dataframe.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_warn_patient_diffs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check the validity of the subject ID column — edc_warn_patient_diffs","text":"nothing, called errors/warnings","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_warn_patient_diffs.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check the validity of the subject ID column — edc_warn_patient_diffs","text":"","code":"tm = edc_example() #> Warning: Option \"edc_lookup\" has been overwritten. load_list(tm) options(edc_subjid_ref=enrol$subjid) #usually, you set something like: #options(edc_subjid_ref=enrolres$subjid) edc_warn_patient_diffs(db1) db1 %>% dplyr::filter(subjid>1) %>% edc_warn_patient_diffs() #> Warning: In `edc_warn_patient_diffs()`, `data_name` should not be NULL if `issue_n` is #> not NULL and function is piped, otherwise the message will be unreadable. #> Warning: Issue #xx: `.` has patient discrepancies: #> ℹ Missing: 1 patient: #1 edc_warn_patient_diffs(c(db1$subjid, 99, 999)) #> Warning: Issue #xx: `c(db1$subjid, 99, 999)` has patient discrepancies: #> ℹ Extra: 2 patients: #99 and #999"},{"path":"https://danchaltiel.github.io/EDCimport/reference/extend_lookup.html","id":null,"dir":"Reference","previous_headings":"","what":"Extend the lookup table — extend_lookup","title":"Extend the lookup table — extend_lookup","text":"utility extends lookup table include: n_id number patients present dataset rows_per_id mean number row per patient crfname actual name dataset","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/extend_lookup.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extend the lookup table — extend_lookup","text":"","code":"extend_lookup(   lookup,   ...,   id_cols = get_subjid_cols(lookup),   crf_cols = get_crfname_cols(lookup),   datasets = get_datasets(lookup, envir = parent.frame()) )"},{"path":"https://danchaltiel.github.io/EDCimport/reference/extend_lookup.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extend the lookup table — extend_lookup","text":"lookup [data.frame(1)] lookup table ... unused id_cols, crf_cols [character(n)] experts datasets [data.frame(n)] experts ","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/extend_lookup.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extend the lookup table — extend_lookup","text":"lookup, extended","code":""},{"path":[]},{"path":"https://danchaltiel.github.io/EDCimport/reference/extend_lookup.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extend the lookup table — extend_lookup","text":"","code":"#tm = read_trialmaster(\"filename.zip\", pw=\"xx\") tm = edc_example() #> Warning: Option \"edc_lookup\" has been overwritten. load_list(tm) .lookup #> ── Lookup table (extraction of 2024-01-01)  ──────────────────────────────────── #>   dataset     nrow  ncol #>   <chr>      <dbl> <dbl> #> 1 enrol         50     5 #> 2 db2           50     5 #> 3 db3           50     6 #> 4 short         50     4 #> 5 db1          100     6 #> 6 long_mixed   100     5 #> 7 long_pure    150     4 #> 8 ae           175     6 .lookup = extend_lookup(.lookup) .lookup #> ── Lookup table (extraction of 2024-01-01)  ──────────────────────────────────── #>   dataset     nrow  ncol  n_id rows_per_id crfname                  #>   <chr>      <dbl> <dbl> <int>       <dbl> <chr>                    #> 1 ae           175     6    48         3.6 Adverse events           #> 2 long_pure    150     4    50         3   long data                #> 3 db1          100     6    50         2   db1                      #> 4 long_mixed   100     5    50         2   both short and long data #> 5 enrol         50     5    50         1   enrol                    #> 6 db2           50     5    50         1   db2                      #> 7 db3           50     6    50         1   db3                      #> 8 short         50     4    50         1   short data"},{"path":"https://danchaltiel.github.io/EDCimport/reference/fct_yesno.html","id":null,"dir":"Reference","previous_headings":"","what":"Format factor levels as Yes/No — fct_yesno","title":"Format factor levels as Yes/No — fct_yesno","text":"Format factor levels arbitrary values Yes/(Yes always first) leaving untouched vectors contain information.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/fct_yesno.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Format factor levels as Yes/No — fct_yesno","text":"","code":"fct_yesno(   x,   input = list(yes = c(\"Yes\", \"Oui\"), no = c(\"No\", \"Non\")),   output = c(\"Yes\", \"No\"),   strict = FALSE,   mutate_character = TRUE,   fail = TRUE )"},{"path":"https://danchaltiel.github.io/EDCimport/reference/fct_yesno.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Format factor levels as Yes/No — fct_yesno","text":"x vector type/class. input list values considered \"yes\" \"\". output output factor levels. strict whether match input strictly use stringr::str_detect find . mutate_character whether turn characters factor. fail whether fail levels recoded yes/.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/fct_yesno.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Format factor levels as Yes/No — fct_yesno","text":"factor, x untouched.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/fct_yesno.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Format factor levels as Yes/No — fct_yesno","text":"","code":"fct_yesno(c(\"No\", \"Yes\")) #levels are in order #> [1] No  Yes #> Levels: Yes No  set.seed(42) N=6 x = tibble(   a=sample(c(\"Yes\", \"No\"), size=N, replace=TRUE),   b=sample(c(\"Oui\", \"Non\"), size=N, replace=TRUE),   c=sample(0:1, size=N, replace=TRUE),   d=sample(c(TRUE, FALSE), size=N, replace=TRUE),   e=sample(c(\"1-Yes\", \"0-No\"), size=N, replace=TRUE),      y=sample(c(\"aaa\", \"bbb\", \"ccc\"), size=N, replace=TRUE),   z=1:N, )   x           #> # A tibble: 6 × 7 #>   a     b         c d     e     y         z #>   <chr> <chr> <int> <lgl> <chr> <chr> <int> #> 1 Yes   Non       0 FALSE 1-Yes bbb       1 #> 2 Yes   Non       1 FALSE 0-No  ccc       2 #> 3 Yes   Oui       0 TRUE  1-Yes bbb       3 #> 4 Yes   Non       0 TRUE  1-Yes aaa       4 #> 5 No    Oui       1 TRUE  1-Yes bbb       5 #> 6 No    Non       1 TRUE  1-Yes bbb       6 #y and z are left untouched (or throw an error if fail=TRUE)    sapply(x, fct_yesno, fail=FALSE) #>      a   b   c   d   e   y     z   #> [1,] \"1\" \"2\" \"2\" \"2\" \"1\" \"bbb\" \"1\" #> [2,] \"1\" \"2\" \"1\" \"2\" \"2\" \"ccc\" \"2\" #> [3,] \"1\" \"1\" \"2\" \"1\" \"1\" \"bbb\" \"3\" #> [4,] \"1\" \"2\" \"2\" \"1\" \"1\" \"aaa\" \"4\" #> [5,] \"2\" \"1\" \"1\" \"1\" \"1\" \"bbb\" \"5\" #> [6,] \"2\" \"2\" \"1\" \"1\" \"1\" \"bbb\" \"6\"  # as \"1-Yes\" is not in `input`, x$e is untouched/fails if strict=TRUE fct_yesno(x$e) #> [1] Yes No  Yes Yes Yes Yes #> Levels: Yes No fct_yesno(x$e, strict=TRUE, fail=FALSE)  #> [1] \"1-Yes\" \"0-No\"  \"1-Yes\" \"1-Yes\" \"1-Yes\" \"1-Yes\" fct_yesno(x$e, output=c(\"Ja\", \"Nein\")) #> [1] Ja   Nein Ja   Ja   Ja   Ja   #> Levels: Ja Nein"},{"path":"https://danchaltiel.github.io/EDCimport/reference/find_keyword.html","id":null,"dir":"Reference","previous_headings":"","what":"Find a keyword in the whole database — find_keyword","title":"Find a keyword in the whole database — find_keyword","text":"Find keyword names labels list datasets.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/find_keyword.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Find a keyword in the whole database — find_keyword","text":"","code":"find_keyword(keyword, data = edc_lookup(), ignore_case = TRUE)"},{"path":"https://danchaltiel.github.io/EDCimport/reference/find_keyword.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Find a keyword in the whole database — find_keyword","text":"keyword keyword search . Can handle regular expressions (see examples). data lookup dataframe search keyword. Can set using edc_options(edc_lookup=my_data), done automatically calling read_trialmaster(). ignore_case case differences ignored match? Default TRUE.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/find_keyword.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Find a keyword in the whole database — find_keyword","text":"tibble","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/find_keyword.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Find a keyword in the whole database — find_keyword","text":"","code":"if (FALSE) { # \\dontrun{ path = system.file(\"extdata/Example_Export_SAS_XPORT_2022_08_25_15_16.zip\",                     package=\"EDCimport\", mustWork=TRUE) w = read_trialmaster(path, verbose=FALSE)  find_keyword(\"patient\")  #with regex find_keyword(\"patient$\") find_keyword(\"\\\\d\") find_keyword(\"(Trial|Form) Name\") find_keyword(\"\\\\(\") #you need to escape special characters } # }"},{"path":"https://danchaltiel.github.io/EDCimport/reference/get_common_cols.html","id":null,"dir":"Reference","previous_headings":"","what":"Get columns that are common to multiple datasets — get_common_cols","title":"Get columns that are common to multiple datasets — get_common_cols","text":"Attempt list columns database group ones common datasets. Useful find keys pivot summarise data.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/get_common_cols.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get columns that are common to multiple datasets — get_common_cols","text":"","code":"get_common_cols(lookup = edc_lookup(), min_datasets = 3)  # S3 method for class 'common_cols' summary(object, ...)"},{"path":"https://danchaltiel.github.io/EDCimport/reference/get_common_cols.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get columns that are common to multiple datasets — get_common_cols","text":"lookup lookup table, default edc_lookup() min_datasets minimal number datasets considered object object class \"common_cols\" ... unused","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/get_common_cols.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get columns that are common to multiple datasets — get_common_cols","text":"tibble class \"common_cols\"","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/get_common_cols.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get columns that are common to multiple datasets — get_common_cols","text":"","code":"tm = edc_example() #> Warning: Option \"edc_lookup\" has been overwritten. load_list(tm) x = get_common_cols(min_datasets=1) x #> # A tibble: 27 × 7 #>    column  name_in   datasets  n_datasets pct_datasets datasets_in  datasets_out #>    <chr>   <list>    <list>         <int>        <dbl> <chr>        <chr>        #>  1 crfname <lgl [8]> <chr [8]>          8        1     enrol, db2,… \"\"           #>  2 subjid  <lgl [8]> <chr [8]>          8        1     enrol, db2,… \"\"           #>  3 aegr    <lgl [8]> <chr [1]>          1        0.125 ae           \"enrol, db2… #>  4 aesoc   <lgl [8]> <chr [1]>          1        0.125 ae           \"enrol, db2… #>  5 age     <lgl [8]> <chr [1]>          1        0.125 enrol        \"db2, db3, … #>  6 arm     <lgl [8]> <chr [1]>          1        0.125 enrol        \"db2, db3, … #>  7 date1   <lgl [8]> <chr [1]>          1        0.125 db1          \"enrol, db2… #>  8 date10  <lgl [8]> <chr [1]>          1        0.125 db3          \"enrol, db2… #>  9 date2   <lgl [8]> <chr [1]>          1        0.125 db1          \"enrol, db2… #> 10 date3   <lgl [8]> <chr [1]>          1        0.125 db1          \"enrol, db2… #> # ℹ 17 more rows summary(x) #> # A tibble: 2 × 7 #>   pct_datasets n_datasets n_distinct_datasets n_columns columns    datasets    #>   <chr>             <int>               <int>     <int> <list>     <list>      #> 1 100%                  8                   1         2 <chr [2]>  <list [2]>  #> 2 12%                   1                   8        25 <chr [25]> <list [25]> #> # ℹ 1 more variable: columns_str <chr>"},{"path":"https://danchaltiel.github.io/EDCimport/reference/get_datasets.html","id":null,"dir":"Reference","previous_headings":"","what":"Retrieve the datasets as a list of data.frames — get_datasets","title":"Retrieve the datasets as a list of data.frames — get_datasets","text":"Get datasets lookup table list data.frames.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/get_datasets.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Retrieve the datasets as a list of data.frames — get_datasets","text":"","code":"get_datasets(lookup = edc_lookup(), envir = parent.frame())"},{"path":"https://danchaltiel.github.io/EDCimport/reference/get_datasets.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Retrieve the datasets as a list of data.frames — get_datasets","text":"lookup lookup table envir (internal use)","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/get_datasets.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Retrieve the datasets as a list of data.frames — get_datasets","text":"list datasets","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/get_key_cols.html","id":null,"dir":"Reference","previous_headings":"","what":"Important column names — get_key_cols","title":"Important column names — get_key_cols","text":"Retrieve names patient_id (usually \"SUBJID\" \"PATNO\") crfname (usually \"CRFNAME\") actual names datasets","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/get_key_cols.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Important column names — get_key_cols","text":"","code":"get_key_cols(lookup = edc_lookup())"},{"path":"https://danchaltiel.github.io/EDCimport/reference/get_key_cols.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Important column names — get_key_cols","text":"lookup lookup table","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/get_key_cols.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Important column names — get_key_cols","text":"list(2) characters names patient_id crfname","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/get_meta_cols.html","id":null,"dir":"Reference","previous_headings":"","what":"Get columns shared by most datasets — get_meta_cols","title":"Get columns shared by most datasets — get_meta_cols","text":"trialmaster exports, many datasets share certain amount columns containing meta-data often irrelevant point. function identifies columns present least 95% datasets (default)","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/get_meta_cols.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get columns shared by most datasets — get_meta_cols","text":"","code":"get_meta_cols(min_pct = getOption(\"edc_meta_cols_pct\", 0.95))"},{"path":"https://danchaltiel.github.io/EDCimport/reference/get_meta_cols.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get columns shared by most datasets — get_meta_cols","text":"min_pct Default=0.95. minimal proportion datasets column reach. Subject ID always excluded.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/get_meta_cols.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get columns shared by most datasets — get_meta_cols","text":"character vector","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/get_meta_cols.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get columns shared by most datasets — get_meta_cols","text":"","code":"tm = edc_example() #> Warning: Option \"edc_lookup\" has been overwritten. load_list(tm) meta_cols = get_meta_cols() long_mixed %>% dplyr::select(-dplyr::any_of(meta_cols)) #> # A tibble: 100 × 4 #>    subjid    val1b val2b val3b #>     <int>    <dbl> <dbl> <chr> #>  1      1  1.33    11.0  B     #>  2      1 -0.869   10.9  B     #>  3      2  0.0555  10.0  C     #>  4      2  0.0491  10.1  C     #>  5      3 -0.578    9.28 D     #>  6      3 -0.999    9.80 D     #>  7      4 -0.00243  8.97 E     #>  8      4  0.656    9.03 E     #>  9      5  1.48     8.78 F     #> 10      5 -1.91    10.8  F     #> # ℹ 90 more rows"},{"path":"https://danchaltiel.github.io/EDCimport/reference/get_subjid_cols.html","id":null,"dir":"Reference","previous_headings":"","what":"Get key column names — get_subjid_cols","title":"Get key column names — get_subjid_cols","text":"Retrieve names patient ID CRF name actual names datasets, without respect case. Default values set options.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/get_subjid_cols.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get key column names — get_subjid_cols","text":"","code":"get_subjid_cols(lookup = edc_lookup())  get_crfname_cols(lookup = edc_lookup())"},{"path":"https://danchaltiel.github.io/EDCimport/reference/get_subjid_cols.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get key column names — get_subjid_cols","text":"lookup lookup table","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/get_subjid_cols.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get key column names — get_subjid_cols","text":"character vector","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/get_subjid_cols.html","id":"options","dir":"Reference","previous_headings":"","what":"options","title":"Get key column names — get_subjid_cols","text":"Use edc_options() set default values: edc_cols_subjid defaults c(\"PTNO\", \"SUBJID\") edc_cols_crfname defaults c(\"CRFNAME\")","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/get_subjid_cols.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get key column names — get_subjid_cols","text":"","code":"get_subjid_cols() #> [1] \"subjid\" get_crfname_cols() #> [1] \"crfname\""},{"path":"https://danchaltiel.github.io/EDCimport/reference/harmonize_subjid.html","id":null,"dir":"Reference","previous_headings":"","what":"Harmonize the subject ID of the database — harmonize_subjid","title":"Harmonize the subject ID of the database — harmonize_subjid","text":"Turns subject ID columns datasets factor containing levels subjects database. Avoid problems joining tables, checks can performed levels.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/harmonize_subjid.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Harmonize the subject ID of the database — harmonize_subjid","text":"","code":"harmonize_subjid(datalist, preprocess = NULL, col_subjid = get_subjid_cols())"},{"path":"https://danchaltiel.github.io/EDCimport/reference/harmonize_subjid.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Harmonize the subject ID of the database — harmonize_subjid","text":"datalist list dataframes preprocess optional function modify subject ID column, example .numeric(). See examples. col_subjid names columns holding subject ID (character)","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/harmonize_subjid.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Harmonize the subject ID of the database — harmonize_subjid","text":"datalist, subject id modified","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/harmonize_subjid.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Harmonize the subject ID of the database — harmonize_subjid","text":"","code":"db = edc_example() #> Warning: Option \"edc_lookup\" has been overwritten. db$enrol = head(db$enrol, 10) db$enrol$subjid %>% head() #> [1] 1 2 3 4 5 6 db = harmonize_subjid(db) db$enrol$subjid %>% head() #> [1] 1 2 3 4 5 6 #> 50 Levels: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 ... 50 db = harmonize_subjid(db, preprocess=function(x) paste0(\"#\", x)) db$enrol$subjid %>% head() #> [1] #1 #2 #3 #4 #5 #6 #> 50 Levels: #1 #2 #3 #4 #5 #6 #7 #8 #9 #10 #11 #12 #13 #14 #15 #16 #17 ... #50"},{"path":"https://danchaltiel.github.io/EDCimport/reference/lastnews_table.html","id":null,"dir":"Reference","previous_headings":"","what":"Get a table with the latest date for each patient — lastnews_table","title":"Get a table with the latest date for each patient — lastnews_table","text":"function search date columns every tables returns latest date patient variable comes . Useful survival analysis get right censoring time.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/lastnews_table.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get a table with the latest date for each patient — lastnews_table","text":"","code":"lastnews_table(   except = NULL,   with_ties = FALSE,   show_delta = FALSE,   numeric_id = TRUE,   prefer = NULL,   regex = FALSE,   warn_if_future = TRUE )"},{"path":"https://danchaltiel.github.io/EDCimport/reference/lastnews_table.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get a table with the latest date for each patient — lastnews_table","text":"except datasets/columns searched. Example: scheduled visit patient may died attending considered. with_ties case tie, whether return first origin (FALSE) origins share tie (TRUE). show_delta whether compute difference last prefer date actual last date numeric_id set FALSE patient ID column numeric prefer preferred origins event tie. Usually followup table. regex whether consider except prefer regex. warn_if_future whether show warning dates extraction date. Can also csv file path save warning csv (see csv_path argument edc_data_warn).","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/lastnews_table.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get a table with the latest date for each patient — lastnews_table","text":"dataframe","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/lastnews_table.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get a table with the latest date for each patient — lastnews_table","text":"","code":"tm = edc_example() #> Warning: Option \"edc_lookup\" has been overwritten. load_list(tm) lastnews_table() #> # A tibble: 50 × 5 #>    subjid last_date           origin_data origin_col origin_label     #>     <dbl> <dttm>              <chr>       <chr>      <chr>            #>  1      1 2010-08-01 18:59:37 db2         date4      Date at visit 4  #>  2      2 2010-07-31 15:32:45 db2         date4      Date at visit 4  #>  3      3 2010-07-22 11:24:37 db2         date5      Date at visit 5  #>  4      4 2010-07-23 20:38:32 db3         date10     Date at visit 10 #>  5      5 2010-07-15 07:09:47 db3         date10     Date at visit 10 #>  6      6 2010-07-20 12:27:00 db3         date10     Date at visit 10 #>  7      7 2010-07-28 16:24:09 db3         date9      Date at visit 9  #>  8      8 2010-07-19 15:24:18 db3         date9      Date at visit 9  #>  9      9 2010-08-11 03:48:27 db3         date9      Date at visit 9  #> 10     10 2010-07-30 20:41:23 db3         date10     Date at visit 10 #> # ℹ 40 more rows lastnews_table(except=\"db3\") #> # A tibble: 50 × 5 #>    subjid last_date           origin_data origin_col origin_label    #>     <dbl> <dttm>              <chr>       <chr>      <chr>           #>  1      1 2010-08-01 18:59:37 db2         date4      Date at visit 4 #>  2      2 2010-07-31 15:32:45 db2         date4      Date at visit 4 #>  3      3 2010-07-22 11:24:37 db2         date5      Date at visit 5 #>  4      4 2010-06-19 20:25:02 db2         date6      Date at visit 6 #>  5      5 2010-06-15 11:26:57 db2         date5      Date at visit 5 #>  6      6 2010-06-11 22:06:25 db2         date6      Date at visit 6 #>  7      7 2010-06-17 07:46:07 db2         date6      Date at visit 6 #>  8      8 2010-06-22 10:18:23 db2         date6      Date at visit 6 #>  9      9 2010-05-31 00:51:54 db2         date6      Date at visit 6 #> 10     10 2010-06-12 03:57:46 db2         date6      Date at visit 6 #> # ℹ 40 more rows lastnews_table(except=\"db3$date9\") #> # A tibble: 50 × 5 #>    subjid last_date           origin_data origin_col origin_label     #>     <dbl> <dttm>              <chr>       <chr>      <chr>            #>  1      1 2010-08-01 18:59:37 db2         date4      Date at visit 4  #>  2      2 2010-07-31 15:32:45 db2         date4      Date at visit 4  #>  3      3 2010-07-22 11:24:37 db2         date5      Date at visit 5  #>  4      4 2010-07-23 20:38:32 db3         date10     Date at visit 10 #>  5      5 2010-07-15 07:09:47 db3         date10     Date at visit 10 #>  6      6 2010-07-20 12:27:00 db3         date10     Date at visit 10 #>  7      7 2010-07-12 04:59:23 db3         date10     Date at visit 10 #>  8      8 2010-07-12 19:55:50 db3         date10     Date at visit 10 #>  9      9 2010-07-17 06:26:31 db3         date8      Date at visit 8  #> 10     10 2010-07-30 20:41:23 db3         date10     Date at visit 10 #> # ℹ 40 more rows  lastnews_table(prefer=\"date10\", show_delta=TRUE)  #> # A tibble: 50 × 8 #>    subjid last_date           origin_data origin_col origin_label     #>     <dbl> <dttm>              <chr>       <chr>      <chr>            #>  1      1 2010-08-01 18:59:37 db3         date10     Date at visit 10 #>  2      2 2010-07-31 15:32:45 db3         date10     Date at visit 10 #>  3      3 2010-07-22 11:24:37 db3         date10     Date at visit 10 #>  4      4 2010-07-23 20:38:32 db3         date10     Date at visit 10 #>  5      5 2010-07-15 07:09:47 db3         date10     Date at visit 10 #>  6      6 2010-07-20 12:27:00 db3         date10     Date at visit 10 #>  7      7 2010-07-28 16:24:09 db3         date9      Date at visit 9  #>  8      8 2010-07-19 15:24:18 db3         date9      Date at visit 9  #>  9      9 2010-08-11 03:48:27 db3         date9      Date at visit 9  #> 10     10 2010-07-30 20:41:23 db3         date10     Date at visit 10 #> # ℹ 40 more rows #> # ℹ 3 more variables: preferred_last_date <dttm>, preferred_origin <chr>, #> #   delta <drtn>  csv_file = tempfile(fileext=\".csv\") lastnews_table(prefer=\"date9\", warn_if_future=csv_file)  #> # A tibble: 50 × 5 #>    subjid last_date           origin_data origin_col origin_label     #>     <dbl> <dttm>              <chr>       <chr>      <chr>            #>  1      1 2010-08-01 18:59:37 db2         date4      Date at visit 4  #>  2      2 2010-07-31 15:32:45 db2         date4      Date at visit 4  #>  3      3 2010-07-22 11:24:37 db2         date5      Date at visit 5  #>  4      4 2010-07-23 20:38:32 db3         date10     Date at visit 10 #>  5      5 2010-07-15 07:09:47 db3         date10     Date at visit 10 #>  6      6 2010-07-20 12:27:00 db3         date10     Date at visit 10 #>  7      7 2010-07-28 16:24:09 db3         date9      Date at visit 9  #>  8      8 2010-07-19 15:24:18 db3         date9      Date at visit 9  #>  9      9 2010-08-11 03:48:27 db3         date9      Date at visit 9  #> 10     10 2010-07-30 20:41:23 db3         date10     Date at visit 10 #> # ℹ 40 more rows"},{"path":"https://danchaltiel.github.io/EDCimport/reference/load_as_list.html","id":null,"dir":"Reference","previous_headings":"","what":"Load a .RData file as a list — load_as_list","title":"Load a .RData file as a list — load_as_list","text":"Instead loading .RData file global environment, extract every object list.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/load_as_list.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Load a .RData file as a list — load_as_list","text":"","code":"load_as_list(filename)"},{"path":"https://danchaltiel.github.io/EDCimport/reference/load_as_list.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Load a .RData file as a list — load_as_list","text":"filename filename, .RData extension.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/load_as_list.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Load a .RData file as a list — load_as_list","text":"list","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/load_as_list.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Load a .RData file as a list — load_as_list","text":"","code":"x = list(a=1, b=mtcars) save_list(x, \"test.RData\") y = load_as_list(\"test.RData\") print(y$a) #> [1] 1"},{"path":"https://danchaltiel.github.io/EDCimport/reference/load_list.html","id":null,"dir":"Reference","previous_headings":"","what":"Load a list in an environment — load_list","title":"Load a list in an environment — load_list","text":"Load list environment","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/load_list.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Load a list in an environment — load_list","text":"","code":"load_list(x, env = parent.frame(), remove = TRUE)"},{"path":"https://danchaltiel.github.io/EDCimport/reference/load_list.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Load a list in an environment — load_list","text":"x list env environment onto list loaded remove TRUE, x removed environment afterward","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/load_list.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Load a list in an environment — load_list","text":"nothing, called side-effect","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/load_list.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Load a list in an environment — load_list","text":"","code":"x=list(a=1, b=mtcars) load_list(x, remove=FALSE) print(a) #> [1] 1 print(nrow(b)) #> [1] 32"},{"path":"https://danchaltiel.github.io/EDCimport/reference/manual_correction.html","id":null,"dir":"Reference","previous_headings":"","what":"Manual correction — manual_correction","title":"Manual correction — manual_correction","text":"finding wrong unexpected values exported dataset, can useful temporarily correct hard-coding value. However, manual correction undone soon central database updated correction. manual_correction() applies correction specific dataset column location throws error correction already place. check applies per R session can source script without errors. reset_manual_correction() resets checks. instance, called read_trialmaster().","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/manual_correction.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Manual correction — manual_correction","text":"","code":"manual_correction(   data,   col,   rows,   wrong,   correct,   verbose = getOption(\"edc_correction_verbose\", TRUE) )  reset_manual_correction()"},{"path":"https://danchaltiel.github.io/EDCimport/reference/manual_correction.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Manual correction — manual_correction","text":"data, col, rows rows column dataframe error lies wrong actual wrong value correct temporary correction value verbose whether print informations ()","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/manual_correction.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Manual correction — manual_correction","text":"Nothing, used side effects","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/manual_correction.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Manual correction — manual_correction","text":"","code":"library(dplyr) x = iris %>% mutate(id=row_number(), .before=1) %>% as_tibble() x$Sepal.Length[c(1,3,5)] #> [1] 5.1 4.7 5.0  #1st correction is silent manual_correction(x, Sepal.Length, rows=c(1,3,5),                   wrong=c(5.1, 4.7, 5.0), correct=c(5, 4, 3)) #> Manual correction of \"x$Sepal.Length\": #> ℹ Old: 5.1, 4.7, and 5 #> ℹ New: 5, 4, and 3 x$Sepal.Length[c(1,3,5)] #> [1] 5 4 3  #further correction is silent manual_correction(x, Sepal.Length, rows=c(1,3,5),                   wrong=c(5.1, 4.7, 5.0), correct=c(5, 4, 3))                     #if the database is corrected, an error is thrown if (FALSE) { # \\dontrun{ reset_manual_correction() x$Sepal.Length[c(1,3,5)] = c(5, 4, 3) #mimics db correction manual_correction(x, Sepal.Length, rows=c(1,3,5),                   wrong=c(5.1, 4.7, 5.0), correct=c(5, 4, 3)) } # }"},{"path":"https://danchaltiel.github.io/EDCimport/reference/read_all_csv.html","id":null,"dir":"Reference","previous_headings":"","what":"Read all .csv files in a directory — read_all_csv","title":"Read all .csv files in a directory — read_all_csv","text":"Read .csv files directory, labels specified.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/read_all_csv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Read all .csv files in a directory — read_all_csv","text":"","code":"read_all_csv(   path,   ...,   labels_from = NULL,   clean_names_fun = NULL,   read_fun = \"guess\",   subdirectories = FALSE,   datetime_extraction = \"guess\",   verbose = getOption(\"edc_read_verbose\", 1) )"},{"path":"https://danchaltiel.github.io/EDCimport/reference/read_all_csv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Read all .csv files in a directory — read_all_csv","text":"path [character(1)] path directory containing .csv files. ... unused labels_from [misc] list path file containing labels. clean_names_fun [function] function clean column names, e.g. tolower, janitor::clean_names(),... read_fun [function] function read files path, e.g. read.csv(), read.csv2(),... subdirectories [logical(1)] whether read subdirectories. datetime_extraction [dateish(1)] datetime database extraction (database lock). \"guess\", datetime inferred files modification time. verbose [logical(1)] level verbosity","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/read_all_csv.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Read all .csv files in a directory — read_all_csv","text":"list containing one dataframe .csv file folder, extraction date (datetime_extraction), summary imported tables (.lookup).","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/read_all_csv.html","id":"labels-file","dir":"Reference","previous_headings":"","what":"Labels file","title":"Read all .csv files in a directory — read_all_csv","text":"labels_from contain information column labels. data file (.csv) containing 2 columns: one column name associated label. Use options(edc_col_name=\"xxx\", edc_col_label=\"xxx\") specify names columns.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/read_all_sas.html","id":null,"dir":"Reference","previous_headings":"","what":"Read all .sas7bdat files in a directory — read_all_sas","title":"Read all .sas7bdat files in a directory — read_all_sas","text":"Read .sas7bdat files directory. Formats can applied procformat.sas SAS file, .","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/read_all_sas.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Read all .sas7bdat files in a directory — read_all_sas","text":"","code":"read_all_sas(   path,   ...,   format_file = \"procformat.sas\",   clean_names_fun = NULL,   subdirectories = FALSE,   datetime_extraction = \"guess\",   verbose = getOption(\"edc_read_verbose\", 1) )"},{"path":"https://danchaltiel.github.io/EDCimport/reference/read_all_sas.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Read all .sas7bdat files in a directory — read_all_sas","text":"path [character(1)] path directory containing .sas7bdat files. ... unused format_file [character(1)] path file used apply formats. See details. Use NULL apply formats. clean_names_fun [function] function clean column names, e.g. tolower, janitor::clean_names(),... subdirectories [logical(1)] whether read subdirectories datetime_extraction [POSIXt(1)] datetime data extraction. Default common date last modification directory. verbose [numeric(1)] one c(0, 1, 2). higher, information printed.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/read_all_sas.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Read all .sas7bdat files in a directory — read_all_sas","text":"list containing one dataframe .xpt file folder, extraction date (datetime_extraction), summary imported tables (.lookup).","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/read_all_sas.html","id":"format-file","dir":"Reference","previous_headings":"","what":"Format file","title":"Read all .sas7bdat files in a directory — read_all_sas","text":"format_file contain information SAS formats. can either procformat.sas file, containing whole PROC FORMAT catalog file (.sas7bcat) data file (.csv .sas7bdat) containing 3 columns: SAS format name (repeated), level, associated label. Use options(edc_var_format_name=\"xxx\", edc_var_level=\"xxx\", edc_var_label=\"xxx\") specify names columns.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/read_all_xpt.html","id":null,"dir":"Reference","previous_headings":"","what":"Read all .xpt files in a directory — read_all_xpt","title":"Read all .xpt files in a directory — read_all_xpt","text":"Read .xpt files directory (unzipped TrialMaster archive).  7zip installed, probably rather use read_trialmaster() instead.  procformat.sas file exists directory, formats applied.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/read_all_xpt.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Read all .xpt files in a directory — read_all_xpt","text":"","code":"read_all_xpt(   path,   ...,   format_file = \"procformat.sas\",   clean_names_fun = NULL,   split_mixed = FALSE,   extend_lookup = TRUE,   datetime_extraction = \"guess\",   subdirectories = FALSE,   verbose = getOption(\"edc_read_verbose\", 1),   directory = \"deprecated\",   key_columns = \"deprecated\" )"},{"path":"https://danchaltiel.github.io/EDCimport/reference/read_all_xpt.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Read all .xpt files in a directory — read_all_xpt","text":"path [character(1)] path directory containing .xpt files. ... unused format_file [character(1)] path file used apply formats. See details. Use NULL apply formats. clean_names_fun [function] function clean column names, e.g. tolower, janitor::clean_names(),... split_mixed [logical(1): FALSE] whether split mixed datasets. See split_mixed_datasets. extend_lookup [character(1): FALSE] whether enrich lookup table. See extend_lookup. datetime_extraction [POSIXt(1)] datetime data extraction. Default common date last modification directory. subdirectories [logical(1)] whether read subdirectories verbose [numeric(1)] one c(0, 1, 2). higher, information printed. directory deprecated favour path key_columns deprecated","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/read_all_xpt.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Read all .xpt files in a directory — read_all_xpt","text":"list containing one dataframe .xpt file folder, extraction date (datetime_extraction), summary imported tables (.lookup).","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/read_all_xpt.html","id":"format-file","dir":"Reference","previous_headings":"","what":"Format file","title":"Read all .xpt files in a directory — read_all_xpt","text":"format_file contain information SAS formats. can either procformat.sas file, containing whole PROC FORMAT data file (.csv .sas7bdat) containing 3 columns: SAS format name (repeated), level, associated label. Use options(edc_var_format_name=\"xxx\", edc_var_level=\"xxx\", edc_var_label=\"xxx\") specify names columns.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/read_trialmaster.html","id":null,"dir":"Reference","previous_headings":"","what":"Read the .zip archive of a TrialMaster export — read_trialmaster","title":"Read the .zip archive of a TrialMaster export — read_trialmaster","text":"Import .zip archive TrialMaster trial export list dataframes. archive filename leaved untouched contains project name date extraction.  Generate .rds cache file future reads.  7zip installed available, use read_all_xpt() instead.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/read_trialmaster.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Read the .zip archive of a TrialMaster export — read_trialmaster","text":"","code":"read_trialmaster(   archive,   ...,   use_cache = \"write\",   clean_names_fun = NULL,   split_mixed = FALSE,   extend_lookup = TRUE,   subdirectories = FALSE,   pw = getOption(\"trialmaster_pw\"),   verbose = getOption(\"edc_read_verbose\", 1),   key_columns = \"deprecated\" )"},{"path":"https://danchaltiel.github.io/EDCimport/reference/read_trialmaster.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Read the .zip archive of a TrialMaster export — read_trialmaster","text":"archive [character(1)] path archive ... unused use_cache [mixed(1): \"write\"] controls .rds cache. TRUE, read cache extract archive create cache. FALSE extract archive without creating cache file. Can also \"read\" \"write\". clean_names_fun [function] function clean column names, e.g. tolower, janitor::clean_names(),... split_mixed [logical(1): FALSE] whether split mixed datasets. See split_mixed_datasets. extend_lookup [character(1): FALSE] whether enrich lookup table. See extend_lookup. subdirectories [logical(1)] whether read subdirectories pw [character(1)] password archive protected. avoid writing passwords plain text, probably better use options(trialmaster_pw=\"xxx\") instead though. verbose [numeric(1)] one c(0, 1, 2). higher, information printed. key_columns deprecated","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/read_trialmaster.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Read the .zip archive of a TrialMaster export — read_trialmaster","text":"list containing one dataframe .xpt file folder, extraction date (datetime_extraction), summary imported tables (.lookup).","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/reexports.html","id":null,"dir":"Reference","previous_headings":"","what":"Objects exported from other packages — reexports","title":"Objects exported from other packages — reexports","text":"objects imported packages. Follow links see documentation. dplyr %>% tibble tibble","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/save_list.html","id":null,"dir":"Reference","previous_headings":"","what":"Save a list as .RData file — save_list","title":"Save a list as .RData file — save_list","text":"Save list .RData file","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/save_list.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Save a list as .RData file — save_list","text":"","code":"save_list(x, filename)"},{"path":"https://danchaltiel.github.io/EDCimport/reference/save_list.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Save a list as .RData file — save_list","text":"x list filename filename, .RData extension.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/save_list.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Save a list as .RData file — save_list","text":"nothing, called side-effect","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/save_list.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Save a list as .RData file — save_list","text":"","code":"x=list(a=1, b=mtcars) save_list(x, \"test.RData\") load(\"test.RData\") file.remove(\"test.RData\") #> [1] TRUE print(a) #> [1] 1 print(nrow(b)) #> [1] 32"},{"path":"https://danchaltiel.github.io/EDCimport/reference/save_plotly.html","id":null,"dir":"Reference","previous_headings":"","what":"Save a plotly to an HTML file — save_plotly","title":"Save a plotly to an HTML file — save_plotly","text":"Save plotly HTML file","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/save_plotly.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Save a plotly to an HTML file — save_plotly","text":"","code":"save_plotly(p, file, ...)"},{"path":"https://danchaltiel.github.io/EDCimport/reference/save_plotly.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Save a plotly to an HTML file — save_plotly","text":"p plot object (plotly ggplot) file file path save HTML file ... passed htmlwidgets::saveWidget","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/save_plotly.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Save a plotly to an HTML file — save_plotly","text":"nothing, used side effect","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/save_plotly.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Save a plotly to an HTML file — save_plotly","text":"","code":"if (FALSE) { # \\dontrun{ tm = edc_example_plot() p = edc_swimmerplot(tm$.lookup, id_lim=c(5,45)) save_plotly(p, \"graph/swimplots/edc_swimmerplot.html\", title=\"My Swimmerplot\") } # }"},{"path":"https://danchaltiel.github.io/EDCimport/reference/save_sessioninfo.html","id":null,"dir":"Reference","previous_headings":"","what":"Save sessionInfo() output — save_sessioninfo","title":"Save sessionInfo() output — save_sessioninfo","text":"Save sessionInfo() output text file.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/save_sessioninfo.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Save sessionInfo() output — save_sessioninfo","text":"","code":"save_sessioninfo(path = \"check/session_info.txt\", with_date = TRUE)"},{"path":"https://danchaltiel.github.io/EDCimport/reference/save_sessioninfo.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Save sessionInfo() output — save_sessioninfo","text":"path target path write file with_date whether insert date file extension","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/save_sessioninfo.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Save sessionInfo() output — save_sessioninfo","text":"nothing","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/save_sessioninfo.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Save sessionInfo() output — save_sessioninfo","text":"","code":"if (FALSE) { # \\dontrun{    save_sessioninfo() } # }"},{"path":"https://danchaltiel.github.io/EDCimport/reference/search_for_newer_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Search for newer data — search_for_newer_data","title":"Search for newer data — search_for_newer_data","text":"Search folders TrialMaster database recent current extraction present. default, search \"data\" folder OS usual \"Downloads\" folder. newer database found, user asked want move \"data\" folder.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/search_for_newer_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Search for newer data — search_for_newer_data","text":"","code":"search_for_newer_data(   archive,   ...,   source = path_home(\"Downloads\"),   target = \"data\",   ask = TRUE,   advice = TRUE )"},{"path":"https://danchaltiel.github.io/EDCimport/reference/search_for_newer_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Search for newer data — search_for_newer_data","text":"archive TM archive path, giving project name date ... unused source path vector searched, default \"data\" usual \"Downloads\" folder target path files copied ask whether ask user move file \"data\" advice whether advice move instead, ask==FALSE","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/search_for_newer_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Search for newer data — search_for_newer_data","text":"path newer file, invisibly.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/search_for_newer_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Search for newer data — search_for_newer_data","text":"","code":"if (FALSE) { # \\dontrun{   archive = \"data/MYPROJECT_ExportTemplate_xxx_SAS_XPORT_2024_06_01_12_00.zip\"   #tm = read_trialmaster(archive)   search_for_newer_data(archive) } # }"},{"path":"https://danchaltiel.github.io/EDCimport/reference/select_distinct.html","id":null,"dir":"Reference","previous_headings":"","what":"Select only distinct columns — select_distinct","title":"Select only distinct columns — select_distinct","text":"Select columns one level given grouping scope. Useful dealing mixed datasets containing long data repeated short data.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/select_distinct.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Select only distinct columns — select_distinct","text":"","code":"select_distinct(df, .by)"},{"path":"https://danchaltiel.github.io/EDCimport/reference/select_distinct.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Select only distinct columns — select_distinct","text":"df dataframe .optional grouping columns","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/select_distinct.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Select only distinct columns — select_distinct","text":"df less columns","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/select_distinct.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Select only distinct columns — select_distinct","text":"","code":"db = edc_example() #> Warning: Option \"edc_lookup\" has been overwritten. db$ae %>% colnames() #> [1] \"subjid\"  \"crfname\" \"aesoc\"   \"aegr\"    \"n_ae\"    \"sae\"     #`crfname` has one level for the whole dataset db$ae %>% select_distinct() %>% colnames() #> [1] \"crfname\" #`n_ae` has one level per patient db$ae %>% select_distinct(.by=subjid) %>% colnames() #> [1] \"subjid\"  \"crfname\" \"n_ae\""},{"path":"https://danchaltiel.github.io/EDCimport/reference/split_mixed_datasets.html","id":null,"dir":"Reference","previous_headings":"","what":"Split mixed datasets — split_mixed_datasets","title":"Split mixed datasets — split_mixed_datasets","text":"Split mixed tables, .e. tables hold long data (N values per patient) short data (one value per patient, duplicated N lines), one long table one short table.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/split_mixed_datasets.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Split mixed datasets — split_mixed_datasets","text":"","code":"split_mixed_datasets(   datasets = get_datasets(),   id = get_subjid_cols(),   ...,   ignore_cols = get_meta_cols(0.95),   output_code = FALSE,   verbose = TRUE )"},{"path":"https://danchaltiel.github.io/EDCimport/reference/split_mixed_datasets.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Split mixed datasets — split_mixed_datasets","text":"datasets dataframe list dataframes split. Default datasets .lookup. id patient identifier, probably \"subjid\". shared datasets. Case-insensitive. ... used ignore_cols columns ignore considering table long. Default getOption(\"edc_cols_crfname\", \"CRFNAME\"). Case-insensitive. output_code whether print code explicitly write. Can also file path. verbose whether print informations process.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/split_mixed_datasets.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Split mixed datasets — split_mixed_datasets","text":"list new long short tables. Use load_list() load global environment.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/split_mixed_datasets.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Split mixed datasets — split_mixed_datasets","text":"","code":"#tm = read_trialmaster(\"filename.zip\", pw=\"xx\") tm = edc_example() #> Warning: Option \"edc_lookup\" has been overwritten. names(tm) #>  [1] \"enrol\"               \"db1\"                 \"db2\"                 #>  [4] \"db3\"                 \"short\"               \"long_pure\"           #>  [7] \"long_mixed\"          \"ae\"                  \"datetime_extraction\" #> [10] \"date_extraction\"     \".lookup\"             #load_list(tm) print(tm$long_mixed) #`val1` and `val2` are long but `val3` is short #> # A tibble: 100 × 5 #>    subjid crfname                     val1b val2b val3b #>     <int> <chr>                       <dbl> <dbl> <chr> #>  1      1 both short and long data  1.33    11.0  B     #>  2      1 both short and long data -0.869   10.9  B     #>  3      2 both short and long data  0.0555  10.0  C     #>  4      2 both short and long data  0.0491  10.1  C     #>  5      3 both short and long data -0.578    9.28 D     #>  6      3 both short and long data -0.999    9.80 D     #>  7      4 both short and long data -0.00243  8.97 E     #>  8      4 both short and long data  0.656    9.03 E     #>  9      5 both short and long data  1.48     8.78 F     #> 10      5 both short and long data -1.91    10.8  F     #> # ℹ 90 more rows  mixed_data = split_mixed_datasets(tm, id=\"subjid\", verbose=TRUE) #> ✔ There were 5 short tables: #>   \"enrol\", \"db1\", \"db2\", \"db3\", and \"short\" #> ✔ There was 1 pure long table: #>   \"long_pure\" #> ✔ There were 2 mixed (short+long) tables: #>   \"long_mixed\" and \"ae\" #> → Use `EDCimport::load_list()` on the result to get separated long and short #>   data. load_list(mixed_data) print(long_mixed_short)  #> # A tibble: 50 × 3 #>    subjid crfname                  val3b #>     <int> <chr>                    <chr> #>  1      1 both short and long data B     #>  2      2 both short and long data C     #>  3      3 both short and long data D     #>  4      4 both short and long data E     #>  5      5 both short and long data F     #>  6      6 both short and long data G     #>  7      7 both short and long data H     #>  8      8 both short and long data I     #>  9      9 both short and long data J     #> 10     10 both short and long data K     #> # ℹ 40 more rows print(long_mixed_long)  #> # A tibble: 100 × 3 #>    subjid    val1b val2b #>     <int>    <dbl> <dbl> #>  1      1  1.33    11.0  #>  2      1 -0.869   10.9  #>  3      2  0.0555  10.0  #>  4      2  0.0491  10.1  #>  5      3 -0.578    9.28 #>  6      3 -0.999    9.80 #>  7      4 -0.00243  8.97 #>  8      4  0.656    9.03 #>  9      5  1.48     8.78 #> 10      5 -1.91    10.8  #> # ℹ 90 more rows  #alternatively, get the code and only use the datasets you need split_mixed_datasets(tm, id=\"subjid\", output_code=TRUE) #> ✔ There were 5 short tables: #>   \"enrol\", \"db1\", \"db2\", \"db3\", and \"short\" #> ✔ There was 1 pure long table: #>   \"long_pure\" #> ✔ There were 2 mixed (short+long) tables: #>   \"long_mixed\" and \"ae\" #> → Copy the following code in your script to separate long and short data: #> ## `long_mixed` (dim=100x5) ----  #>  #> long_mixed_short = long_mixed %>%  #>   select(subjid, crfname, val3b) %>%  #>   group_by(subjid) %>%  #>   summarise(across(everything(), unify)) #dim=50x3  #>  #>  long_mixed_long = long_mixed %>%  #>   select(subjid, val1b, val2b) #dim=100x3 #>  #>  #> ## `ae` (dim=175x6) ----  #>  #> ae_short = ae %>%  #>   select(subjid, crfname, n_ae) %>%  #>   group_by(subjid) %>%  #>   summarise(across(everything(), unify)) #dim=48x3  #>  #>  ae_long = ae %>%  #>   select(subjid, aesoc, aegr, sae) #dim=175x4  filename = tempfile(\"mixed_code\", fileext=\".R\") split_mixed_datasets(tm, id=\"subjid\", output_code=filename) #> ✔ There were 5 short tables: #>   \"enrol\", \"db1\", \"db2\", \"db3\", and \"short\" #> ✔ There was 1 pure long table: #>   \"long_pure\" #> ✔ There were 2 mixed (short+long) tables: #>   \"long_mixed\" and \"ae\" #> → Copy the code from /tmp/RtmpvVIOBV/mixed_code1fd86a67712c.R in your script to #>   separate long and short data: #>   `utils::browseURL(/tmp/RtmpvVIOBV/mixed_code1fd86a67712c.R)` readLines(filename) #>  [1] \"## `long_mixed` (dim=100x5) ---- \"                   #>  [2] \"\"                                                    #>  [3] \"long_mixed_short = long_mixed %>% \"                  #>  [4] \"  select(subjid, crfname, val3b) %>% \"               #>  [5] \"  group_by(subjid) %>% \"                             #>  [6] \"  summarise(across(everything(), unify)) #dim=50x3 \" #>  [7] \"\"                                                    #>  [8] \" long_mixed_long = long_mixed %>% \"                  #>  [9] \"  select(subjid, val1b, val2b) #dim=100x3\"           #> [10] \"\"                                                    #> [11] \"\"                                                    #> [12] \"## `ae` (dim=175x6) ---- \"                           #> [13] \"\"                                                    #> [14] \"ae_short = ae %>% \"                                  #> [15] \"  select(subjid, crfname, n_ae) %>% \"                #> [16] \"  group_by(subjid) %>% \"                             #> [17] \"  summarise(across(everything(), unify)) #dim=48x3 \" #> [18] \"\"                                                    #> [19] \" ae_long = ae %>% \"                                  #> [20] \"  select(subjid, aesoc, aegr, sae) #dim=175x4 \""},{"path":"https://danchaltiel.github.io/EDCimport/reference/table_format.html","id":null,"dir":"Reference","previous_headings":"","what":"Identify if a dataframe has a long or a wide format — table_format","title":"Identify if a dataframe has a long or a wide format — table_format","text":"dataset either wide format long format (link). function identifies format dataframe respect subject ID. dataframe wide long columns, considered \"mixed\".","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/table_format.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Identify if a dataframe has a long or a wide format — table_format","text":"","code":"table_format(   df,   id = get_subjid_cols(),   ...,   ignore_cols = get_meta_cols(0.95),   na_rm = FALSE,   warn = TRUE )"},{"path":"https://danchaltiel.github.io/EDCimport/reference/table_format.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Identify if a dataframe has a long or a wide format — table_format","text":"df dataframe id identifying subject ID ... used ignore_cols columns ignore. Usually meta columns (see get_meta_cols). na_rm whether consider missing values warn whether warn ID found","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/table_format.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Identify if a dataframe has a long or a wide format — table_format","text":"string value c(\"wide\", \"long\", \"mixed)","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/table_format.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Identify if a dataframe has a long or a wide format — table_format","text":"","code":"tm = edc_example() #> Warning: Option \"edc_lookup\" has been overwritten. sapply(tm, table_format, warn=FALSE)  #> $enrol #> [1] \"wide\" #>  #> $db1 #> [1] \"wide\" #>  #> $db2 #> [1] \"wide\" #>  #> $db3 #> [1] \"wide\" #>  #> $short #> [1] \"wide\" #>  #> $long_pure #> [1] \"long\" #>  #> $long_mixed #> [1] \"mixed\" #>  #> $ae #> [1] \"mixed\" #>  #> $datetime_extraction #> NULL #>  #> $date_extraction #> NULL #>  #> $.lookup #> NULL #>"},{"path":"https://danchaltiel.github.io/EDCimport/reference/unify.html","id":null,"dir":"Reference","previous_headings":"","what":"Unify a vector — unify","title":"Unify a vector — unify","text":"Turn vector length N vector length 1 checking one unique value. Useful safely flatten duplicated table. preserves label attribute set.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/unify.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Unify a vector — unify","text":"","code":"unify(x)"},{"path":"https://danchaltiel.github.io/EDCimport/reference/unify.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Unify a vector — unify","text":"x vector","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/unify.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Unify a vector — unify","text":"vector length 1","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/unify.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Unify a vector — unify","text":"","code":"unify(c(1,1,1,1)) #> [1] 1 #unify(c(1,1,2,1)) #warning  library(dplyr) x=tibble(id=rep(letters[1:5],10), value=rep(1:5,10)) x %>% group_by(id) %>% summarise(value=unify(value)) #safer than `value=value[1]` #> # A tibble: 5 × 2 #>   id    value #>   <chr> <int> #> 1 a         1 #> 2 b         2 #> 3 c         3 #> 4 d         4 #> 5 e         5 x$value[2]=1 #x %>% group_by(id) %>% summarise(value=unify(value)) #warning about that non-unique value"},{"path":[]},{"path":"https://danchaltiel.github.io/EDCimport/news/index.html","id":"new-features-0-6-0","dir":"Changelog","previous_headings":"","what":"New features","title":"EDCimport 0.6.0 (dev)","text":"New functions edc_patient_gridplot(), creates ggplot matrix giving presence patients datasets (#77) Improved lastnews_table(): allow regex except & prefer, improved warning message, allow saving warning csv (#78) New argument lastnews_table(show_delta=TRUE), computes difference last prefer date actual last date (#81) New functions edc_left_join(), edc_right_join(), edc_full_join(), perform joins defaults subject ID primary key (#82) New function edc_viewer(), run shiny application easily browsing database (#83) New argument subdirectories reading functions (read_trialmaster(), read_all_xpt(), read_all_sas(), read_all_csv()), control whether read sub-directories. Note now, subdirectories read overwrite root files.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/news/index.html","id":"edcimport-052","dir":"Changelog","previous_headings":"","what":"EDCimport 0.5.2","title":"EDCimport 0.5.2","text":"CRAN release: 2024-11-14 Fixed bug lastnews_table() subjid numeric Fixed bug read_all_sas() causing metadata (e.g. date_extraction) converted dataframes","code":""},{"path":"https://danchaltiel.github.io/EDCimport/news/index.html","id":"edcimport-051","dir":"Changelog","previous_headings":"","what":"EDCimport 0.5.1","title":"EDCimport 0.5.1","text":"CRAN release: 2024-10-31 Internal fix CRAN check","code":""},{"path":"https://danchaltiel.github.io/EDCimport/news/index.html","id":"edcimport-050","dir":"Changelog","previous_headings":"","what":"EDCimport 0.5.0","title":"EDCimport 0.5.0","text":"CRAN release: 2024-10-24","code":""},{"path":[]},{"path":"https://danchaltiel.github.io/EDCimport/news/index.html","id":"read-functions-0-5-0","dir":"Changelog","previous_headings":"New features","what":"Read functions","title":"EDCimport 0.5.0","text":"New function read_all_sas() read database .sas7bdat files. New function read_all_csv() read database .csv files.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/news/index.html","id":"sanity-checks-alerts-0-5-0","dir":"Changelog","previous_headings":"New features","what":"Sanity checks alerts","title":"EDCimport 0.5.0","text":"New functions edc_data_warn() edc_data_stop(), alert data inconsistencies (#29, #39, #43). New function edc_data_warnings(), get dataframe warnings thrown edc_data_warn(). New function edc_warn_extraction_date(), alert data old.","code":"ae %>% filter(grade<1 | grade>5) %>% edc_data_stop(\"AE of invalid grade\") ae %>% filter(is.na(grade)) %>% edc_data_warn(\"Grade is missing\", issue_n=13) #> Warning: Issue #13: Grade is missing (8 patients: #21, #28, #39, #95, #97, ...)"},{"path":"https://danchaltiel.github.io/EDCimport/news/index.html","id":"miscellaneous-utils-0-5-0","dir":"Changelog","previous_headings":"New features","what":"Miscellaneous utils","title":"EDCimport 0.5.0","text":"New function select_distinct() select columns one level given grouping scope (#57). New function edc_population_plot() visualize patient analysis population (#56). New function edc_db_to_excel() export whole database Excel file, easier browse RStudio’s table viewer (#55). Use edc_browse_excel() browse file without knowing name. New function edc_inform_code() show much code project contains (#49). New function search_for_newer_data() search path (e.g. Downloads) newer data archive (#46). New function edc_crf_plot() show current database completion status (#48). New function save_sessioninfo(), save sessionInfo() text file (#42). New function fct_yesno(), easily format Yes/columns (#19, #23, #40). New function lastnews_table() find last date information entered patient (#37). Useful survival analyses. New function harmonize_subjid(), structure subject IDs datasets database (#30). New function save_plotly(), save plotly HTML file (#15). New experimental functions table_format(), get_common_cols() get_meta_cols() might become useful find keys pivot summarise data.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/news/index.html","id":"bug-fixes--improvements-0-5-0","dir":"Changelog","previous_headings":"","what":"Bug fixes & Improvements","title":"EDCimport 0.5.0","text":"get_datasets() now work even dataset named base function (#67). read_trialmaster() output readable error password entered although one needed. read_trialmaster(split_mixed=\"TRUE\") work intended. assert_no_duplicate() now argument check duplicate groups, example visit (#17). find_keyword() robust inform proportion missing possible. edc_lookup() now retrieve lookup table. Use build_lookup() build one table list. extend_lookup() fail anymore database faulty table.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/news/index.html","id":"deprecations-0-5-0","dir":"Changelog","previous_headings":"","what":"Deprecations","title":"EDCimport 0.5.0","text":"get_key_cols() replaced get_subjid_cols() get_crfname_cols(). check_subjid() replaced edc_warn_patient_diffs(). can either take vector dataframe input, message informative.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/news/index.html","id":"edcimport-041","dir":"Changelog","previous_headings":"","what":"EDCimport 0.4.1","title":"EDCimport 0.4.1","text":"CRAN release: 2023-12-19","code":""},{"path":"https://danchaltiel.github.io/EDCimport/news/index.html","id":"bug-fixes--improvements-0-4-1","dir":"Changelog","previous_headings":"","what":"Bug fixes & Improvements","title":"EDCimport 0.4.1","text":"Changes testing environment package can installed CRAN despite firewall policies forbidding password-protected archive downloading. Fixed bug corrupted XPT file can prevent whole import fail.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/news/index.html","id":"edcimport-040","dir":"Changelog","previous_headings":"","what":"EDCimport 0.4.0","title":"EDCimport 0.4.0","text":"CRAN release: 2023-12-11","code":""},{"path":"https://danchaltiel.github.io/EDCimport/news/index.html","id":"new-features-0-4-0","dir":"Changelog","previous_headings":"","what":"New features","title":"EDCimport 0.4.0","text":"New function check_subjid() check vector missing patients (#8). New function assert_no_duplicate() abort table duplicates subject ID column(#9). New function manual_correction() safely hard-code correction waiting TrialMaster database updated. New function edc_options() manage EDCimport global parameterization. New argument edc_swimmerplot(id_lim) subset swimmer plot patients . New option read_trialmaster(use_cache=\"write\") read zip still update cache. can now use syntax read_trialmaster(split_mixed=c(\"col1\", \"col2\")) split datasets need (#10).","code":"options(edc_subjid_ref=enrolres$subjid) check_subjid(treatment$subjid) check_subjid(ae$subjid) tibble(subjid=c(1:10, 1)) %>% assert_no_duplicate() %>% nrow() #Error in `assert_no_duplicate()`: #! Duplicate on column \"subjid\" for value 1."},{"path":"https://danchaltiel.github.io/EDCimport/news/index.html","id":"bug-fixes--improvements-0-4-0","dir":"Changelog","previous_headings":"","what":"Bug fixes & Improvements","title":"EDCimport 0.4.0","text":"Reading read_trialmaster() cache output error parameters (split_mixed, clean_names_fun) different (#4). split_mixed_datasets() now fully case-insensitive. Non-UTF8 characters labels now identified corrected reading (#5).","code":""},{"path":"https://danchaltiel.github.io/EDCimport/news/index.html","id":"minor-breaking-changes-0-4-0","dir":"Changelog","previous_headings":"","what":"Minor breaking changes","title":"EDCimport 0.4.0","text":"read_trialmaster(use_cache=\"write\") now default. Reading cache stable yet, opt-rather opt-. read_trialmaster(extend_lookup=TRUE) now default. Options edc_id, edc_crfname, edc_verbose respectively renamed edc_cols_id, edc_cols_crfname, edc_read_verbose clarity.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/news/index.html","id":"edcimport-030-20230519","dir":"Changelog","previous_headings":"","what":"EDCimport 0.3.0 2023/05/19","title":"EDCimport 0.3.0 2023/05/19","text":"CRAN release: 2023-05-19","code":""},{"path":"https://danchaltiel.github.io/EDCimport/news/index.html","id":"new-features-0-3-0","dir":"Changelog","previous_headings":"","what":"New features","title":"EDCimport 0.3.0 2023/05/19","text":"New function edc_swimmerplot() show swimmer plot dates database easily find outliers. New features read_trialmaster(): clean_names_fun=some_fun clean names tables. instance, clean_names_fun=janitor::clean_names() turn default SAS uppercase column names valid R snake-case column names. split_mixed=TRUE split tables contain long short data regarding patient ID one long table one short table. See ?split_mixed_datasets() details. extend_lookup=TRUE improve lookup table additional information. See ?extend_lookup() details. key_columns=get_key_cols() can change default column names patient ID CRF name (used new features). Standalone functions extend_lookup() split_mixed_datasets(). New helper unify(), turns vector duplicate values vector length 1.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/news/index.html","id":"bug-fixes-0-3-0","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"EDCimport 0.3.0 2023/05/19","text":"Reading errors now handled read_trialmaster() instead failing. one XPT file corrupted, resulting object contain error message instead dataset. find_keyword() now robust non-UTF8 characters labels. Option edc_lookup now set even reading cache. SAS formats containing = now work intended.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/news/index.html","id":"edcimport-021-20221101","dir":"Changelog","previous_headings":"","what":"EDCimport 0.2.1 2022/11/01","title":"EDCimport 0.2.1 2022/11/01","text":"CRAN release: 2022-12-02 Import data TrialMaster using tm = read_trialmaster(\"path//archive.zip\"). Search keyword column name label using find_keyword(\"date\", data=tm$.lookup). can also generate lookup table arbitrary list dataframe using build_lookup(my_data). Load datasets global environment using load_list(tm) avoid typing tm$ everywhere. Browse available global options using ?EDCimport_options.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/news/index.html","id":"edcimport-010","dir":"Changelog","previous_headings":"","what":"EDCimport 0.1.0","title":"EDCimport 0.1.0","text":"Draft version","code":""}]
