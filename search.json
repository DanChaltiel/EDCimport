[{"path":"https://danchaltiel.github.io/EDCimport/articles/checking.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"3 - Data checking","text":"imported database, now need check errors inconsistencies. lot ways , EDCimport provides functions concepts. previous vignettes, using edc_example(), real world use EDC reading functions. See vignette(\"reading\") see .","code":"library(EDCimport) library(dplyr) db = edc_example(N=200) %>%    edc_unify_subjid() %>%    edc_clean_names() db #> â”€â”€ EDCimport database â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ load_database(db)"},{"path":"https://danchaltiel.github.io/EDCimport/articles/checking.html","id":"data-warning","dir":"Articles","previous_headings":"","what":"Data warning","title":"3 - Data checking","text":"primary valuable data-checking tool EDCimport edc_data_warn(). Simply use dplyr::filter() identify problematic inconsistent rows pipe function. example, letâ€™s say study: Patients older 25 Adverse event grades 1 5. Patients treatment arm data1$date1 2010-04-10 â€™s check conditions: can implement checks according Data Validation Plan, ensuring run every export. failed check produce warning R console. database corrected, warnings longer appear (e.g.Â issue_n=2). running checks, can use edc_data_warnings() get summary detected issues. one check mandatory work database fails, use edc_data_stop() instead. example, can use check variable construction didnâ€™t go wrong:","code":"enrol %>%    filter(age<25) %>%    edc_data_warn(\"Patients should be >25yo\", issue_n=1) #> Warning: Issue #01: Patients should be >25yo (2 patients: #18 and #59)  ae %>%    filter(aegr<1 | aegr>5) %>%    edc_data_warn(\"Incorrect adverse event grade\", issue_n=2)  data1 %>%    edc_left_join(enrol) %>%    filter(arm==\"Trt\") %>%    filter(date1<\"2010-04-10\") %>%    edc_data_warn(\"Treated patients should have been seen later\", issue_n=3) #> Warning: Issue #03: Treated patients should have been seen later (9 patients: #1, #45, #> #64, #69, #82, â€¦) edc_data_warnings() #> # A tibble: 3 Ã— 5 #>   issue_n message                                      subjid    data     type  #>   <chr>   <chr>                                        <list>    <list>   <chr> #> 1 01      Patients should be >25yo                     <chr [2]> <tibble> WARN  #> 2 02      Incorrect adverse event grade                <NULL>    <tibble> WARN  #> 3 03      Treated patients should have been seen later <chr [9]> <tibble> WARN df = mtcars %>%    mutate(     type = case_when(       cyl==4 ~ \"4 cylinders\",        cyl==6 ~ \"6 cylinders\",        cyl==8 ~ \"8 cylinders\",        .default=\"ERROR\"     ),   )  df %>%    filter(type==\"ERROR\") %>%    edc_data_stop(\"Error on type construction\")"},{"path":"https://danchaltiel.github.io/EDCimport/articles/checking.html","id":"data-errors","dir":"Articles","previous_headings":"","what":"Data errors","title":"3 - Data checking","text":"primary valuable data-checking tool EDCimport edc_data_warn(). Simply use dplyr::filter() identify problematic inconsistent rows pipe function. example, letâ€™s say study: Patients older 25 Adverse event grades 1 5. Patients treatment arm data1$date1 2010-04-10 â€™s check conditions: can implement checks according Data Validation Plan, ensuring run every export. failed check produce warning R console. database corrected, warnings longer appear (e.g.Â issue_n=2). running checks, can use edc_data_warnings() get summary detected issues.","code":"enrol %>%    filter(age<25) %>%    edc_data_warn(\"Patients should be >25yo\", issue_n=1) #> Warning: Issue #01: Patients should be >25yo (2 patients: #18 and #59)  ae %>%    filter(aegr<1 | aegr>5) %>%    edc_data_warn(\"Incorrect adverse event grade\", issue_n=2)  data1 %>%    edc_left_join(enrol) %>%    filter(arm==\"Trt\") %>%    filter(date1<\"2010-04-10\") %>%    edc_data_warn(\"Treated patients should have been seen later\", issue_n=3) #> Warning: Issue #03: Treated patients should have been seen later (9 patients: #1, #45, #> #64, #69, #82, â€¦) edc_data_warnings() #> # A tibble: 3 Ã— 5 #>   issue_n message                                      subjid    data     type  #>   <chr>   <chr>                                        <list>    <list>   <chr> #> 1 01      Patients should be >25yo                     <chr [2]> <tibble> WARN  #> 2 02      Incorrect adverse event grade                <NULL>    <tibble> WARN  #> 3 03      Treated patients should have been seen later <chr [9]> <tibble> WARN"},{"path":"https://danchaltiel.github.io/EDCimport/articles/checking.html","id":"fatal-error","dir":"Articles","previous_headings":"","what":"Fatal error","title":"3 - Data checking","text":"one check mandatory work database fails, use edc_data_stop() instead. example, can use check variable construction didnâ€™t go wrong:","code":"df = mtcars %>%    mutate(     type = case_when(       cyl==4 ~ \"4 cylinders\",        cyl==6 ~ \"6 cylinders\",        cyl==8 ~ \"8 cylinders\",        .default=\"ERROR\"     ),   )  df %>%    filter(type==\"ERROR\") %>%    edc_data_stop(\"Error on type construction\")"},{"path":"https://danchaltiel.github.io/EDCimport/articles/checking.html","id":"duplicate-free-dataset-assertion","dir":"Articles","previous_headings":"","what":"Duplicate-free dataset assertion","title":"3 - Data checking","text":"work multiple datasets, code probably include lot joins. may painfully discovered, joining data carries high risk altering data layout resulting multiple rows per patient. always include assert_no_duplicate() pipeline expect one row per patient. Tip Fail Fast principle: â€™d better error R script analysis report.","code":"enrol %>%    assert_no_duplicate() %>%    count(arm) #> # A tibble: 2 Ã— 2 #>   arm       n #>   <chr> <int> #> 1 Ctl      99 #> 2 Trt     101  enrol %>%    edc_left_join(data1) %>% #oopsie   assert_no_duplicate() %>%    count(arm) #> Error in `assert_no_duplicate()`: #> ! Duplicate on column \"subjid\" for values 1, 2, 3, 4, 5, 6, 7, 8, 9, and #>   10."},{"path":"https://danchaltiel.github.io/EDCimport/articles/checking.html","id":"last-news-table","dir":"Articles","previous_headings":"","what":"Last-news table","title":"3 - Data checking","text":"analysis involves survival endpoint, likely follow-dataset includes vital status last visit date. However, real-world scenarios, dataset might accurately filled, patient can data date last visit. lastnews_table() function calculates actual date last recorded information patient (SUBJID), based Date/Datetime columns across datasets. Currently, edc_example() include explicit table scenario, letâ€™s consider following example: data3$date10 last visit date followup dataset. origin prefer tie reference identify inconsistency. data1 dataset containing scheduled protocol dates, planned medical visits. ignore columns dataset, pertain patientâ€™s last known date8 date9 dates treatments administered. imply patient alive time. date date10, means survival time underestimated. parameterize lastnews_table() fit scenario: Warning table useful Overall Survival data checking. However, careful using Event-Free Survival: patient can alive point without experienced event.","code":"lastnews_table(prefer=\"date10\", except=\"data1\", show_delta=TRUE) %>%    mutate(delta=round(delta)) %>%    arrange(desc(delta)) #> # A tibble: 200 Ã— 8 #>    subjid last_date  origin_data origin_col origin_label    preferred_last_date #>     <dbl> <date>     <chr>       <chr>      <chr>           <date>              #>  1      9 2010-08-01 data3       date9      Date at visit 9 2010-07-14          #>  2     41 2010-07-28 data3       date9      Date at visit 9 2010-07-09          #>  3     71 2010-07-16 data3       date8      Date at visit 8 2010-06-28          #>  4    186 2010-07-12 data3       date9      Date at visit 9 2010-06-23          #>  5     14 2010-07-30 data3       date9      Date at visit 9 2010-07-13          #>  6     61 2010-07-30 data3       date9      Date at visit 9 2010-07-12          #>  7     68 2010-08-06 data3       date8      Date at visit 8 2010-07-20          #>  8    120 2010-07-27 data3       date9      Date at visit 9 2010-07-09          #>  9     58 2010-07-31 data3       date9      Date at visit 9 2010-07-15          #> 10     93 2010-07-30 data3       date9      Date at visit 9 2010-07-13          #> # â„¹ 190 more rows #> # â„¹ 2 more variables: preferred_origin <chr>, delta <drtn>"},{"path":"https://danchaltiel.github.io/EDCimport/articles/postprocessing.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"2 - Post processing","text":"Caution reading , read vignette(\"reading\") learn import database. importing database EDCimport, end edc_database object, can loaded global environment using load_database(). However, EDCimport provides functions improve database loading .","code":""},{"path":"https://danchaltiel.github.io/EDCimport/articles/postprocessing.html","id":"harmonize-subject-id-across-the-database","dir":"Articles","previous_headings":"","what":"Harmonize Subject ID across the database","title":"2 - Post processing","text":"Subject ID column, usually SUBJID CDISC data, primary key, shared almost datasets. Using edc_unify_subjid(), can harmonize column across whole database, becomes factor, consistent datasets. preprocess, can even customize . especially convenient joining data checking missing patients. Note SUBJID column numeric preprocess empty, SUBJID cast numeric.","code":"library(EDCimport) db1 = edc_example() load_database(db1) enrol$subjid %>% class() #> [1] \"integer\" enrol$subjid %>% head() #> [1] 1 2 3 4 5 6  db2 = edc_example() %>%    edc_unify_subjid(preprocess=~paste0(\"#\", .x)) load_database(db2) enrol$subjid %>% class() #> [1] \"factor\" enrol$subjid %>% head() #> [1] #1 #2 #3 #4 #5 #6 #> 50 Levels: #1 #2 #3 #4 #5 #6 #7 #8 #9 #10 #11 #12 #13 #14 #15 #16 #17 ... #50 #missing patients in table `ae` ae$subjid %>%    forcats::fct_count() %>%    dplyr::filter(n==0)  #> # A tibble: 2 Ã— 2 #>   f         n #>   <fct> <int> #> 1 #35       0 #> 2 #37       0"},{"path":"https://danchaltiel.github.io/EDCimport/articles/postprocessing.html","id":"clean-dataset-names","dir":"Articles","previous_headings":"","what":"Clean dataset names","title":"2 - Post processing","text":"database messy EDC software, filled special characters camelCase column names? Fear ! edc_clean_names() can clean dataset names . default, converts names lowercase letters, numbers, underscores . example, since edc_example() already provides clean column names, letâ€™s convert columns uppercase:","code":"library(EDCimport) db = edc_example() %>%    edc_clean_names(toupper) load_database(db) names(enrol) #> [1] \"SUBJID\"     \"AGE\"        \"ENROL_DATE\" \"ARM\"        \"CRFNAME\"    #> [6] \"CRFSTAT\""},{"path":"https://danchaltiel.github.io/EDCimport/articles/postprocessing.html","id":"split-some-dataset-to-shortlong","dir":"Articles","previous_headings":"","what":"Split some dataset to short+long","title":"2 - Post processing","text":"Note one bit complex, bear , â€™ll try make understandable. CRF form contains repeated non-repeated measures, export usually duplicates non-repeated measure. results â€œmixedâ€ data format, combining â€œlongâ€ â€œshortâ€ structures. (usually call latter â€œwideâ€, case really.) example, dataset long_mixed edc_example(), two long-format variables (one value per observation) one wide-format variable (one value per subject). complex CRFs lengthy forms, mixed structure can complicate analysis, repeated non-repeated data may unrelated. edc_split_mixed(), can split dataset two, one short one long:","code":"head(long_mixed) #> # A tibble: 6 Ã— 6 #>   SUBJID CRFNAME                    LONG1 LONG2 SHORT CRFSTAT    #>    <int> <chr>                      <dbl> <dbl> <chr> <chr>      #> 1      1 both short and long data  1.33   11.0  B     Complete   #> 2      1 both short and long data -0.869  10.9  B     Complete   #> 3      2 both short and long data  0.0555 10.00 C     Complete   #> 4      2 both short and long data  0.0491 10.1  C     Incomplete #> 5      3 both short and long data -0.578   9.28 D     Complete   #> 6      3 both short and long data -0.999   9.80 D     Complete db = edc_example() %>%    edc_split_mixed(long_mixed) load_database(db) head(long_mixed_short) #one row per subject #> # A tibble: 6 Ã— 3 #>   subjid crfname                  short #>    <int> <chr>                    <chr> #> 1      1 both short and long data B     #> 2      2 both short and long data C     #> 3      3 both short and long data D     #> 4      4 both short and long data E     #> 5      5 both short and long data F     #> 6      6 both short and long data G head(long_mixed_long)  #one row per observation #> # A tibble: 6 Ã— 4 #>   subjid   long1 long2 crfstat    #>    <int>   <dbl> <dbl> <chr>      #> 1      1  1.33   11.0  Complete   #> 2      1 -0.869  10.9  Complete   #> 3      2  0.0555 10.00 Complete   #> 4      2  0.0491 10.1  Incomplete #> 5      3 -0.578   9.28 Complete   #> 6      3 -0.999   9.80 Complete"},{"path":"https://danchaltiel.github.io/EDCimport/articles/postprocessing.html","id":"you-can-combine","dir":"Articles","previous_headings":"","what":"You can combine!","title":"2 - Post processing","text":"Obviously, functions can piped one another: Donâ€™t hesitate submit feature request think another function can useful others!","code":"db = edc_example() %>%    edc_split_mixed(long_mixed)  %>%    edc_unify_subjid(preprocess=~paste0(\"#\", .x))%>%    edc_clean_names(toupper)  load_database(db)"},{"path":"https://danchaltiel.github.io/EDCimport/articles/reading.html","id":"read-your-database","dir":"Articles","previous_headings":"","what":"Read your database","title":"1 - Read your database","text":"reading vignette, chances requested export EDC software provided directory filled files datasets. Wouldnâ€™t tedious load files one one? Lucky , EDCimport knows better way! Depending type files export directory, use: read_all_sas(), read .sas7bdatÂ files read_all_xpt(), read .xptÂ files read_all_csv(), read .csvÂ files read_trialmaster() read TrialMaster zip archive. Formats imported metadata file, format_file, can either: procformat.sas file, containing whole PROC FORMAT catalog file (.sas7bcat) data file (.csv .sas7bdat) containing 3 columns: SAS format name (repeated), level, associated label. Use options(edc_var_format_name=\"xxx\", edc_var_level=\"xxx\", edc_var_label=\"xxx\") specify names columns. can load datasets global environment load_database().","code":"library(EDCimport) db = read_all_sas(\"path/to/my/files/folder\", format_file=\"procformat.sas\") print(db) load_database(db) #this also removes `db` to save some RAM mean(dataset1$column5)"},{"path":"https://danchaltiel.github.io/EDCimport/articles/reading.html","id":"explore-your-database","dir":"Articles","previous_headings":"","what":"Explore your database","title":"1 - Read your database","text":"Knowing CRF hand always easy task, EDCimport provide useful tools: edc_lookup(), remember available datasets. edc_find_column() edc_find_value(), search database column/label actual value.","code":"db = edc_example() load_database(db) edc_lookup() #> â”€â”€ Lookup table - EDCimport example (extraction of 2024-01-01) - EDCimport v0.6. #>   dataset     nrow  ncol  n_id rows_per_id crfname                  #>   <chr>      <dbl> <dbl> <int>       <dbl> <chr>                    #> 1 long_pure    150     4    50         3   long data                #> 2 data1        100     7    50         2   data1                    #> 3 long_mixed   100     6    50         2   both short and long data #> 4 data2         50     6    50         1   data2                    #> 5 data3         50     7    50         1   data3                    #> 6 enrol         50     6    50         1   enrol                    #> 7 short         50     5    50         1   short data               #> 8 ae           175     7    48         3.6 Adverse events edc_find_column(\"date\") #> # A tibble: 11 Ã— 5 #>    dataset crfname names      labels            prop_na #>    <chr>   <chr>   <chr>      <chr>               <dbl> #>  1 data1   data1   date1      Date at visit 1         0 #>  2 data1   data1   date2      Date at visit 2         0 #>  3 data1   data1   date3      Date at visit 3         0 #>  4 data2   data2   date4      Date at visit 4         0 #>  5 data2   data2   date5      Date at visit 5         0 #>  6 data2   data2   date6      Date at visit 6         0 #>  7 data3   data3   date7      Date at visit 7         0 #>  8 data3   data3   date8      Date at visit 8         0 #>  9 data3   data3   date9      Date at visit 9         0 #> 10 data3   data3   date10     Date at visit 10        0 #> 11 enrol   enrol   enrol_date Date of enrolment       0 edc_find_value(\"immune\") #> # A tibble: 7 Ã— 5 #>   subjid dataset column column_label value                   #>   <chr>  <chr>   <chr>  <chr>        <chr>                   #> 1 9      ae      aesoc  AE SOC       Immune system disorders #> 2 24     ae      aesoc  AE SOC       Immune system disorders #> 3 26     ae      aesoc  AE SOC       Immune system disorders #> 4 31     ae      aesoc  AE SOC       Immune system disorders #> 5 46     ae      aesoc  AE SOC       Immune system disorders #> 6 46     ae      aesoc  AE SOC       Immune system disorders #> 7 49     ae      aesoc  AE SOC       Immune system disorders"},{"path":"https://danchaltiel.github.io/EDCimport/articles/reading.html","id":"shiny-browser","dir":"Articles","previous_headings":"","what":"Shiny browser","title":"1 - Read your database","text":"simplest way explore database running edc_viewer(), launches local Shiny application:","code":"db = edc_example() load_database(db) edc_viewer()"},{"path":"https://danchaltiel.github.io/EDCimport/articles/utils.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"5 - Utility Functions","text":"imported database, now might want visualize part . lot ways , EDCimport provides functions concepts. previous vignettes, using edc_example(), real world use EDC reading functions. See vignette(\"reading\") see .","code":"library(EDCimport)  library(dplyr)  db = edc_example(N=200) %>%   edc_unify_subjid() %>%   edc_clean_names()  db  #> â”€â”€ EDCimport database â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ load_database(db)"},{"path":"https://danchaltiel.github.io/EDCimport/articles/utils.html","id":"joins","dir":"Articles","previous_headings":"","what":"Joins","title":"5 - Utility Functions","text":"primary key almost always SUBJID, {dplyr} joins can simplified default suffix arguments.","code":"data_xx = enrol %>%    edc_left_join(data2) %>%    edc_right_join(data1) %>%    edc_full_join(ae) dim(data_xx) #> [1] 1240   23 names(data_xx) %>% stringr::str_subset(\"crfname\") #suffixes are automated #> [1] \"crfname\"       \"crfname_data2\" \"crfname_data1\" \"crfname_ae\""},{"path":"https://danchaltiel.github.io/EDCimport/articles/utils.html","id":"yesno-harmonizer","dir":"Articles","previous_headings":"","what":"â€œYes/Noâ€ harmonizer","title":"5 - Utility Functions","text":"Using fct_yesno(), can harmonize â€œYes/â€ values vector â€œYesâ€ level first:","code":"set.seed(42) x = tibble(a=c(\"Yes\", \"No\"), b=c(\"Oui\", \"Non\"), c=0:1, d=c(TRUE, FALSE)) x #> # A tibble: 2 Ã— 4 #>   a     b         c d     #>   <chr> <chr> <int> <lgl> #> 1 Yes   Oui       0 TRUE  #> 2 No    Non       1 FALSE x %>% dplyr::mutate_all(fct_yesno) #> # A tibble: 2 Ã— 4 #>   a     b     c     d     #>   <fct> <fct> <fct> <fct> #> 1 Yes   Yes   No    Yes   #> 2 No    No    Yes   No"},{"path":"https://danchaltiel.github.io/EDCimport/articles/utils.html","id":"miscellaneous","dir":"Articles","previous_headings":"","what":"Miscellaneous","title":"5 - Utility Functions","text":"three helpers donâ€™t quite fit anywhere else, still deserve moment! save_session_info() saves output session_info() file. edc_warn_extraction_date() triggers warning extraction date edc_database older specified threshold. edc_inform_code() outputs message indicating amount code written analysis, assuming one file sourcing others.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/articles/visualizing.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"4 - Database Visualizing","text":"imported database, now might want visualize part . lot ways , EDCimport provides functions concepts. previous vignettes, using edc_example(), real world use EDC reading functions. See vignette(\"reading\") see .","code":"library(EDCimport)  library(dplyr)  db = edc_example(N=200) %>%   edc_unify_subjid() %>%   edc_clean_names()  db  #> â”€â”€ EDCimport database â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ load_database(db)"},{"path":"https://danchaltiel.github.io/EDCimport/articles/visualizing.html","id":"swimmer-plot","dir":"Articles","previous_headings":"","what":"Swimmer plot","title":"4 - Database Visualizing","text":"patient experiences series events visits, recorded Date/Datetime columns across datasets. simple effective method identify errors inconsistencies create swimmerplot columns. visualization helps quickly spot incorrect sequences, data entry errors, unexpected time gaps. example, can check experimental treatment administered enrollment latest recorded date appears follow-dataset.  convenient way perform checks using interactive plot plotly=TRUE. Although displayed within vignette, output can saved standalone HTML file easy sharing.","code":"edc_swimmerplot(origin=\"enrol$enrol_date\") sp = edc_swimmerplot(plotly=TRUE) sp save_plotly(sp, \"swimmerplot.html\")"},{"path":"https://danchaltiel.github.io/EDCimport/articles/visualizing.html","id":"crf-completion-plot","dir":"Articles","previous_headings":"","what":"CRF completion plot","title":"4 - Database Visualizing","text":"Using edc_crf_plot(), can generate barplot showing distribution CRF status (Complete, Incomplete, â€¦) dataset database.","code":"edc_crf_plot()"},{"path":"https://danchaltiel.github.io/EDCimport/articles/visualizing.html","id":"patient-gridplot","dir":"Articles","previous_headings":"","what":"Patient gridplot","title":"4 - Database Visualizing","text":"Using edc_patient_gridplot(), can visualize patients included dataset identify problematic missing records.","code":"edc_patient_gridplot()"},{"path":"https://danchaltiel.github.io/EDCimport/articles/visualizing.html","id":"population-plot","dir":"Articles","previous_headings":"","what":"Population plot","title":"4 - Database Visualizing","text":"edc_population_plot(), can visualize different analysis populations. , use setdiff() exclude patients various populations, real-world data probably use dplyr::filter().","code":"# Total population: all screened patients pop_total <- c(1:100) %>% setdiff(12) #Software error, SUBJID attributed twice  # ITT (Intent-to-Treat): All randomized patients (excluding screening failures only) pop_itt <- pop_total %>% setdiff(55)  # mITT (Modified ITT): All treated patients pop_m_itt <- pop_itt %>% setdiff(68) #Patient 68 randomized but never received treatment  # PP (Per-Protocol): Patients who completed treatment without major protocol deviations pop_pp <- pop_m_itt %>% setdiff(c(33, 79)) #Major deviations  # Safety: All patients who received at least one dose of treatment pop_safety <- pop_itt %>% setdiff(68)  #Same as mITT  # Evaluable: Patients who completed required assessments for primary endpoint pop_evaluable <- pop_itt %>% setdiff(c(44, 91))  #No primary endpoint assessment  l = list(   \"Total population\"=pop_total,   \"ITT population\"=pop_itt,   \"mITT population\"=pop_m_itt,   \"PP population\"=pop_pp,   \"Safety population\"=pop_safety,   \"Evaluable population\"=pop_evaluable ) edc_population_plot(l[-1], ref=pop_total)"},{"path":"https://danchaltiel.github.io/EDCimport/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Dan Chaltiel. Author, maintainer.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Chaltiel D (2025). EDCimport: Import Data EDC Software. R package version 0.6.0.9014, https://github.com/DanChaltiel/EDCimport.","code":"@Manual{,   title = {EDCimport: Import Data from EDC Software},   author = {Dan Chaltiel},   year = {2025},   note = {R package version 0.6.0.9014},   url = {https://github.com/DanChaltiel/EDCimport}, }"},{"path":[]},{"path":"https://danchaltiel.github.io/EDCimport/index.html","id":"introduction-","dir":"","previous_headings":"","what":"Introduction ðŸ“¦","title":"Import Data from EDC Software","text":"EDCimport package designed simplify import management Electronic Data Capture (EDC) exports, particularly clinical research settings. opinionated framework, providing multiple streamlined tools importing, cleaning, checking datasets. [!WARNING] package experimental active development. Backward compatibility priority moment. reproducibility, use renv set package version.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/index.html","id":"installation-ï¸","dir":"","previous_headings":"","what":"Installation ðŸ› ï¸","title":"Import Data from EDC Software","text":"[!WARNING] documentation pertains dev version, one CRAN.","code":"# Install last version available on CRAN install.packages(\"EDCimport\")  # Install development version on Github pak::pak(\"DanChaltiel/EDCimport@v0.6.0.9014\")"},{"path":[]},{"path":"https://danchaltiel.github.io/EDCimport/index.html","id":"load-the-data","dir":"","previous_headings":"Features ðŸš€","what":"Load the data","title":"Import Data from EDC Software","text":"Use one read_all_sas(), read_all_xpt(), read_all_csv(), read_trialmaster(), depending type files export directory. can load datasets global environment load_database().","code":"library(EDCimport) db = read_all_sas(\"path/to/my/files/folder\") print(db) load_database(db) #this also removes `db` to save some RAM mean(dataset1$column5)"},{"path":"https://danchaltiel.github.io/EDCimport/index.html","id":"database-management-tools","dir":"","previous_headings":"Features ðŸš€","what":"Database management tools","title":"Import Data from EDC Software","text":"EDCimport includes set useful tools help using imported database. See References complete list.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/index.html","id":"database-summary","dir":"","previous_headings":"Features ðŸš€ > Database management tools","what":"Database summary","title":"Import Data from EDC Software","text":"edc_lookup() returns dataframe containing number rows, columns, patients, CRF name dataset.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/index.html","id":"search-the-whole-database","dir":"","previous_headings":"Features ðŸš€ > Database management tools","what":"Search the whole database","title":"Import Data from EDC Software","text":"find_keyword() runs global search database given keyword (regex). instance, say looking â€œdate ECGâ€ donâ€™t know , can run find_keyword(\"date\") find_keyword(\"ecg\"). wonâ€™t look actual data, though, take much computing power.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/index.html","id":"get-the-last-news-date-of-each-subject","dir":"","previous_headings":"Features ðŸš€ > Database management tools","what":"Get the last news date of each subject","title":"Import Data from EDC Software","text":"lastnews_table() finds last date subject throughout whole database inform date original dataset column. arguments avoid selecting irrelevant dates. useful get actual followup time fitting survival analyses.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/index.html","id":"data-checking-system","dir":"","previous_headings":"Features ðŸš€ > Database management tools","what":"Data checking system","title":"Import Data from EDC Software","text":"edc_data_warn() throws warning inconsistency found dataset. interface allows perform multiple checks get report CSV file.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/index.html","id":"join-helpers","dir":"","previous_headings":"Features ðŸš€ > Database management tools","what":"Join helpers","title":"Import Data from EDC Software","text":"primary key almost always Subject ID, join helpers added reduce code clutter. Currently, edc_left_join(), edc_right_join(), edc_full_join() supported.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/index.html","id":"shiny-browser","dir":"","previous_headings":"Features ðŸš€ > Database management tools","what":"Shiny browser","title":"Import Data from EDC Software","text":"edc_viewer() runs shiny application browses whole database. HTML interface quicker less cluttered RStudio. also allows filtering Subject ID.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/index.html","id":"swimmer-plot","dir":"","previous_headings":"Features ðŸš€ > Database management tools","what":"Swimmer Plot","title":"Import Data from EDC Software","text":"edc_swimmerplot() creates swimmer plot date variables whole database. useful find inconsistencies outliers, especially plotly interactive output.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/EDCimport-package.html","id":null,"dir":"Reference","previous_headings":"","what":"EDCimport: Import Data from EDC Software â€” EDCimport-package","title":"EDCimport: Import Data from EDC Software â€” EDCimport-package","text":"convenient toolbox import data exported Electronic Data Capture (EDC) software 'TrialMaster'.","code":""},{"path":[]},{"path":"https://danchaltiel.github.io/EDCimport/reference/EDCimport-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"EDCimport: Import Data from EDC Software â€” EDCimport-package","text":"Maintainer: Dan Chaltiel dan.chaltiel@gmail.com (ORCID)","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/assert_no_duplicate.html","id":null,"dir":"Reference","previous_headings":"","what":"Assert that a dataframe has one row per patient â€” assert_no_duplicate","title":"Assert that a dataframe has one row per patient â€” assert_no_duplicate","text":"Check duplicate column holding patient ID pipeable style.  Mostly useful joining two datasets.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/assert_no_duplicate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Assert that a dataframe has one row per patient â€” assert_no_duplicate","text":"","code":"assert_no_duplicate(df, by = NULL, id_col = get_subjid_cols())"},{"path":"https://danchaltiel.github.io/EDCimport/reference/assert_no_duplicate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Assert that a dataframe has one row per patient â€” assert_no_duplicate","text":"df dataframe (optional) grouping columns id_col name columns holding patient ID","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/assert_no_duplicate.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Assert that a dataframe has one row per patient â€” assert_no_duplicate","text":"df dataset, unchanged","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/assert_no_duplicate.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Assert that a dataframe has one row per patient â€” assert_no_duplicate","text":"","code":"if (FALSE) { # \\dontrun{ #without duplicate => no error, continue the pipeline tibble(subjid=c(1:10)) %>% assert_no_duplicate() %>% nrow()  #with duplicate => throws an error tibble(subjid=c(1:10, 1:2)) %>% assert_no_duplicate() %>% nrow()  #By groups df = tibble(subjid=rep(1:10, 4), visit=rep(c(\"V1\", \"V2\"), 2, each=10),              group=rep(c(\"A\", \"B\"), each=20)) df %>% assert_no_duplicate() #error df %>% assert_no_duplicate(by=c(visit, group)) #no error } # }"},{"path":"https://danchaltiel.github.io/EDCimport/reference/compare_databases.html","id":null,"dir":"Reference","previous_headings":"","what":"Compare multiple EDC database extractions â€” compare_databases","title":"Compare multiple EDC database extractions â€” compare_databases","text":"Compares several EDC database extractions returns:","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/compare_databases.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compare multiple EDC database extractions â€” compare_databases","text":"","code":"compare_databases(databases, fun_read = read_trialmaster, ...)"},{"path":"https://danchaltiel.github.io/EDCimport/reference/compare_databases.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compare multiple EDC database extractions â€” compare_databases","text":"databases file paths read using fun_read. Can also list edc_database objects. fun_read Reading function use databases ... arguments passed fun_read","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/compare_databases.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compare multiple EDC database extractions â€” compare_databases","text":"list table (gt object tooltips) plot (patchwork ggplots)","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/compare_databases.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Compare multiple EDC database extractions â€” compare_databases","text":"summary table detected differences datasets/columns presence summary plot differences number rows, columns, patients, rows per patient","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/compare_databases.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compare multiple EDC database extractions â€” compare_databases","text":"","code":"#list of 3 edc_databases, each being a list of multiple datasets databases = edc_example_multiple()   comparison = compare_databases(databases) #> Warning: Some database extraction dates are not unique: \"extract_2024_01_01\" comparison$table     dataset       2024-01-01 (#0)       2024-01-01 (#1)       2024-04-01     ae Added Unchanged Unchangeddata1 Added +0 -2 +0 -1data2 Added +1 -1 +1 -1data3 Added Unchanged Unchangeddata99 Absent Added Unchangedenrol Added +2 -0 +2 -0long_mixed Added Unchanged Unchangedlong_pure Added Unchanged Unchangedshort Added Unchanged Unchanged This table reflects changes in the dataset structure only,                      not in the underlying data.     comparison$figures #> NULL  #in real world, you should better use paths with a reader function: if (FALSE) { # \\dontrun{   databases = c(     \"data/MYPROJECT_ExportTemplate_xxx_SAS_XPORT_2024_06_01_12_00.zip\",     \"data/MYPROJECT_ExportTemplate_xxx_SAS_XPORT_2024_08_01_12_00.zip\",     \"data/MYPROJECT_ExportTemplate_xxx_SAS_XPORT_2024_09_01_12_00.zip\",   )   #`pw` is passed to `read_trialmaster()`   comparison = compare_databases(databases, fun_read=read_trialmaster, pw=\"the_password\") } # }"},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_clean_names.html","id":null,"dir":"Reference","previous_headings":"","what":"Clean up the names of all datasets â€” edc_clean_names","title":"Clean up the names of all datasets â€” edc_clean_names","text":"Clean names datasets database. default, converts names lowercase letters, numbers, underscores .","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_clean_names.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Clean up the names of all datasets â€” edc_clean_names","text":"","code":"edc_clean_names(database, clean_fun = NULL)"},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_clean_names.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Clean up the names of all datasets â€” edc_clean_names","text":"database edc_database object, read_trialmaster() EDCimport reading functions. clean_fun cleaning function applied column names.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_clean_names.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Clean up the names of all datasets â€” edc_clean_names","text":"edc_database object","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_clean_names.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Clean up the names of all datasets â€” edc_clean_names","text":"","code":"#db = read_trialmaster(\"filename.zip\", pw=\"xx\") db = edc_example() %>%    edc_clean_names() #> Warning: Option \"edc_lookup\" has been overwritten. names(db$enrol) #> [1] \"subjid\"     \"age\"        \"enrol_date\" \"arm\"        \"crfname\"    #> [6] \"crfstat\""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_crf_plot.html","id":null,"dir":"Reference","previous_headings":"","what":"Show the current CRF status distribution â€” edc_crf_plot","title":"Show the current CRF status distribution â€” edc_crf_plot","text":"Generate barplot showing distribution CRF status (Complete, Incomplete, ...) dataset database.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_crf_plot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Show the current CRF status distribution â€” edc_crf_plot","text":"","code":"edc_crf_plot(   crfstat_col = \"CRFSTAT\",   ...,   details = FALSE,   pal = edc_pal_crf(),   reverse = FALSE,   x_label = \"{dataset}\",   treat_as_worst = NULL,   datasets = get_datasets(),   lookup = edc_lookup() )  edc_pal_crf()"},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_crf_plot.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Show the current CRF status distribution â€” edc_crf_plot","text":"ggsci:::ggsci_db$lancet[[\"lanonc\"]] %>% dput()","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_crf_plot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Show the current CRF status distribution â€” edc_crf_plot","text":"crfstat_col column name CRF status ... unused details whether show CRF status levels. FALSE (default), recode status \"Complete\", \"Incomplete\", \"Data\". pal palette, defaulting helper EDCimport:::edc_pal_crf(). names give CRF status levels, \"best\" \"worst\". plot ordered \"worst\" level. reverse whether reverse CRF status level order. x_label glue pattern determining tick label x axis. Available variables ones edc_lookup(): c(\"dataset\", \"nrow\", \"ncol\", \"n_id\", \"rows_per_id\", \"crfname\"). treat_as_worst regex levels treated worst ordering. datasets, lookup internal","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_crf_plot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Show the current CRF status distribution â€” edc_crf_plot","text":"ggplot","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_crf_plot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Show the current CRF status distribution â€” edc_crf_plot","text":"","code":"if (FALSE) { # \\dontrun{ #import a TM database and use load_database(), then: edc_crf_plot() + ggtitle(date_extraction) edc_crf_plot(reverse=TRUE) edc_crf_plot(details=TRUE, treat_as_worst=\"No Data\") edc_crf_plot(x_label=\"{crfname} (N={n_id}, n={nrow})\")  p = edc_crf_plot(details=TRUE) p$data$crfstat %>% unique() #> [1] \"Incomplete\"        \"No Data Locked\"    \"No Data\"           \"Signed\"            #> [5] \"Partial Monitored\" \"Monitored\"         \"Complete Locked\"   \"Complete\"  } # }"},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_data_warn.html","id":null,"dir":"Reference","previous_headings":"","what":"Standardized warning system â€” edc_data_warn","title":"Standardized warning system â€” edc_data_warn","text":"checking data, filter dataset get problematic rows.  , use either: edc_data_warn() generate standardized warning can forwarded datamanager. edc_data_stop() abort script problem serious. time edc_data_warn used, warning saved internally summary warnings can retrieved using edc_data_warnings.  result can saved Excel file using save_edc_data_warnings().","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_data_warn.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Standardized warning system â€” edc_data_warn","text":"","code":"edc_data_warn(   df,   message,   ...,   issue_n = \"xx\",   max_subjid = 5,   csv_path = FALSE,   envir = parent.frame(),   col_subjid = get_subjid_cols() )  edc_data_stop(df, message, ..., issue_n, max_subjid, csv_path, envir, col_subjid)  edc_data_warnings()"},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_data_warn.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Standardized warning system â€” edc_data_warn","text":"df filtered dataframe message message. Can use cli formats. df can accessed using .data special keyword (see example) ... unused issue_n identifying row number max_subjid max number subject ID show message csv_path path save df csv file can shared DM details. envir environment evaluate message . col_subjid column name subject ID. Set NULL ignore.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_data_warn.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Standardized warning system â€” edc_data_warn","text":"df invisibly","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_data_warn.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Standardized warning system â€” edc_data_warn","text":"","code":"library(dplyr) #>  #> Attaching package: â€˜dplyrâ€™ #> The following objects are masked from â€˜package:statsâ€™: #>  #>     filter, lag #> The following objects are masked from â€˜package:baseâ€™: #>  #>     intersect, setdiff, setequal, union db = edc_example() #> Warning: Option \"edc_lookup\" has been overwritten. load_database(db) enrol %>%    filter(age>70) %>%    edc_data_warn(\"Age should not be >70\", issue_n=1) #> Warning: Datasets from this lookup are not available in the global environment. #> â„¹ Did you forget to use `EDCimport::load_database(db)` to load the tables? #> This warning is displayed once per session. #> Warning: Issue #01: Age should not be >70 (2 patients: #9 and #12)  enrol %>%    filter(age<25) %>%    edc_data_warn(\"Age should not be <25\", issue_n=2) #> Warning: Issue #02: Age should not be <25 (1 patient: #18)  data1 %>%    filter(n()>1, .by=subjid) %>%    edc_data_warn(\"There are duplicated patients in `data1` ({nrow(.data)} rows)\", issue_n=3) #> Warning: Issue #03: There are duplicated patients in `data1` (100 rows) (50 patients: #> #1, #2, #3, #4, #5, â€¦)  enrol %>%    filter(age<25) %>%    edc_data_warn(\"Age should not be <25\", issue_n=NULL) #> Warning: Age should not be <25 (1 patient: #18)    edc_data_warnings() #> # A tibble: 3 Ã— 5 #>   issue_n message                                          subjid data     type  #>   <chr>   <chr>                                            <list> <list>   <chr> #> 1 01      Age should not be >70                            <chr>  <tibble> WARN  #> 2 02      Age should not be <25                            <chr>  <tibble> WARN  #> 3 03      There are duplicated patients in `data1` (100 râ€¦ <chr>  <tibble> WARN   if (FALSE) { # \\dontrun{ enrol %>%    filter(age<25) %>%    edc_data_warn(\"Age should not be <25\", csv_path=\"check/check_age_25.csv\")    enrol %>%    filter(age<25) %>%    edc_data_stop(\"Age should *never* be <25\") } # }"},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_database.html","id":null,"dir":"Reference","previous_headings":"","what":"EDCimport Database â€” edc_database","title":"EDCimport Database â€” edc_database","text":"class object represents database, result EDCimport reading function. print() method.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_database.html","id":"functions-returning-edc-database-objects","dir":"Reference","previous_headings":"","what":"Functions returning edc_database objects","title":"EDCimport Database â€” edc_database","text":"per now, reading functions : read_trialmaster(), read_all_sas(), read_all_xpt(), read_all_csv().","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_database.html","id":"structure","dir":"Reference","previous_headings":"","what":"Structure","title":"EDCimport Database â€” edc_database","text":"usually useful query , edc_database object named list containing: datasets source files datetime_extraction date_extraction inferred date data extraction .lookup temporary copy lookup table","code":""},{"path":[]},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_db_to_excel.html","id":null,"dir":"Reference","previous_headings":"","what":"Save the database as an Excel file â€” edc_db_to_excel","title":"Save the database as an Excel file â€” edc_db_to_excel","text":"RStudio good showing data, can convenient browse database using MS Excel. function turns whole TM export (named list datasets) Excel workbook, one tab dataset. Use edc_db_to_excel() create file edc_browse_excel() open .","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_db_to_excel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Save the database as an Excel file â€” edc_db_to_excel","text":"","code":"edc_db_to_excel(   filename = tempfile(fileext = \".xlsx\"),   ...,   datasets = get_datasets(),   overwrite = FALSE,   open = FALSE )  edc_browse_excel()"},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_db_to_excel.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Save the database as an Excel file â€” edc_db_to_excel","text":"filename path Excel output file. Default temporary file. Use special value TRUE save \"data/database_{date_extraction}.xlsx\". ... unused datasets named list dataframes. Default TM export. overwrite whether overwrite existing file. Default FALSE. open whether open Excel file afterward. Default FALSE.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_db_to_excel.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Save the database as an Excel file â€” edc_db_to_excel","text":"nothing","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_db_to_excel.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Save the database as an Excel file â€” edc_db_to_excel","text":"","code":"if (FALSE) { # \\dontrun{   db = edc_example()   load_database(db)     edc_db_to_excel() #default arguments are usually OK   edc_db_to_excel(filename=TRUE) } # }"},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_example.html","id":null,"dir":"Reference","previous_headings":"","what":"Example database â€” edc_example","title":"Example database â€” edc_example","text":"list tables simulates extraction clinical database. Used EDCimport examples tests.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_example.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Example database â€” edc_example","text":"","code":"edc_example(N = 50, seed = 42, outdated = FALSE)"},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_example.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Example database â€” edc_example","text":"N number patients seed random seed outdated whether simulate times data extraction date","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_example.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Example database â€” edc_example","text":"list tables class edc_database.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_example_multiple.html","id":null,"dir":"Reference","previous_headings":"","what":"Example for compare_databases() â€” edc_example_multiple","title":"Example for compare_databases() â€” edc_example_multiple","text":"functions returns list 3 edc_example() instances, slightly different one another.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_example_multiple.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Example for compare_databases() â€” edc_example_multiple","text":"","code":"edc_example_multiple()"},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_find_value.html","id":null,"dir":"Reference","previous_headings":"","what":"Search the whole database â€” edc_find_value","title":"Search the whole database â€” edc_find_value","text":"Find keyword columns values, datasets database.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_find_value.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Search the whole database â€” edc_find_value","text":"","code":"edc_find_value(   keyword,   ignore_case = TRUE,   data = get_datasets(),   lookup = edc_lookup() )  edc_find_column(keyword, ignore_case = TRUE, lookup = edc_lookup())"},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_find_value.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Search the whole database â€” edc_find_value","text":"keyword keyword search . Regular expressions supported edc_find_column. ignore_case Logical. TRUE (default), search ignore case differences. data list datasets. lookup lookup table.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_find_value.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Search the whole database â€” edc_find_value","text":"tibble","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_find_value.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Search the whole database â€” edc_find_value","text":"","code":"db = edc_example() #> Warning: Option \"edc_lookup\" has been overwritten. load_database(db)  edc_find_value(\"respi\") #> # A tibble: 8 Ã— 5 #>   subjid dataset column column_label value                                       #>   <chr>  <chr>   <chr>  <chr>        <chr>                                       #> 1 10     ae      aesoc  AE SOC       Respiratory, thoracic and mediastinal disoâ€¦ #> 2 13     ae      aesoc  AE SOC       Respiratory, thoracic and mediastinal disoâ€¦ #> 3 13     ae      aesoc  AE SOC       Respiratory, thoracic and mediastinal disoâ€¦ #> 4 17     ae      aesoc  AE SOC       Respiratory, thoracic and mediastinal disoâ€¦ #> 5 22     ae      aesoc  AE SOC       Respiratory, thoracic and mediastinal disoâ€¦ #> 6 29     ae      aesoc  AE SOC       Respiratory, thoracic and mediastinal disoâ€¦ #> 7 44     ae      aesoc  AE SOC       Respiratory, thoracic and mediastinal disoâ€¦ #> 8 47     ae      aesoc  AE SOC       Respiratory, thoracic and mediastinal disoâ€¦ edc_find_value(2010) #> # A tibble: 700 Ã— 5 #>    subjid dataset column column_label    value      #>    <chr>  <chr>   <chr>  <chr>           <chr>      #>  1 1      data1   date1  Date at visit 1 2010-04-26 #>  2 1      data1   date1  Date at visit 1 2010-04-26 #>  3 2      data1   date1  Date at visit 1 2010-04-15 #>  4 2      data1   date1  Date at visit 1 2010-04-15 #>  5 3      data1   date1  Date at visit 1 2010-05-08 #>  6 3      data1   date1  Date at visit 1 2010-05-08 #>  7 4      data1   date1  Date at visit 1 2010-04-29 #>  8 4      data1   date1  Date at visit 1 2010-04-29 #>  9 5      data1   date1  Date at visit 1 2010-04-23 #> 10 5      data1   date1  Date at visit 1 2010-04-23 #> # â„¹ 690 more rows  edc_find_column(\"ad\") #> # A tibble: 1 Ã— 4 #>   dataset crfname        names labels   #>   <chr>   <chr>          <chr> <chr>    #> 1 ae      Adverse events aegr  AE grade edc_find_column(\"date\")  #> # A tibble: 11 Ã— 4 #>    dataset crfname names      labels            #>    <chr>   <chr>   <chr>      <chr>             #>  1 data1   data1   date1      Date at visit 1   #>  2 data1   data1   date2      Date at visit 2   #>  3 data1   data1   date3      Date at visit 3   #>  4 data2   data2   date4      Date at visit 4   #>  5 data2   data2   date5      Date at visit 5   #>  6 data2   data2   date6      Date at visit 6   #>  7 data3   data3   date7      Date at visit 7   #>  8 data3   data3   date8      Date at visit 8   #>  9 data3   data3   date9      Date at visit 9   #> 10 data3   data3   date10     Date at visit 10  #> 11 enrol   enrol   enrol_date Date of enrolment #with regex edc_find_column(\"\\\\d\") #> # A tibble: 16 Ã— 4 #>    dataset    crfname                  names  labels           #>    <chr>      <chr>                    <chr>  <chr>            #>  1 long_pure  long data                val1a  val1a            #>  2 long_pure  long data                val2a  val2a            #>  3 data1      data1                    date1  Date at visit 1  #>  4 data1      data1                    date2  Date at visit 2  #>  5 data1      data1                    date3  Date at visit 3  #>  6 long_mixed both short and long data long1  long1            #>  7 long_mixed both short and long data long2  long2            #>  8 data2      data2                    date4  Date at visit 4  #>  9 data2      data2                    date5  Date at visit 5  #> 10 data2      data2                    date6  Date at visit 6  #> 11 data3      data3                    date7  Date at visit 7  #> 12 data3      data3                    date8  Date at visit 8  #> 13 data3      data3                    date9  Date at visit 9  #> 14 data3      data3                    date10 Date at visit 10 #> 15 short      short data               val1   val1             #> 16 short      short data               val2   val2             edc_find_column(\"\\\\(\") #you need to escape special characters #> # A tibble: 1 Ã— 4 #>   dataset crfname names labels      #>   <chr>   <chr>   <chr> <chr>       #> 1 enrol   enrol   age   Age (years)"},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_inform_code.html","id":null,"dir":"Reference","previous_headings":"","what":"Shows how many code you wrote â€” edc_inform_code","title":"Shows how many code you wrote â€” edc_inform_code","text":"Shows many code wrote","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_inform_code.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Shows how many code you wrote â€” edc_inform_code","text":"","code":"edc_inform_code(main = \"main.R\", Rdir = \"R/\")"},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_inform_code.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Shows how many code you wrote â€” edc_inform_code","text":"main main R file, sources ones Rdir R directory, sourced R files located","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_inform_code.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Shows how many code you wrote â€” edc_inform_code","text":"Nothing","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_left_join.html","id":null,"dir":"Reference","previous_headings":"","what":"Join within the EDCimport framework â€” edc_left_join","title":"Join within the EDCimport framework â€” edc_left_join","text":"Perform join default Subject ID default suffix name y dataset. See [dplyr::mutate-joins] description join logic.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_left_join.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Join within the EDCimport framework â€” edc_left_join","text":"","code":"edc_left_join(   x,   y,   by = NULL,   suffix = NULL,   cols = everything(),   remove_dups = FALSE )"},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_left_join.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Join within the EDCimport framework â€” edc_left_join","text":"x, y Data frames join key join , character. Defaults get_subjid_cols() suffix disambiguation suffix. Defaults actual name y dataset. cols <tidy-select> columns select y joining. remove_dups Whether remove columns y already exist x.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_left_join.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Join within the EDCimport framework â€” edc_left_join","text":"dataframe","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_left_join.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Join within the EDCimport framework â€” edc_left_join","text":"","code":"db = edc_example() #> Warning: Option \"edc_lookup\" has been overwritten. load_database(db) data1$common = data2$common = \"Common\" x = enrol %>%    edc_left_join(data2) %>%    edc_right_join(data1)    #crfname get a suffix, common  names(x) #>  [1] \"subjid\"        \"age\"           \"enrol_date\"    \"arm\"           #>  [5] \"crfname\"       \"crfstat\"       \"date4\"         \"date5\"         #>  [9] \"date6\"         \"crfname_data2\" \"crfstat_data2\" \"common\"        #> [13] \"date1\"         \"date2\"         \"date3\"         \"x\"             #> [17] \"crfname_data1\" \"crfstat_data1\" \"common_data1\""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_lookup.html","id":null,"dir":"Reference","previous_headings":"","what":"Retrieve the lookup table from options â€” edc_lookup","title":"Retrieve the lookup table from options â€” edc_lookup","text":"Retrieve lookup table options","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_lookup.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Retrieve the lookup table from options â€” edc_lookup","text":"","code":"edc_lookup(..., check = TRUE)"},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_lookup.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Retrieve the lookup table from options â€” edc_lookup","text":"... passed dplyr::arrange() check whether check internal consistency","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_lookup.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Retrieve the lookup table from options â€” edc_lookup","text":"lookup dataframe summarizing database import","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_lookup.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Retrieve the lookup table from options â€” edc_lookup","text":"","code":"db = edc_example() #> Warning: Option \"edc_lookup\" has been overwritten. load_database(db) edc_lookup() #> â”€â”€ Lookup table - EDCimport example (extraction of 2024-01-01) - EDCimport v0.6. #>   dataset     nrow  ncol  n_id rows_per_id crfname                  #>   <chr>      <dbl> <dbl> <int>       <dbl> <chr>                    #> 1 long_pure    150     4    50         3   long data                #> 2 data1        100     7    50         2   data1                    #> 3 long_mixed   100     6    50         2   both short and long data #> 4 data2         50     6    50         1   data2                    #> 5 data3         50     7    50         1   data3                    #> 6 enrol         50     6    50         1   enrol                    #> 7 short         50     5    50         1   short data               #> 8 ae           175     7    48         3.6 Adverse events           edc_lookup(dataset) #> â”€â”€ Lookup table - EDCimport example (extraction of 2024-01-01) - EDCimport v0.6. #>   dataset     nrow  ncol  n_id rows_per_id crfname                  #>   <chr>      <dbl> <dbl> <int>       <dbl> <chr>                    #> 1 ae           175     7    48         3.6 Adverse events           #> 2 data1        100     7    50         2   data1                    #> 3 data2         50     6    50         1   data2                    #> 4 data3         50     7    50         1   data3                    #> 5 enrol         50     6    50         1   enrol                    #> 6 long_mixed   100     6    50         2   both short and long data #> 7 long_pure    150     4    50         3   long data                #> 8 short         50     5    50         1   short data"},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_options.html","id":null,"dir":"Reference","previous_headings":"","what":"Set global options for EDCimport â€” edc_options","title":"Set global options for EDCimport â€” edc_options","text":"Use function manage EDCimport parameters globally taking advantage autocompletion.  Use edc_peek_options() see option currently set edc_reset_options() set options back default.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_options.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set global options for EDCimport â€” edc_options","text":"","code":"edc_options(   ...,   trialmaster_pw,   path_7zip,   edc_lookup,   edc_subjid_ref,   edc_plotly,   edc_fct_yesno,   edc_cols_subjid,   edc_cols_meta,   edc_cols_id,   edc_cols_crfname,   edc_meta_cols_pct,   edc_warn_max_subjid,   edc_read_verbose,   edc_correction_verbose,   edc_get_key_cols_verbose,   edc_lookup_overwrite_warn,   .local = FALSE )"},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_options.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set global options for EDCimport â€” edc_options","text":"... unused trialmaster_pw password trialmaster zip archive. instance, can use edc_options(trialmaster_pw=\"my_pwd\") console per session, write password clear R code path_7zip path 7zip executable. Default \"C:/Program Files/7-Zip/\". edc_lookup (Internal) reference lookup table (usually .lookup). usually changed manually. edc_subjid_ref used edc_warn_patient_diffs vector reference subject IDs. usually write edc_options(edc_subjid_ref=enrolres$subjid). edc_plotly used edc_swimmerplot whether use plotly visualize plot. edc_fct_yesno used fct_yesno list values considered Yes/values. Defaults get_yesno_lvl(). edc_cols_subjid, edc_cols_meta name columns holding subject id (default c(\"ptno\", \"subjid\")) CRF form name (default c(\"crfname\")). case-insensitive. edc_cols_id, edc_cols_crfname deprecated edc_meta_cols_pct minimal proportion datasets column reach considered \"meta\" edc_warn_max_subjid max number subject IDs show edc_data_warn edc_read_verbose, edc_correction_verbose, edc_get_key_cols_verbose verbosity output functions read_trialmaster read_all_xpt, manual_correction. example, set edc_options(edc_read_verbose=0) silence first 2. edc_lookup_overwrite_warn default TRUE. Whether warning overwriting .lookup (like reading 2 databases successively) .local TRUE, effect apply local frame (internally using rlang::local_options())","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_options.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Set global options for EDCimport â€” edc_options","text":"Nothing, called side effects","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_patient_gridplot.html","id":null,"dir":"Reference","previous_headings":"","what":"Patient gridplot â€” edc_patient_gridplot","title":"Patient gridplot â€” edc_patient_gridplot","text":"Draw gridplot giving, patient dataset, whether patient present dataset. Data drawn get_datasets.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_patient_gridplot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Patient gridplot â€” edc_patient_gridplot","text":"","code":"edc_patient_gridplot(   sort_rows = TRUE,   sort_cols = TRUE,   gradient = FALSE,   axes_flip = FALSE,   show_grid = TRUE,   preprocess = NULL,   palette = c(Yes = \"#00468BFF\", No = \"#ED0000FF\"),   datasets = get_datasets(),   lookup = edc_lookup() )"},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_patient_gridplot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Patient gridplot â€” edc_patient_gridplot","text":"sort_rows whether sort patients \"present datasets\" \"present least datasets\" sort_cols whether sort datasets \"containing patients\" \"containing least patients\" gradient whether add color gradient repeating measures axes_flip whether flip axes, patients Y axis datasets X axis show_grid whether show grid preprocess function preprocess patient ID, e.g. .numeric, custom function string replacement palette colors use datasets, lookup internal","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_patient_gridplot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Patient gridplot â€” edc_patient_gridplot","text":"ggplot object","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_patient_gridplot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Patient gridplot â€” edc_patient_gridplot","text":"","code":"if (FALSE) { # \\dontrun{   tm = read_trialmaster(\"path/to/archive.zip\")   load_database(db)   edc_patient_gridplot(sort_rows=FALSE, sort_cols=FALSE)   edc_patient_gridplot(axes_flip=TRUE, show_grid=TRUE,                        preprocess=~str_remove(.x, \"\\\\D*\")) #remove all non-digits } # }"},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_peek_options.html","id":null,"dir":"Reference","previous_headings":"","what":"See which EDCimport option is currently set â€” edc_peek_options","title":"See which EDCimport option is currently set â€” edc_peek_options","text":"See EDCimport option currently set","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_peek_options.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"See which EDCimport option is currently set â€” edc_peek_options","text":"","code":"edc_peek_options(keep_null = FALSE)"},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_peek_options.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"See which EDCimport option is currently set â€” edc_peek_options","text":"keep_null set TRUE get list","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_peek_options.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"See which EDCimport option is currently set â€” edc_peek_options","text":"named list EDCimport options","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_population_plot.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot the populations â€” edc_population_plot","title":"Plot the populations â€” edc_population_plot","text":"RCT, usually several populations analysis, function allow show patient population graphically.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_population_plot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot the populations â€” edc_population_plot","text":"","code":"edc_population_plot(x, id_per_row = 50, ref = \"first\")"},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_population_plot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot the populations â€” edc_population_plot","text":"x named list subject ID, numeric factor. id_per_row number patients per rows. ref whole population. Default first member x.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_population_plot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot the populations â€” edc_population_plot","text":"ggplot","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_population_plot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot the populations â€” edc_population_plot","text":"","code":"#in real word code, use filter and pull to get these vectors pop_total = c(1:180) %>% setdiff(55) #screen failure, no patient 55 pop_itt = pop_total %>% setdiff(10) #patient 10 has had the wrong treatment pop_safety = pop_total %>% setdiff(c(40,160)) #patients 40 and 160 didn't receive any treatment pop_m_itt = pop_total %>% setdiff(c(40,160,80)) #patient 80 had a wrong inclusion criterion pop_evaluable = pop_total %>% setdiff(c(40,160,101,147,186)) #patients with no recist evaluation  l = list(   \"Total population\"=pop_total,   \"ITT population\"=pop_itt,   \"Safety population\"=pop_safety,   \"mITT population\"=pop_m_itt,   \"Evaluable population\"=pop_evaluable ) edc_population_plot(l)  edc_population_plot(l[-1], ref=pop_total)  edc_population_plot(l, ref=1:200)  edc_population_plot(l, id_per_row=60)"},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_reset_options.html","id":null,"dir":"Reference","previous_headings":"","what":"Reset all EDCimport options â€” edc_reset_options","title":"Reset all EDCimport options â€” edc_reset_options","text":"Reset EDCimport options","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_reset_options.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reset all EDCimport options â€” edc_reset_options","text":"","code":"edc_reset_options(   except = c(\"edc_lookup\", \"trialmaster_pw\", \"path_7zip\"),   quiet = FALSE )"},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_reset_options.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reset all EDCimport options â€” edc_reset_options","text":"except options reset default quiet set TRUE remove message.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_reset_options.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Reset all EDCimport options â€” edc_reset_options","text":"Nothing, called side effects","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_split_mixed.html","id":null,"dir":"Reference","previous_headings":"","what":"Split mixed datasets â€” edc_split_mixed","title":"Split mixed datasets â€” edc_split_mixed","text":"Split mixed tables, .e. tables hold long data (N values per patient) short data (one value per patient, duplicated N lines), one long table one short table.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_split_mixed.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Split mixed datasets â€” edc_split_mixed","text":"","code":"edc_split_mixed(   database,   datasets = everything(),   ...,   ignore_cols = NULL,   verbose = FALSE )"},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_split_mixed.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Split mixed datasets â€” edc_split_mixed","text":"database edc_database object, read_trialmaster() EDCimport reading functions. datasets <tidy-select> datasets split database ... used, ensure arguments named ignore_cols columns ignore long tables. Default getOption(\"edc_cols_crfname\", \"CRFNAME\"). Case-insensitive. Avoid splitting tables useless columns. verbose whether print informations process.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_split_mixed.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Split mixed datasets â€” edc_split_mixed","text":"edc_database object","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_split_mixed.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Split mixed datasets â€” edc_split_mixed","text":"","code":"#db = read_trialmaster(\"filename.zip\", pw=\"xx\") db = edc_example() %>%    edc_split_mixed(c(ae, starts_with(\"long\")),                    ignore_cols=\"crfstat\") #> Warning: Option \"edc_lookup\" has been overwritten.    names(db) #>  [1] \"enrol\"               \"data1\"               \"data2\"               #>  [4] \"data3\"               \"short\"               \"long_pure\"           #>  [7] \"long_mixed\"          \"ae\"                  \"datetime_extraction\" #> [10] \"date_extraction\"     \".lookup\"             \"ae_short\"            #> [13] \"ae_long\"             \"long_mixed_short\"    \"long_mixed_long\"     edc_lookup() #> â”€â”€ Lookup table - EDCimport example (extraction of 2024-01-01) - EDCimport v0.6. #>    dataset           nrow  ncol  n_id rows_per_id crfname                  #>    <chr>            <dbl> <dbl> <int>       <dbl> <chr>                    #>  1 long_pure          150     4    50         3   long data                #>  2 data1              100     7    50         2   data1                    #>  3 long_mixed         100     6    50         2   both short and long data #>  4 long_mixed_long    100     4    50         2   both short and long data #>  5 data2               50     6    50         1   data2                    #>  6 data3               50     7    50         1   data3                    #>  7 enrol               50     6    50         1   enrol                    #>  8 long_mixed_short    50     3    50         1   both short and long data #>  9 short               50     5    50         1   short data               #> 10 ae                 175     7    48         3.6 Adverse events           #> 11 ae_long            175     5    48         3.6 Adverse events           #> 12 ae_short            48     3    48         1   Adverse events            db$ae #`aesoc`, `aegr`, and `sae` are long, but `n_ae` is short #> # A tibble: 175 Ã— 7 #>    subjid crfname        aesoc                          aegr  n_ae sae   crfstat #>  *  <int> <chr>          <chr>                         <int> <int> <fct> <chr>   #>  1      1 Adverse events Endocrine disorders               2     5 No    Incompâ€¦ #>  2      1 Adverse events Gastrointestinal disorders        2     5 No    Compleâ€¦ #>  3      1 Adverse events Reproductive system and breaâ€¦     2     5 No    Compleâ€¦ #>  4      1 Adverse events Renal and urinary disorders       3     5 No    Compleâ€¦ #>  5      1 Adverse events Neoplasms benign, malignant â€¦     1     5 No    Compleâ€¦ #>  6      2 Adverse events Vascular disorders                3     5 No    Incompâ€¦ #>  7      2 Adverse events Nervous system disorders          3     5 No    Compleâ€¦ #>  8      2 Adverse events Injury, poisoning and procedâ€¦     1     5 No    Compleâ€¦ #>  9      2 Adverse events Hepatobiliary disorders           1     5 No    Compleâ€¦ #> 10      2 Adverse events Injury, poisoning and procedâ€¦     2     5 No    Compleâ€¦ #> # â„¹ 165 more rows  db$ae_short #> # A tibble: 48 Ã— 3 #>    subjid crfname         n_ae #>     <int> <chr>          <int> #>  1      1 Adverse events     5 #>  2      2 Adverse events     5 #>  3      3 Adverse events     2 #>  4      4 Adverse events     4 #>  5      5 Adverse events     3 #>  6      6 Adverse events     3 #>  7      7 Adverse events     4 #>  8      8 Adverse events     1 #>  9      9 Adverse events     4 #> 10     10 Adverse events     4 #> # â„¹ 38 more rows db$ae_long #> # A tibble: 175 Ã— 5 #>    subjid aesoc                                               aegr sae   crfstat #>     <int> <chr>                                              <int> <fct> <chr>   #>  1      1 Endocrine disorders                                    2 No    Incompâ€¦ #>  2      1 Gastrointestinal disorders                             2 No    Compleâ€¦ #>  3      1 Reproductive system and breast disorders               2 No    Compleâ€¦ #>  4      1 Renal and urinary disorders                            3 No    Compleâ€¦ #>  5      1 Neoplasms benign, malignant and unspecified (inclâ€¦     1 No    Compleâ€¦ #>  6      2 Vascular disorders                                     3 No    Incompâ€¦ #>  7      2 Nervous system disorders                               3 No    Compleâ€¦ #>  8      2 Injury, poisoning and procedural complications         1 No    Compleâ€¦ #>  9      2 Hepatobiliary disorders                                1 No    Compleâ€¦ #> 10      2 Injury, poisoning and procedural complications         2 No    Compleâ€¦ #> # â„¹ 165 more rows"},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_swimmerplot.html","id":null,"dir":"Reference","previous_headings":"","what":"Swimmer plot of all dates columns â€” edc_swimmerplot","title":"Swimmer plot of all dates columns â€” edc_swimmerplot","text":"Join tables id date columns build ggplot (plotly plotly=TRUE) showing dates subject.  allows outliers easily identified.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_swimmerplot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Swimmer plot of all dates columns â€” edc_swimmerplot","text":"","code":"edc_swimmerplot(   ...,   include = NULL,   exclude = NULL,   group = NULL,   origin = NULL,   data_list = get_datasets(),   id_subset = \"all\",   id_sort = FALSE,   id_cols = get_subjid_cols(),   time_unit = c(\"days\", \"weeks\", \"months\", \"years\"),   origin_fun = \"min\",   aes_color = c(\"variable\", \"label\"),   plotly = getOption(\"edc_plotly\", FALSE),   id = \"deprecated\",   id_lim = \"deprecated\",   .lookup = \"deprecated\" )"},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_swimmerplot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Swimmer plot of all dates columns â€” edc_swimmerplot","text":"... used include, exclude character vector variables exclude/include, form dataset$column. Can regex (apart $ symbols automatically escaped). Case-insensitive. group grouping variable, given \"dataset$column\". origin variable consider time 0, given \"dataset$column\". data_list named list data.frames get dates . Default get_datasets, retrieve raw datasets. id_subset subjects include plot. id_sort whether sort subjects date (time). id_cols subject identifiers columns. Identifiers coerced numeric possible. See get_subjid_cols needed. time_unit origin!=NULL, unit measure time. One c(\"days\", \"weeks\", \"months\", \"years\"). origin_fun function summarise origin date id level needed. named, least meaningful function name (see example \"summarised origin\". aes_color either variable (\"{dataset} - {column}\") label (column label). plotly whether use {plotly} get interactive plot. id deprecated id_lim deprecated .lookup deprecated","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_swimmerplot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Swimmer plot of all dates columns â€” edc_swimmerplot","text":"either plotly ggplot","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_swimmerplot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Swimmer plot of all dates columns â€” edc_swimmerplot","text":"","code":"#db = read_trialmaster(\"filename.zip\", pw=\"xx\") db = edc_example() #> Warning: Option \"edc_lookup\" has been overwritten. load_database(db) edc_swimmerplot(id_lim=c(5,45))   #fixed origin edc_swimmerplot(origin=\"enrol$enrol_date\", time_unit=\"months\",                  include=c(\"data1\", \"data3\"),                 exclude=c(\"DATA1$DATE2\", \"data3$date\\\\d\\\\d\"),                  id_sort=TRUE)   #summarised origin edc_swimmerplot(origin=\"data1$date2\", time_unit=\"months\",                  origin_fun=c(\"average\"=~mean(.x, na.rm=TRUE)),                 include=c(\"data1\", \"data3\"),                 exclude=c(\"DATA1$DATE2\", \"data3$date\\\\d\\\\d\"),                  id_sort=TRUE)   #id_subset edc_swimmerplot(group=\"enrol$arm\", id_subset=1:10, aes_color=\"label\")   if (FALSE) { # \\dontrun{ p = edc_swimmerplot(plotly=TRUE) save_plotly(p, \"edc_swimmerplot.html\") } # }"},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_unify_subjid.html","id":null,"dir":"Reference","previous_headings":"","what":"Harmonize the subject ID of the database â€” edc_unify_subjid","title":"Harmonize the subject ID of the database â€” edc_unify_subjid","text":"Turns subject ID columns datasets factor containing levels subjects database. Avoid problems joining tables, checks can performed levels. See vignette(\"postprocessing\") real-life case.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_unify_subjid.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Harmonize the subject ID of the database â€” edc_unify_subjid","text":"","code":"edc_unify_subjid(   database,   preprocess = NULL,   mode = c(\"factor\", \"numeric\"),   col_subjid = NULL )"},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_unify_subjid.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Harmonize the subject ID of the database â€” edc_unify_subjid","text":"database edc_database object, read_trialmaster() EDCimport reading functions. preprocess optional function modify subject ID column (character level). Default behavior remove trailing zeros numeric. mode output type subject ID columns col_subjid names subject ID columns (character)","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_unify_subjid.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Harmonize the subject ID of the database â€” edc_unify_subjid","text":"database, subject id modified","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_unify_subjid.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Harmonize the subject ID of the database â€” edc_unify_subjid","text":"","code":"db = edc_example() #> Warning: Option \"edc_lookup\" has been overwritten. db$enrol$subjid %>% head()  #double vector #> [1] 1 2 3 4 5 6  db2 = edc_unify_subjid(db) db2$enrol$subjid %>% head() #factor with 50 levels #> [1] 1 2 3 4 5 6 #> 50 Levels: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 ... 50  db3 = edc_unify_subjid(db, preprocess=function(x) paste0(\"#\", x)) db3$enrol$subjid %>% head() #> [1] #1 #2 #3 #4 #5 #6 #> 50 Levels: #1 #2 #3 #4 #5 #6 #7 #8 #9 #10 #11 #12 #13 #14 #15 #16 #17 ... #50  #use numeric mode to get a numeric output db4 = edc_unify_subjid(db, preprocess=function(x) as.numeric(x)+1, mode=\"numeric\") db4$enrol$subjid %>% head() #> [1] 2 3 4 5 6 7"},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_viewer.html","id":null,"dir":"Reference","previous_headings":"","what":"Shiny data explorer â€” edc_viewer","title":"Shiny data explorer â€” edc_viewer","text":"Run Shiny application allows browse datasets.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_viewer.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Shiny data explorer â€” edc_viewer","text":"","code":"edc_viewer(   data = NULL,   ...,   background = TRUE,   title = NULL,   port = 1209,   replace = FALSE )"},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_viewer.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Shiny data explorer â€” edc_viewer","text":"data list dataframes view. NULL, defaults last datasets loaded using EDCimport functions. ... unused background Whether app run background process. title app title, header tab label. port TCP port application listen . replace whether replace previously running app port.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_warn_extraction_date.html","id":null,"dir":"Reference","previous_headings":"","what":"Warn if extraction is too old â€” edc_warn_extraction_date","title":"Warn if extraction is too old â€” edc_warn_extraction_date","text":"Warn extraction old","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_warn_extraction_date.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Warn if extraction is too old â€” edc_warn_extraction_date","text":"","code":"edc_warn_extraction_date(max_days = 30)"},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_warn_extraction_date.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Warn if extraction is too old â€” edc_warn_extraction_date","text":"max_days max acceptable age data","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_warn_extraction_date.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Warn if extraction is too old â€” edc_warn_extraction_date","text":"nothing","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_warn_extraction_date.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Warn if extraction is too old â€” edc_warn_extraction_date","text":"","code":"db = edc_example() #> Warning: Option \"edc_lookup\" has been overwritten. load_database(db) edc_warn_extraction_date() #> Error in edc_warn_extraction_date(): object 'datetime_extraction' not found"},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_warn_patient_diffs.html","id":null,"dir":"Reference","previous_headings":"","what":"Check the validity of the subject ID column â€” edc_warn_patient_diffs","title":"Check the validity of the subject ID column â€” edc_warn_patient_diffs","text":"Compare subject ID vector study's reference subject ID (usually something like enrolres$subjid), warn patient missing extra. check_subjid() old, deprecated name.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_warn_patient_diffs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check the validity of the subject ID column â€” edc_warn_patient_diffs","text":"","code":"edc_warn_patient_diffs(   x,   ref = getOption(\"edc_subjid_ref\"),   issue_n = \"xx\",   data_name = NULL,   col_subjid = get_subjid_cols() )"},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_warn_patient_diffs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check the validity of the subject ID column â€” edc_warn_patient_diffs","text":"x subject ID vector check, dataframe ID column guessed ref reference subject ID. usually set edc_options(edc_subjid_ref=xxx). See example. issue_n identifying row number data_name name data (warning message) col_subjid name subject ID column x dataframe.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_warn_patient_diffs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check the validity of the subject ID column â€” edc_warn_patient_diffs","text":"nothing, called errors/warnings","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_warn_patient_diffs.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check the validity of the subject ID column â€” edc_warn_patient_diffs","text":"","code":"db = edc_example() #> Warning: Option \"edc_lookup\" has been overwritten. load_database(db) options(edc_subjid_ref=enrol$subjid) #usually, you set something like: #options(edc_subjid_ref=enrolres$subjid) edc_warn_patient_diffs(data1) data1 %>% dplyr::filter(subjid>1) %>% edc_warn_patient_diffs(issue_n=NULL) #> Warning: `.` has patient discrepancies: #> â„¹ Missing: 1 patient: #1 edc_warn_patient_diffs(c(data1$subjid, 99, 999)) #> Warning: Issue #xx: `c(data1$subjid, 99, 999)` has patient discrepancies: #> â„¹ Extra: 2 patients: #99 and #999"},{"path":"https://danchaltiel.github.io/EDCimport/reference/fct_yesno.html","id":null,"dir":"Reference","previous_headings":"","what":"Format factor levels as Yes/No â€” fct_yesno","title":"Format factor levels as Yes/No â€” fct_yesno","text":"Format factor levels arbitrary values Yes/(Yes always first) leaving untouched vectors contain information.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/fct_yesno.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Format factor levels as Yes/No â€” fct_yesno","text":"","code":"fct_yesno(   x,   input = list(yes = c(\"Yes\", \"Oui\"), no = c(\"No\", \"Non\"), na = c(\"NA\", \"\")),   output = c(\"Yes\", \"No\"),   strict = FALSE,   mutate_character = TRUE,   fail = TRUE )"},{"path":"https://danchaltiel.github.io/EDCimport/reference/fct_yesno.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Format factor levels as Yes/No â€” fct_yesno","text":"x vector type/class. input list values considered \"yes\", \"\", NA. output output factor levels. strict whether match input strictly use stringr::str_detect find . Can also \"ignore_case\" just ignore case. mutate_character whether turn characters factor. fail whether fail levels recoded yes/.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/fct_yesno.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Format factor levels as Yes/No â€” fct_yesno","text":"factor, x untouched.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/fct_yesno.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Format factor levels as Yes/No â€” fct_yesno","text":"","code":"fct_yesno(c(\"No\", \"Yes\")) #levels are in order #> [1] No  Yes #> Levels: Yes No  set.seed(42) N=6 x = tibble(   a=sample(c(\"Yes\", \"No\"), size=N, replace=TRUE),   b=sample(c(\"Oui\", \"Non\"), size=N, replace=TRUE),   c=sample(0:1, size=N, replace=TRUE),   d=sample(c(TRUE, FALSE), size=N, replace=TRUE),   e=sample(c(\"1-Yes\", \"0-No\", \"2-NA\"), size=N, replace=TRUE),      y=sample(c(\"aaa\", \"bbb\", \"ccc\"), size=N, replace=TRUE),   z=1:N, )   x           #> # A tibble: 6 Ã— 7 #>   a     b         c d     e     y         z #>   <chr> <chr> <int> <lgl> <chr> <chr> <int> #> 1 Yes   Non       0 FALSE 2-NA  ccc       1 #> 2 Yes   Non       1 FALSE 1-Yes bbb       2 #> 3 Yes   Oui       0 TRUE  2-NA  aaa       3 #> 4 Yes   Non       0 TRUE  1-Yes bbb       4 #> 5 No    Oui       1 TRUE  1-Yes bbb       5 #> 6 No    Non       1 TRUE  0-No  ccc       6 #y and z are left untouched (or throw an error if fail=TRUE)    sapply(x, fct_yesno, fail=FALSE, simplify=FALSE) #> $a #> [1] Yes Yes Yes Yes No  No  #> Levels: Yes No #>  #> $b #> [1] No  No  Yes No  Yes No  #> Levels: Yes No #>  #> $c #> [1] No  Yes No  No  Yes Yes #> Levels: Yes No #>  #> $d #> [1] No  No  Yes Yes Yes Yes #> Levels: Yes No #>  #> $e #> [1] <NA> Yes  <NA> Yes  Yes  No   #> Levels: Yes No #>  #> $y #> [1] \"ccc\" \"bbb\" \"aaa\" \"bbb\" \"bbb\" \"ccc\" #>  #> $z #> [1] 1 2 3 4 5 6 #>   # as \"1-Yes\" is not in `input`, x$e is untouched/fails if strict=TRUE fct_yesno(x$e) #> [1] <NA> Yes  <NA> Yes  Yes  No   #> Levels: Yes No fct_yesno(x$e, strict=TRUE, fail=FALSE)  #> [1] \"2-NA\"  \"1-Yes\" \"2-NA\"  \"1-Yes\" \"1-Yes\" \"0-No\"  fct_yesno(x$e, output=c(\"Ja\", \"Nein\")) #> [1] <NA> Ja   <NA> Ja   Ja   Nein #> Levels: Ja Nein"},{"path":"https://danchaltiel.github.io/EDCimport/reference/get_common_cols.html","id":null,"dir":"Reference","previous_headings":"","what":"Get columns that are common to multiple datasets â€” get_common_cols","title":"Get columns that are common to multiple datasets â€” get_common_cols","text":"Attempt list columns database group ones common datasets. Useful find keys pivot summarise data.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/get_common_cols.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get columns that are common to multiple datasets â€” get_common_cols","text":"","code":"get_common_cols(lookup = edc_lookup(), min_datasets = 3)  # S3 method for class 'common_cols' summary(object, ...)"},{"path":"https://danchaltiel.github.io/EDCimport/reference/get_common_cols.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get columns that are common to multiple datasets â€” get_common_cols","text":"lookup lookup table, default edc_lookup() min_datasets minimal number datasets considered object object class \"common_cols\" ... unused","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/get_common_cols.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get columns that are common to multiple datasets â€” get_common_cols","text":"tibble class \"common_cols\"","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/get_common_cols.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get columns that are common to multiple datasets â€” get_common_cols","text":"","code":"db = edc_example() #> Warning: Option \"edc_lookup\" has been overwritten. load_database(db) x = get_common_cols(min_datasets=1) x #> # A tibble: 28 Ã— 7 #>    column  name_in   datasets  n_datasets pct_datasets datasets_in  datasets_out #>    <chr>   <list>    <list>         <int>        <dbl> <chr>        <chr>        #>  1 crfname <lgl [8]> <chr [8]>          8        1     long_pure, â€¦ \"\"           #>  2 subjid  <lgl [8]> <chr [8]>          8        1     long_pure, â€¦ \"\"           #>  3 crfstat <lgl [8]> <chr [7]>          7        0.875 data1, longâ€¦ \"long_pure\"  #>  4 aegr    <lgl [8]> <chr [1]>          1        0.125 ae           \"long_pure,â€¦ #>  5 aesoc   <lgl [8]> <chr [1]>          1        0.125 ae           \"long_pure,â€¦ #>  6 age     <lgl [8]> <chr [1]>          1        0.125 enrol        \"long_pure,â€¦ #>  7 arm     <lgl [8]> <chr [1]>          1        0.125 enrol        \"long_pure,â€¦ #>  8 date1   <lgl [8]> <chr [1]>          1        0.125 data1        \"long_pure,â€¦ #>  9 date10  <lgl [8]> <chr [1]>          1        0.125 data3        \"long_pure,â€¦ #> 10 date2   <lgl [8]> <chr [1]>          1        0.125 data1        \"long_pure,â€¦ #> # â„¹ 18 more rows summary(x) #> # A tibble: 3 Ã— 7 #>   pct_datasets n_datasets n_distinct_datasets n_columns columns    datasets    #>   <chr>             <int>               <int>     <int> <list>     <list>      #> 1 100%                  8                   1         2 <chr [2]>  <list [2]>  #> 2 88%                   7                   1         1 <chr [1]>  <list [1]>  #> 3 12%                   1                   8        25 <chr [25]> <list [25]> #> # â„¹ 1 more variable: columns_str <chr>"},{"path":"https://danchaltiel.github.io/EDCimport/reference/get_datasets.html","id":null,"dir":"Reference","previous_headings":"","what":"Retrieve the datasets as a list of data.frames â€” get_datasets","title":"Retrieve the datasets as a list of data.frames â€” get_datasets","text":"Get datasets lookup table list data.frames.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/get_datasets.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Retrieve the datasets as a list of data.frames â€” get_datasets","text":"","code":"get_datasets(lookup = edc_lookup(), envir = edc_data_env())"},{"path":"https://danchaltiel.github.io/EDCimport/reference/get_datasets.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Retrieve the datasets as a list of data.frames â€” get_datasets","text":"lookup lookup table envir (internal use)","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/get_datasets.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Retrieve the datasets as a list of data.frames â€” get_datasets","text":"list datasets","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/get_subjid_cols.html","id":null,"dir":"Reference","previous_headings":"","what":"Get key column names â€” get_subjid_cols","title":"Get key column names â€” get_subjid_cols","text":"Retrieve names patient ID CRF name actual names datasets, without respect case. Default values set options.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/get_subjid_cols.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get key column names â€” get_subjid_cols","text":"","code":"get_subjid_cols(lookup = edc_lookup())"},{"path":"https://danchaltiel.github.io/EDCimport/reference/get_subjid_cols.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get key column names â€” get_subjid_cols","text":"lookup lookup table","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/get_subjid_cols.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get key column names â€” get_subjid_cols","text":"character vector","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/get_subjid_cols.html","id":"options","dir":"Reference","previous_headings":"","what":"options","title":"Get key column names â€” get_subjid_cols","text":"Use edc_options() set default values: edc_cols_subjid defaults c(\"SUBJID\", \"PTNO\") edc_cols_crfname defaults c(\"FORMDESC\", \"CRFNAME\")","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/get_subjid_cols.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get key column names â€” get_subjid_cols","text":"","code":"#get_subjid_cols() #get_crfname_cols()"},{"path":"https://danchaltiel.github.io/EDCimport/reference/lastnews_table.html","id":null,"dir":"Reference","previous_headings":"","what":"Get a table with the latest date for each patient â€” lastnews_table","title":"Get a table with the latest date for each patient â€” lastnews_table","text":"function search date columns every tables returns latest date patient variable comes . Useful survival analysis get right censoring time.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/lastnews_table.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get a table with the latest date for each patient â€” lastnews_table","text":"","code":"lastnews_table(   except = NULL,   with_ties = FALSE,   show_delta = FALSE,   numeric_id = TRUE,   prefer = NULL,   regex = FALSE,   warn_if_future = TRUE )"},{"path":"https://danchaltiel.github.io/EDCimport/reference/lastnews_table.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get a table with the latest date for each patient â€” lastnews_table","text":"except datasets/columns searched. Example: scheduled visit patient may died attending considered. with_ties case tie, whether return first origin (FALSE) origins share tie (TRUE). show_delta whether compute difference last prefer date actual last date numeric_id set FALSE patient ID column numeric prefer preferred origins event tie. Usually followup table. regex whether consider except prefer regex. warn_if_future whether show warning dates extraction date. Can also csv file path save warning csv (see csv_path argument edc_data_warn).","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/lastnews_table.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get a table with the latest date for each patient â€” lastnews_table","text":"dataframe","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/lastnews_table.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get a table with the latest date for each patient â€” lastnews_table","text":"","code":"db = edc_example() #> Warning: Option \"edc_lookup\" has been overwritten. load_database(db) lastnews_table() #> # A tibble: 50 Ã— 5 #>    subjid last_date  origin_data origin_col origin_label     #>     <dbl> <date>     <chr>       <chr>      <chr>            #>  1      1 2010-08-01 data2       date4      Date at visit 4  #>  2      2 2010-07-31 data2       date4      Date at visit 4  #>  3      3 2010-07-21 data2       date5      Date at visit 5  #>  4      4 2010-07-23 data3       date10     Date at visit 10 #>  5      5 2010-07-14 data3       date10     Date at visit 10 #>  6      6 2010-07-20 data3       date10     Date at visit 10 #>  7      7 2010-07-28 data3       date9      Date at visit 9  #>  8      8 2010-07-19 data3       date9      Date at visit 9  #>  9      9 2010-08-10 data3       date9      Date at visit 9  #> 10     10 2010-07-30 data3       date10     Date at visit 10 #> # â„¹ 40 more rows lastnews_table(except=\"data3\") #> # A tibble: 50 Ã— 5 #>    subjid last_date  origin_data origin_col origin_label    #>     <dbl> <date>     <chr>       <chr>      <chr>           #>  1      1 2010-08-01 data2       date4      Date at visit 4 #>  2      2 2010-07-31 data2       date4      Date at visit 4 #>  3      3 2010-07-21 data2       date5      Date at visit 5 #>  4      4 2010-06-19 data2       date6      Date at visit 6 #>  5      5 2010-06-14 data2       date5      Date at visit 5 #>  6      6 2010-06-11 data2       date6      Date at visit 6 #>  7      7 2010-06-16 data2       date6      Date at visit 6 #>  8      8 2010-06-21 data2       date6      Date at visit 6 #>  9      9 2010-05-30 data2       date6      Date at visit 6 #> 10     10 2010-06-11 data2       date6      Date at visit 6 #> # â„¹ 40 more rows lastnews_table(except=\"data3$date9\") #> # A tibble: 50 Ã— 5 #>    subjid last_date  origin_data origin_col origin_label     #>     <dbl> <date>     <chr>       <chr>      <chr>            #>  1      1 2010-08-01 data2       date4      Date at visit 4  #>  2      2 2010-07-31 data2       date4      Date at visit 4  #>  3      3 2010-07-21 data2       date5      Date at visit 5  #>  4      4 2010-07-23 data3       date10     Date at visit 10 #>  5      5 2010-07-14 data3       date10     Date at visit 10 #>  6      6 2010-07-20 data3       date10     Date at visit 10 #>  7      7 2010-07-11 data3       date10     Date at visit 10 #>  8      8 2010-07-12 data3       date10     Date at visit 10 #>  9      9 2010-07-16 data3       date8      Date at visit 8  #> 10     10 2010-07-30 data3       date10     Date at visit 10 #> # â„¹ 40 more rows lastnews_table(prefer=\"date10\", show_delta=TRUE)  #> # A tibble: 50 Ã— 8 #>    subjid last_date  origin_data origin_col origin_label     preferred_last_date #>     <dbl> <date>     <chr>       <chr>      <chr>            <date>              #>  1      1 2010-08-01 data3       date10     Date at visit 10 2010-08-01          #>  2      2 2010-07-31 data3       date10     Date at visit 10 2010-07-31          #>  3      3 2010-07-21 data3       date10     Date at visit 10 2010-07-21          #>  4      4 2010-07-23 data3       date10     Date at visit 10 2010-07-23          #>  5      5 2010-07-14 data3       date10     Date at visit 10 2010-07-14          #>  6      6 2010-07-20 data3       date10     Date at visit 10 2010-07-20          #>  7      7 2010-07-28 data3       date9      Date at visit 9  2010-07-11          #>  8      8 2010-07-19 data3       date9      Date at visit 9  2010-07-12          #>  9      9 2010-08-10 data3       date9      Date at visit 9  2010-07-09          #> 10     10 2010-07-30 data3       date10     Date at visit 10 2010-07-30          #> # â„¹ 40 more rows #> # â„¹ 2 more variables: preferred_origin <chr>, delta <drtn> lastnews_table() %>%    dplyr::count(origin = glue::glue(\"{origin_data}${origin_col}\"),    sort=TRUE) #> # A tibble: 5 Ã— 2 #>   origin           n #>   <glue>       <int> #> 1 data3$date10    36 #> 2 data3$date9     10 #> 3 data2$date4      2 #> 4 data2$date5      1 #> 5 data3$date8      1  csv_file = tempfile(fileext=\".csv\") lastnews_table(prefer=\"date9\", warn_if_future=csv_file)  #> # A tibble: 50 Ã— 5 #>    subjid last_date  origin_data origin_col origin_label     #>     <dbl> <date>     <chr>       <chr>      <chr>            #>  1      1 2010-08-01 data2       date4      Date at visit 4  #>  2      2 2010-07-31 data2       date4      Date at visit 4  #>  3      3 2010-07-21 data2       date5      Date at visit 5  #>  4      4 2010-07-23 data3       date10     Date at visit 10 #>  5      5 2010-07-14 data3       date10     Date at visit 10 #>  6      6 2010-07-20 data3       date10     Date at visit 10 #>  7      7 2010-07-28 data3       date9      Date at visit 9  #>  8      8 2010-07-19 data3       date9      Date at visit 9  #>  9      9 2010-08-10 data3       date9      Date at visit 9  #> 10     10 2010-07-30 data3       date10     Date at visit 10 #> # â„¹ 40 more rows"},{"path":"https://danchaltiel.github.io/EDCimport/reference/load_database.html","id":null,"dir":"Reference","previous_headings":"","what":"Load a list in an environment â€” load_database","title":"Load a list in an environment â€” load_database","text":"Load list environment","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/load_database.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Load a list in an environment â€” load_database","text":"","code":"load_database(db, env = parent.frame(), remove = TRUE)"},{"path":"https://danchaltiel.github.io/EDCimport/reference/load_database.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Load a list in an environment â€” load_database","text":"db edc_database object (fair, list ) env environment onto list loaded remove TRUE, db removed environment afterward","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/load_database.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Load a list in an environment â€” load_database","text":"nothing, called side-effect","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/load_database.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Load a list in an environment â€” load_database","text":"","code":"db = edc_example() #> Warning: Option \"edc_lookup\" has been overwritten. load_database(db, remove=FALSE) print(db) #> â”€â”€ EDCimport database â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #> Contains 8 tables: `enrol`, `data1`, `data2`, â€¦, `long_mixed`, and `ae` #> â„¹ Use `EDCimport::load_database(db)` to load the tables in the global #>   environment. #> â„¹ Use `EDCimport::edc_lookup()` to see the summary table. print(lengths(db)) #>               enrol               data1               data2               data3  #>                   6                   7                   6                   7  #>               short           long_pure          long_mixed                  ae  #>                   5                   4                   6                   7  #> datetime_extraction     date_extraction             .lookup  #>                   1                   1                   9"},{"path":"https://danchaltiel.github.io/EDCimport/reference/manual_correction.html","id":null,"dir":"Reference","previous_headings":"","what":"Manual correction â€” manual_correction","title":"Manual correction â€” manual_correction","text":"finding wrong unexpected values exported dataset, can useful temporarily correct hard-coding value. However, manual correction undone soon central database updated correction. manual_correction() applies correction specific dataset column location throws error correction already place. check applies per R session can source script without errors. reset_manual_correction() resets checks. instance, called read_trialmaster().","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/manual_correction.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Manual correction â€” manual_correction","text":"","code":"manual_correction(   data,   col,   rows,   wrong,   correct,   verbose = getOption(\"edc_correction_verbose\", TRUE) )  reset_manual_correction()"},{"path":"https://danchaltiel.github.io/EDCimport/reference/manual_correction.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Manual correction â€” manual_correction","text":"data, col, rows rows column dataframe error lies wrong actual wrong value correct temporary correction value verbose whether print informations ()","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/manual_correction.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Manual correction â€” manual_correction","text":"Nothing, used side effects","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/manual_correction.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Manual correction â€” manual_correction","text":"","code":"library(dplyr) x = iris %>% mutate(id=row_number(), .before=1) %>% as_tibble() x$Sepal.Length[c(1,3,5)] #> [1] 5.1 4.7 5.0  #1st correction is silent manual_correction(x, Sepal.Length, rows=c(1,3,5),                   wrong=c(5.1, 4.7, 5.0), correct=c(5, 4, 3)) #> Manual correction of \"x$Sepal.Length\": #> â„¹ Old: 5.1, 4.7, and 5 #> â„¹ New: 5, 4, and 3 x$Sepal.Length[c(1,3,5)] #> [1] 5 4 3  #further correction is silent manual_correction(x, Sepal.Length, rows=c(1,3,5),                   wrong=c(5.1, 4.7, 5.0), correct=c(5, 4, 3))                     #if the database is corrected, an error is thrown if (FALSE) { # \\dontrun{ reset_manual_correction() x$Sepal.Length[c(1,3,5)] = c(5, 4, 3) #mimics db correction manual_correction(x, Sepal.Length, rows=c(1,3,5),                   wrong=c(5.1, 4.7, 5.0), correct=c(5, 4, 3)) } # }"},{"path":"https://danchaltiel.github.io/EDCimport/reference/read_all_csv.html","id":null,"dir":"Reference","previous_headings":"","what":"Read all .csv files in a directory â€” read_all_csv","title":"Read all .csv files in a directory â€” read_all_csv","text":"Read .csv files directory, labels specified.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/read_all_csv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Read all .csv files in a directory â€” read_all_csv","text":"","code":"read_all_csv(   path,   ...,   labels_from = NULL,   format_file = NULL,   subdirectories = FALSE,   read_fun = \"guess\",   datetime_extraction = \"guess\",   verbose = getOption(\"edc_read_verbose\", 1),   clean_names_fun = NULL )"},{"path":"https://danchaltiel.github.io/EDCimport/reference/read_all_csv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Read all .csv files in a directory â€” read_all_csv","text":"path [character(1)] path directory containing .csv files. ... unused labels_from [character(1)] path file containing labels. See section \"Labels file\" . format_file [character(1)] path file used apply formats. See section \"Format file\" . Use NULL apply formats. subdirectories [logical(1)] whether read subdirectories read_fun [function] \"guess\" work properly, function read files path, e.g. read.csv, read.csv2,... datetime_extraction [POSIXt(1)] datetime data extraction. Default common date last modification path. verbose [numeric(1)] one c(0, 1, 2). higher, information printed. clean_names_fun use edc_clean_names() instead.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/read_all_csv.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Read all .csv files in a directory â€” read_all_csv","text":"list containing one dataframe .csv file folder, extraction date (datetime_extraction), summary imported tables (.lookup).","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/read_all_csv.html","id":"labels-file","dir":"Reference","previous_headings":"","what":"Labels file","title":"Read all .csv files in a directory â€” read_all_csv","text":"labels_from contain information column labels. data file (.csv) containing 2 columns: one column name associated label. Use options(edc_col_name=\"xxx\", edc_col_label=\"xxx\") specify names columns.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/read_all_csv.html","id":"format-file","dir":"Reference","previous_headings":"","what":"Format file","title":"Read all .csv files in a directory â€” read_all_csv","text":"format_file contain information SAS formats. can either: procformat.sas file, containing whole PROC FORMAT data file (.csv .sas7bdat) containing 3 columns: FMTNAME SAS format name (repeated) START variable level LABEL label associated level can get datafile SAS using PROC FORMAT option CNTLOUT. Otherwise, can use options(edc_var_format_name=\"xxx\", edc_var_level=\"xxx\", edc_var_label=\"xxx\") specify different column names.","code":""},{"path":[]},{"path":"https://danchaltiel.github.io/EDCimport/reference/read_all_csv.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Read all .csv files in a directory â€” read_all_csv","text":"","code":"# Create a directory with multiple csv files and a label lookup. path = paste0(tempdir(), \"/read_all_csv\") dir.create(paste0(path, \"/subdir\"), recursive=TRUE) write.csv(iris, paste0(path, \"/iris.csv\")) write.csv(mtcars, paste0(path, \"/mtcars.csv\")) write.csv(mtcars, paste0(path, \"/subdir/mtcars.csv\")) write.csv(airquality, paste0(path, \"/airquality.csv\")) labs = c(iris, mtcars, airquality) %>% names() write.csv(data.frame(name=labs, label=toupper(labs)), paste0(path, \"/labels.csv\"))   db = read_all_csv(path, labels_from=\"labels.csv\", subdirectories=TRUE) %>%    set_project_name(\"My great project\") #> Warning: Option \"edc_lookup\" has been overwritten. db #> â”€â”€ EDCimport database â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #> Contains 4 tables: `airquality`, `iris`, `mtcars`, and `subdir_mtcars` #> â„¹ Use `EDCimport::load_database(db)` to load the tables in the global #>   environment. #> â„¹ Use `EDCimport::edc_lookup()` to see the summary table. edc_lookup() #> â”€â”€ Lookup table - My great project (extraction of 2025-11-29) - EDCimport v0.6.0 #>   dataset        nrow  ncol  n_id rows_per_id crfname #>   <chr>         <dbl> <dbl> <int>       <dbl> <chr>   #> 1 airquality      153     7     0          NA NA      #> 2 iris            150     6     0          NA NA      #> 3 mtcars           32    12     0          NA NA      #> 4 subdir_mtcars    32    12     0          NA NA"},{"path":"https://danchaltiel.github.io/EDCimport/reference/read_all_sas.html","id":null,"dir":"Reference","previous_headings":"","what":"Read all .sas7bdat files in a directory â€” read_all_sas","title":"Read all .sas7bdat files in a directory â€” read_all_sas","text":"Read .sas7bdat files directory. Formats (factors levels) can applied procformat.sas SAS file, format dictionary. See \"Format file\" section . Column labels read directly .sas7bdat files.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/read_all_sas.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Read all .sas7bdat files in a directory â€” read_all_sas","text":"","code":"read_all_sas(   path,   ...,   format_file = \"procformat.sas\",   subdirectories = FALSE,   datetime_extraction = \"guess\",   verbose = getOption(\"edc_read_verbose\", 1),   clean_names_fun = NULL )"},{"path":"https://danchaltiel.github.io/EDCimport/reference/read_all_sas.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Read all .sas7bdat files in a directory â€” read_all_sas","text":"path [character(1)] path directory containing .sas7bdat files. ... unused format_file [character(1)] path file used apply formats. See section \"Format file\" . Use NULL apply formats. subdirectories [logical(1)] whether read subdirectories datetime_extraction [POSIXt(1)] datetime data extraction. Default common date last modification path. verbose [numeric(1)] one c(0, 1, 2). higher, information printed. clean_names_fun use edc_clean_names() instead.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/read_all_sas.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Read all .sas7bdat files in a directory â€” read_all_sas","text":"list containing one dataframe .xpt file folder, extraction date (datetime_extraction), summary imported tables (.lookup).","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/read_all_sas.html","id":"format-file","dir":"Reference","previous_headings":"","what":"Format file","title":"Read all .sas7bdat files in a directory â€” read_all_sas","text":"format_file contain information SAS formats. can either: procformat.sas file, containing whole PROC FORMAT data file (.csv .sas7bdat) containing 3 columns: FMTNAME SAS format name (repeated) START variable level LABEL label associated level can get datafile SAS using PROC FORMAT option CNTLOUT. Otherwise, can use options(edc_var_format_name=\"xxx\", edc_var_level=\"xxx\", edc_var_label=\"xxx\") specify different column names.","code":""},{"path":[]},{"path":"https://danchaltiel.github.io/EDCimport/reference/read_all_sas.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Read all .sas7bdat files in a directory â€” read_all_sas","text":"","code":"# Create a directory with multiple sas files. path = paste0(tempdir(), \"/read_all_sas\") dir.create(paste0(path, \"/subdir\"), recursive=TRUE) haven::write_sas(attenu, paste0(path, \"/attenu.sas7bdat\")) #> Warning: `write_sas()` was deprecated in haven 2.5.2. #> â„¹ Please use `write_xpt()` instead. haven::write_sas(mtcars, paste0(path, \"/mtcars.sas7bdat\")) haven::write_sas(mtcars, paste0(path, \"/subdir/mtcars.sas7bdat\")) haven::write_sas(esoph, paste0(path, \"/esoph.sas7bdat\"))  db = read_all_sas(path, format_file=NULL, subdirectories=TRUE) %>%    set_project_name(\"My great project\") #> Warning: Option \"edc_lookup\" has been overwritten. db #> â”€â”€ EDCimport database â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #> Contains 4 tables: `attenu`, `esoph`, `mtcars`, and `subdir_mtcars` #> â„¹ Use `EDCimport::load_database(db)` to load the tables in the global #>   environment. #> â„¹ Use `EDCimport::edc_lookup()` to see the summary table. edc_lookup() #> â”€â”€ Lookup table - My great project (extraction of 2025-11-29) - EDCimport v0.6.0 #>   dataset        nrow  ncol  n_id rows_per_id crfname #>   <chr>         <dbl> <dbl> <int>       <dbl> <chr>   #> 1 attenu          182     5     0          NA NA      #> 2 esoph            88     5     0          NA NA      #> 3 mtcars           32    11     0          NA NA      #> 4 subdir_mtcars    32    11     0          NA NA"},{"path":"https://danchaltiel.github.io/EDCimport/reference/read_all_xpt.html","id":null,"dir":"Reference","previous_headings":"","what":"Read all .xpt files in a directory â€” read_all_xpt","title":"Read all .xpt files in a directory â€” read_all_xpt","text":"Read .xpt files directory (unzipped TrialMaster archive).  7zip installed, probably rather use read_trialmaster() instead.  Formats (factors levels) can applied procformat.sas SAS file, format dictionary. See \"Format file\" section . Column labels read directly .xpt files.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/read_all_xpt.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Read all .xpt files in a directory â€” read_all_xpt","text":"","code":"read_all_xpt(   path,   ...,   format_file = \"procformat.sas\",   datetime_extraction = \"guess\",   subdirectories = FALSE,   verbose = getOption(\"edc_read_verbose\", 1),   clean_names_fun = NULL,   directory = \"deprecated\",   key_columns = \"deprecated\" )"},{"path":"https://danchaltiel.github.io/EDCimport/reference/read_all_xpt.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Read all .xpt files in a directory â€” read_all_xpt","text":"path [character(1)] path directory containing .xpt files. ... unused format_file [character(1)] path file used apply formats. See section \"Format file\" . Use NULL apply formats. datetime_extraction [POSIXt(1)] datetime data extraction. Default common date last modification path. subdirectories [logical(1)] whether read subdirectories verbose [numeric(1)] one c(0, 1, 2). higher, information printed. clean_names_fun use edc_clean_names() instead. directory deprecated favor path key_columns deprecated","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/read_all_xpt.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Read all .xpt files in a directory â€” read_all_xpt","text":"list containing one dataframe .xpt file folder, extraction date (datetime_extraction), summary imported tables (.lookup).","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/read_all_xpt.html","id":"format-file","dir":"Reference","previous_headings":"","what":"Format file","title":"Read all .xpt files in a directory â€” read_all_xpt","text":"format_file contain information SAS formats. can either: procformat.sas file, containing whole PROC FORMAT data file (.csv .sas7bdat) containing 3 columns: FMTNAME SAS format name (repeated) START variable level LABEL label associated level can get datafile SAS using PROC FORMAT option CNTLOUT. Otherwise, can use options(edc_var_format_name=\"xxx\", edc_var_level=\"xxx\", edc_var_label=\"xxx\") specify different column names.","code":""},{"path":[]},{"path":"https://danchaltiel.github.io/EDCimport/reference/read_all_xpt.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Read all .xpt files in a directory â€” read_all_xpt","text":"","code":"# Create a directory with multiple .xpt files. path = paste0(tempdir(), \"/read_all_xpt\") dir.create(paste0(path, \"/subdir\"), recursive=TRUE) haven::write_xpt(attenu, paste0(path, \"/attenu.xpt\")) haven::write_xpt(mtcars, paste0(path, \"/mtcars.xpt\")) haven::write_xpt(mtcars, paste0(path, \"/subdir/mtcars.xpt\")) haven::write_xpt(esoph, paste0(path, \"/esoph.xpt\"))  db = read_all_xpt(path, format_file=NULL, subdirectories=TRUE) %>%    set_project_name(\"My great project\") #> Warning: Option \"edc_lookup\" has been overwritten. db #> â”€â”€ EDCimport database â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #> Contains 4 tables: `attenu`, `esoph`, `mtcars`, and `subdir_mtcars` #> â„¹ Use `EDCimport::load_database(db)` to load the tables in the global #>   environment. #> â„¹ Use `EDCimport::edc_lookup()` to see the summary table. edc_lookup() #> â”€â”€ Lookup table - My great project (extraction of 2025-11-29) - EDCimport v0.6.0 #>   dataset        nrow  ncol  n_id rows_per_id crfname #>   <chr>         <dbl> <dbl> <int>       <dbl> <chr>   #> 1 attenu          182     5     0          NA NA      #> 2 esoph            88     5     0          NA NA      #> 3 mtcars           32    11     0          NA NA      #> 4 subdir_mtcars    32    11     0          NA NA"},{"path":"https://danchaltiel.github.io/EDCimport/reference/read_trialmaster.html","id":null,"dir":"Reference","previous_headings":"","what":"Read the .zip archive of a TrialMaster export â€” read_trialmaster","title":"Read the .zip archive of a TrialMaster export â€” read_trialmaster","text":"Import .zip archive TrialMaster trial export list dataframes. archive filename leaved untouched contains project name date extraction.  Generate .rds cache file future reads.  7zip installed available, use read_all_xpt() instead. TM export type SAS Xport, checkbox \"Include Codelists\" ticked.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/read_trialmaster.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Read the .zip archive of a TrialMaster export â€” read_trialmaster","text":"","code":"read_trialmaster(   archive,   ...,   use_cache = \"write\",   clean_names_fun = NULL,   subdirectories = FALSE,   pw = getOption(\"trialmaster_pw\"),   verbose = getOption(\"edc_read_verbose\", 1),   key_columns = \"deprecated\" )"},{"path":"https://danchaltiel.github.io/EDCimport/reference/read_trialmaster.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Read the .zip archive of a TrialMaster export â€” read_trialmaster","text":"archive [character(1)] path archive ... unused use_cache [mixed(1): \"write\"] controls .rds cache. TRUE, read cache extract archive create cache. FALSE extract archive without creating cache file. Can also \"read\" \"write\". clean_names_fun use edc_clean_names() instead. subdirectories [logical(1)] whether read subdirectories pw [character(1)] password archive protected. avoid writing passwords plain text, probably better use options(trialmaster_pw=\"xxx\") instead though. verbose [numeric(1)] one c(0, 1, 2). higher, information printed. key_columns deprecated","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/read_trialmaster.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Read the .zip archive of a TrialMaster export â€” read_trialmaster","text":"list containing one dataframe .xpt file folder, extraction date (datetime_extraction), summary imported tables (.lookup).","code":""},{"path":[]},{"path":"https://danchaltiel.github.io/EDCimport/reference/reexports.html","id":null,"dir":"Reference","previous_headings":"","what":"Objects exported from other packages â€” reexports","title":"Objects exported from other packages â€” reexports","text":"objects imported packages. Follow links see documentation. dplyr %>% tibble tibble","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/save_edc_data_warnings.html","id":null,"dir":"Reference","previous_headings":"","what":"Save EDCimport warning to Excel â€” save_edc_data_warnings","title":"Save EDCimport warning to Excel â€” save_edc_data_warnings","text":"time edc_data_warn used, warning saved internally summary can retrieved using edc_data_warnings. summary can saved .xlsx file using save_edc_data_warnings().","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/save_edc_data_warnings.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Save EDCimport warning to Excel â€” save_edc_data_warnings","text":"","code":"save_edc_data_warnings(   edc_warnings = edc_data_warnings(),   output_file = \"edc_data_warnings_{project}_{date_extraction}.xlsx\",   output_dir = \"output/check\",   open = FALSE,   overwrite = TRUE,   hide_resolved = TRUE,   include_stops = FALSE,   path = \"deprecated\" )"},{"path":"https://danchaltiel.github.io/EDCimport/reference/save_edc_data_warnings.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Save EDCimport warning to Excel â€” save_edc_data_warnings","text":"edc_warnings result edc_data_warnings output_file, output_dir path .xlsx file. Use special values {proj_name} {date_extraction}. open TRUE, overwrite existing file. overwrite TRUE, overwrite existing file. hide_resolved TRUE, hide sheets data. include_stops TRUE, also include STOP-type warnings. path deprecated","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/save_edc_data_warnings.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Save EDCimport warning to Excel â€” save_edc_data_warnings","text":"logical(1), whether file written, invisibly","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/save_plotly.html","id":null,"dir":"Reference","previous_headings":"","what":"Save a plotly to an HTML file â€” save_plotly","title":"Save a plotly to an HTML file â€” save_plotly","text":"Save plotly HTML file","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/save_plotly.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Save a plotly to an HTML file â€” save_plotly","text":"","code":"save_plotly(p, file, ...)"},{"path":"https://danchaltiel.github.io/EDCimport/reference/save_plotly.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Save a plotly to an HTML file â€” save_plotly","text":"p plot object (plotly ggplot) file file path save HTML file. Can use glue syntax add variables. ... passed htmlwidgets::saveWidget","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/save_plotly.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Save a plotly to an HTML file â€” save_plotly","text":"nothing, used side effect","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/save_plotly.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Save a plotly to an HTML file â€” save_plotly","text":"","code":"if (FALSE) { # \\dontrun{ db = edc_example() load_database(db) p = edc_swimmerplot(id_lim=c(5,45)) save_plotly(p, \"graph/swimplots_{date_extraction}/edc_swimmerplot.html\",              title=\"My Swimmerplot\") } # }"},{"path":"https://danchaltiel.github.io/EDCimport/reference/save_sessioninfo.html","id":null,"dir":"Reference","previous_headings":"","what":"Save sessionInfo() output â€” save_sessioninfo","title":"Save sessionInfo() output â€” save_sessioninfo","text":"Save sessionInfo() output text file.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/save_sessioninfo.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Save sessionInfo() output â€” save_sessioninfo","text":"","code":"save_sessioninfo(path = \"check/session_info.txt\", with_date = TRUE)"},{"path":"https://danchaltiel.github.io/EDCimport/reference/save_sessioninfo.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Save sessionInfo() output â€” save_sessioninfo","text":"path target path write file with_date whether insert date file extension","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/save_sessioninfo.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Save sessionInfo() output â€” save_sessioninfo","text":"nothing","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/save_sessioninfo.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Save sessionInfo() output â€” save_sessioninfo","text":"","code":"if (FALSE) { # \\dontrun{    save_sessioninfo() } # }"},{"path":"https://danchaltiel.github.io/EDCimport/reference/search_for_newer_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Search for newer data â€” search_for_newer_data","title":"Search for newer data â€” search_for_newer_data","text":"Search folders TrialMaster database recent current extraction present. default, search \"data\" folder OS usual \"Downloads\" folder. newer database found, user asked want move \"data\" folder.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/search_for_newer_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Search for newer data â€” search_for_newer_data","text":"","code":"search_for_newer_data(   archive,   ...,   source = path_home(\"Downloads\"),   target = \"data\",   ask = TRUE,   advice = TRUE )"},{"path":"https://danchaltiel.github.io/EDCimport/reference/search_for_newer_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Search for newer data â€” search_for_newer_data","text":"archive TM archive path, giving project name date ... unused source path vector searched, default \"data\" usual \"Downloads\" folder target path files copied ask whether ask user move file \"data\" advice whether advice move instead, ask==FALSE","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/search_for_newer_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Search for newer data â€” search_for_newer_data","text":"path newer file, invisibly.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/search_for_newer_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Search for newer data â€” search_for_newer_data","text":"","code":"if (FALSE) { # \\dontrun{   archive = \"data/MYPROJECT_ExportTemplate_xxx_SAS_XPORT_2024_06_01_12_00.zip\"   #tm = read_trialmaster(archive)   search_for_newer_data(archive) } # }"},{"path":"https://danchaltiel.github.io/EDCimport/reference/select_distinct.html","id":null,"dir":"Reference","previous_headings":"","what":"Select only distinct columns â€” select_distinct","title":"Select only distinct columns â€” select_distinct","text":"Select columns one level given grouping scope. Useful dealing mixed datasets containing long data repeated short data.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/select_distinct.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Select only distinct columns â€” select_distinct","text":"","code":"select_distinct(df, .by)"},{"path":"https://danchaltiel.github.io/EDCimport/reference/select_distinct.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Select only distinct columns â€” select_distinct","text":"df dataframe .optional grouping columns","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/select_distinct.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Select only distinct columns â€” select_distinct","text":"df less columns","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/select_distinct.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Select only distinct columns â€” select_distinct","text":"","code":"db = edc_example() #> Warning: Option \"edc_lookup\" has been overwritten. db$ae %>% colnames() #> [1] \"subjid\"  \"crfname\" \"aesoc\"   \"aegr\"    \"n_ae\"    \"sae\"     \"crfstat\" #`crfname` has one level for the whole dataset db$ae %>% select_distinct() %>% colnames() #> [1] \"crfname\" #`n_ae` has one level per patient db$ae %>% select_distinct(.by=subjid) %>% colnames() #> [1] \"subjid\"  \"crfname\" \"n_ae\""},{"path":"https://danchaltiel.github.io/EDCimport/reference/set_project_name.html","id":null,"dir":"Reference","previous_headings":"","what":"Set the project name â€” set_project_name","title":"Set the project name â€” set_project_name","text":"Set override project name","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/set_project_name.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set the project name â€” set_project_name","text":"","code":"set_project_name(db, name, lookup = edc_lookup())  get_project_name(lookup = edc_lookup())"},{"path":"https://danchaltiel.github.io/EDCimport/reference/set_project_name.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set the project name â€” set_project_name","text":"db edc_database name project name lookup lookup table","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/set_project_name.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Set the project name â€” set_project_name","text":"nothing name project","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/set_project_name.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Set the project name â€” set_project_name","text":"","code":"db = edc_example() %>%   set_project_name(\"My great project\") #> Warning: Option \"edc_lookup\" has been overwritten. edc_lookup() #> â”€â”€ Lookup table - My great project (extraction of 2024-01-01) - EDCimport v0.6.0 #>   dataset     nrow  ncol  n_id rows_per_id crfname                  #>   <chr>      <dbl> <dbl> <int>       <dbl> <chr>                    #> 1 long_pure    150     4    50         3   long data                #> 2 data1        100     7    50         2   data1                    #> 3 long_mixed   100     6    50         2   both short and long data #> 4 data2         50     6    50         1   data2                    #> 5 data3         50     7    50         1   data3                    #> 6 enrol         50     6    50         1   enrol                    #> 7 short         50     5    50         1   short data               #> 8 ae           175     7    48         3.6 Adverse events"},{"path":"https://danchaltiel.github.io/EDCimport/reference/table_format.html","id":null,"dir":"Reference","previous_headings":"","what":"Identify if a dataframe has a long or a wide format â€” table_format","title":"Identify if a dataframe has a long or a wide format â€” table_format","text":"dataset either wide format long format. function identifies format dataframe respect subject ID. dataframe wide long columns, considered \"mixed\".","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/table_format.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Identify if a dataframe has a long or a wide format â€” table_format","text":"","code":"table_format(   df,   id = get_subjid_cols(),   ...,   ignore_cols = get_meta_cols(0.95),   na_rm = FALSE,   warn = TRUE )"},{"path":"https://danchaltiel.github.io/EDCimport/reference/table_format.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Identify if a dataframe has a long or a wide format â€” table_format","text":"df dataframe id identifying subject ID ... used ignore_cols columns ignore. na_rm whether consider missing values warn whether warn ID found","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/table_format.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Identify if a dataframe has a long or a wide format â€” table_format","text":"string value c(\"wide\", \"long\", \"mixed)","code":""},{"path":[]},{"path":"https://danchaltiel.github.io/EDCimport/reference/table_format.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Identify if a dataframe has a long or a wide format â€” table_format","text":"","code":"db = edc_example() #> Warning: Option \"edc_lookup\" has been overwritten. sapply(db, table_format, warn=FALSE)  #> $enrol #> [1] \"wide\" #>  #> $data1 #> [1] \"mixed\" #>  #> $data2 #> [1] \"wide\" #>  #> $data3 #> [1] \"wide\" #>  #> $short #> [1] \"wide\" #>  #> $long_pure #> [1] \"long\" #>  #> $long_mixed #> [1] \"mixed\" #>  #> $ae #> [1] \"mixed\" #>  #> $datetime_extraction #> NULL #>  #> $date_extraction #> NULL #>  #> $.lookup #> NULL #>"},{"path":"https://danchaltiel.github.io/EDCimport/reference/unify.html","id":null,"dir":"Reference","previous_headings":"","what":"Unify a vector â€” unify","title":"Unify a vector â€” unify","text":"Turn vector length N vector length 1 checking one unique value. Useful safely flatten duplicated table. Preserves label attribute set.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/unify.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Unify a vector â€” unify","text":"","code":"unify(x, collapse_chr = FALSE, warn = TRUE)"},{"path":"https://danchaltiel.github.io/EDCimport/reference/unify.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Unify a vector â€” unify","text":"x vector collapse_chr whether collapse non-unique character values warn whether warn non-unique values found","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/unify.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Unify a vector â€” unify","text":"vector length 1","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/unify.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Unify a vector â€” unify","text":"","code":"unify(c(1,1,1,1)) #> [1] 1 #unify(c(1,1,2,1)) #warning  library(dplyr) set.seed(42) x=tibble(id=rep(letters[1:5],10), value=rep(1:5,10),           value2=sample(letters[6:10], 50, replace=TRUE)) x %>% summarise(value=unify(value), .by=id) #safer than `value=value[1]` #> # A tibble: 5 Ã— 2 #>   id    value #>   <chr> <int> #> 1 a         1 #> 2 b         2 #> 3 c         3 #> 4 d         4 #> 5 e         5 x %>% summarise(value2=unify(value2, collapse_chr=TRUE, warn=FALSE), .by=id) #> # A tibble: 5 Ã— 2 #>   id    value2                       #>   <chr> <chr>                        #> 1 a     f, i, f, h, j, i, h, j, g, g #> 2 b     j, g, j, f, j, h, g, i, h, g #> 3 c     f, g, i, f, j, g, i, j, f, i #> 4 d     f, f, g, h, i, f, i, i, j, h #> 5 e     g, i, g, i, g, g, g, g, g, j x$value[2]=1 x %>% summarise(value2=unify(value2), .by=id) #warning about that non-unique value #> Warning: There were 5 warnings in `summarise()`. #> The first warning was: #> â„¹ In argument: `value2 = unify(value2)`. #> â„¹ In group 1: `id = \"a\"`. #> Caused by warning: #> ! Unifying multiple values in \"value2\", returning the first one (\"f)\" #> â„¹ Unique values: \"f\", \"i\", \"h\", \"j\", and \"g\" #> â„¹ Run `dplyr::last_dplyr_warnings()` to see the 4 remaining warnings. #> # A tibble: 5 Ã— 2 #>   id    value2 #>   <chr> <chr>  #> 1 a     f      #> 2 b     j      #> 3 c     f      #> 4 d     f      #> 5 e     g"},{"path":[]},{"path":"https://danchaltiel.github.io/EDCimport/news/index.html","id":"new-features-0-6-1","dir":"Changelog","previous_headings":"","what":"New features","title":"EDCimport 0.6.1 (dev)","text":"New function compare_databases(), compares structure several extractions database: added/removed columns, number patients, etc (#26). See examples demo. Support multiple instances different ports custom datasets (#100, #114) instance, can now run edc_viewer(data=lst(iris, mtcars), port=1212) New button browse column labels (#113).","code":""},{"path":"https://danchaltiel.github.io/EDCimport/news/index.html","id":"bug-fixes--improvements-0-6-1","dir":"Changelog","previous_headings":"","what":"Bug fixes & Improvements","title":"EDCimport 0.6.1 (dev)","text":"Fixed modifiers edc_clean_names(), edc_unify_subjid(), edc_split_mixed() donâ€™t strip database attributes (like project name) (#111). Fixed edc_data_stop() works without SUBJID defaults issue number (#109). Fixed assert_no_duplicate() works table columns SUBJID subjid (#105). Fixed bugs edc_left_join() case-sensitivity SUBJID (#108, #117). Improved save_edc_data_warnings() options hide resolved issues include stops, better default path (#107, #110, #112) Improved reading functions tables sorted SUBJID (#115). Improved reading functions dataset label attribute, taken FORMDESC CRFNAME (#118). Improved edc_swimmerplot() removing origin default (#106). Improved edc_swimmerplot() adding arguments origin_fun summarise origin patient level using, data_list control datasets. Improved edc_warn_extraction_date() strict unit â€œdaysâ€. Improved save_plotly() glue syntax param file.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/news/index.html","id":"edcimport-060","dir":"Changelog","previous_headings":"","what":"EDCimport 0.6.0","title":"EDCimport 0.6.0","text":"CRAN release: 2025-06-24","code":""},{"path":"https://danchaltiel.github.io/EDCimport/news/index.html","id":"documentation-0-6-0","dir":"Changelog","previous_headings":"","what":"Documentation","title":"EDCimport 0.6.0","text":"New vignettes: vignette(\"reading\"), vignette(\"postprocessing\"), vignette(\"checking\"), vignette(\"visualizing\"), vignette(\"utils\")","code":""},{"path":"https://danchaltiel.github.io/EDCimport/news/index.html","id":"new-features-0-6-0","dir":"Changelog","previous_headings":"","what":"New features","title":"EDCimport 0.6.0","text":"New function edc_patient_gridplot(), creates ggplot matrix giving presence patients datasets (#77) New functions edc_left_join(), edc_right_join(), edc_full_join(), perform joins defaults subject ID primary key (#82) New function edc_viewer(), runs shiny application easily browsing database (#83) New function set_project_name(), set project name reading directory (#96) New function edc_find_value(), searches whole database value, edc_find_column() searches column names labels. New function save_edc_data_warnings(), save warnings triggered edc_data_warn() .xlsx file sharing.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/news/index.html","id":"bug-fixes--improvements-0-6-0","dir":"Changelog","previous_headings":"","what":"Bug fixes & Improvements","title":"EDCimport 0.6.0","text":"New argument unify(collapse_chr=TRUE), collapse non-unique character values (#99) improvements: allow regex except & prefer (regex=TRUE), improved warning message, allow saving warnings csv file (#78) New argument edc_data_warn(envir), environment evaluate message . New argument edc_swimmerplot(include), subset swimmer plot significant variables . New argument subdirectories reading functions (read_trialmaster(), read_all_xpt(), read_all_sas(), read_all_csv()), control whether read sub-directories. Note now, subdirectories read overwrite root files. Fixed labels sometimes duplicated.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/news/index.html","id":"internal-improvements-0-6-0","dir":"Changelog","previous_headings":"","what":"Internal improvements","title":"EDCimport 0.6.0","text":"read_trialmaster() wonâ€™t read cache installed EDCimport version different cacheâ€™s","code":""},{"path":"https://danchaltiel.github.io/EDCimport/news/index.html","id":"deprecations-0-6-0","dir":"Changelog","previous_headings":"","what":"Deprecations","title":"EDCimport 0.6.0","text":"load_list(), renamed load_database() find_keyword(), renamed edc_find_column()","code":""},{"path":"https://danchaltiel.github.io/EDCimport/news/index.html","id":"breaking-changes-0-6-0","dir":"Changelog","previous_headings":"","what":"Breaking changes","title":"EDCimport 0.6.0","text":"donâ€™t think enough people using necessary go deprecation process. split_mixed_datasets becomes edc_split_mixed() Removed export internal functions: build_lookup(), extend_lookup(), get_key_cols(), get_subjid_cols(), get_crfname_cols(), get_meta_cols(), load_as_list(), save_list()","code":""},{"path":"https://danchaltiel.github.io/EDCimport/news/index.html","id":"edcimport-052","dir":"Changelog","previous_headings":"","what":"EDCimport 0.5.2","title":"EDCimport 0.5.2","text":"CRAN release: 2024-11-14 Fixed bug lastnews_table() SUBJID numeric Fixed bug read_all_sas() causing metadata (e.g.Â date_extraction) converted dataframes","code":""},{"path":"https://danchaltiel.github.io/EDCimport/news/index.html","id":"edcimport-051","dir":"Changelog","previous_headings":"","what":"EDCimport 0.5.1","title":"EDCimport 0.5.1","text":"CRAN release: 2024-10-31 Internal fix CRAN check","code":""},{"path":"https://danchaltiel.github.io/EDCimport/news/index.html","id":"edcimport-050","dir":"Changelog","previous_headings":"","what":"EDCimport 0.5.0","title":"EDCimport 0.5.0","text":"CRAN release: 2024-10-24","code":""},{"path":[]},{"path":"https://danchaltiel.github.io/EDCimport/news/index.html","id":"read-functions-0-5-0","dir":"Changelog","previous_headings":"New features","what":"Read functions","title":"EDCimport 0.5.0","text":"New function read_all_sas() read database .sas7bdat files. New function read_all_csv() read database .csv files.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/news/index.html","id":"sanity-checks-alerts-0-5-0","dir":"Changelog","previous_headings":"New features","what":"Sanity checks alerts","title":"EDCimport 0.5.0","text":"New functions edc_data_warn() edc_data_stop(), alert data inconsistencies (#29, #39, #43). New function edc_data_warnings(), get dataframe warnings thrown edc_data_warn(). New function edc_warn_extraction_date(), alert data old.","code":"ae %>% filter(grade<1 | grade>5) %>% edc_data_stop(\"AE of invalid grade\") ae %>% filter(is.na(grade)) %>% edc_data_warn(\"Grade is missing\", issue_n=13) #> Warning: Issue #13: Grade is missing (8 patients: #21, #28, #39, #95, #97, ...)"},{"path":"https://danchaltiel.github.io/EDCimport/news/index.html","id":"miscellaneous-utils-0-5-0","dir":"Changelog","previous_headings":"New features","what":"Miscellaneous utils","title":"EDCimport 0.5.0","text":"New function select_distinct() select columns one level given grouping scope (#57). New function edc_population_plot() visualize patient analysis population (#56). New function edc_db_to_excel() export whole database Excel file, easier browse RStudioâ€™s table viewer (#55). Use edc_browse_excel() browse file without knowing name. New function edc_inform_code() show much code project contains (#49). New function search_for_newer_data() search path (e.g.Â Downloads) newer data archive (#46). New function edc_crf_plot() show current database completion status (#48). New function save_sessioninfo(), save sessionInfo() text file (#42). New function fct_yesno(), easily format Yes/columns (#19, #23, #40). New function lastnews_table() find last date information entered patient (#37). Useful survival analyses. New function edc_unify_subjid(), structure subject IDs datasets database (#30). New function save_plotly(), save plotly HTML file (#15). New experimental functions table_format(), get_common_cols() get_meta_cols() might become useful find keys pivot summarise data.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/news/index.html","id":"bug-fixes--improvements-0-5-0","dir":"Changelog","previous_headings":"","what":"Bug fixes & Improvements","title":"EDCimport 0.5.0","text":"get_datasets() now work even dataset named base function (#67). read_trialmaster() output readable error password entered although one needed. read_trialmaster(split_mixed=\"TRUE\") work intended. assert_no_duplicate() now argument check duplicate groups, example visit (#17). find_keyword() robust inform proportion missing possible. edc_lookup() now retrieve lookup table. Use build_lookup() build one table list. extend_lookup() fail anymore database faulty table.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/news/index.html","id":"deprecations-0-5-0","dir":"Changelog","previous_headings":"","what":"Deprecations","title":"EDCimport 0.5.0","text":"get_key_cols() replaced get_subjid_cols() get_crfname_cols(). check_subjid() replaced edc_warn_patient_diffs(). can either take vector dataframe input, message informative.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/news/index.html","id":"edcimport-041","dir":"Changelog","previous_headings":"","what":"EDCimport 0.4.1","title":"EDCimport 0.4.1","text":"CRAN release: 2023-12-19","code":""},{"path":"https://danchaltiel.github.io/EDCimport/news/index.html","id":"bug-fixes--improvements-0-4-1","dir":"Changelog","previous_headings":"","what":"Bug fixes & Improvements","title":"EDCimport 0.4.1","text":"Changes testing environment package can installed CRAN despite firewall policies forbidding password-protected archive downloading. Fixed bug corrupted XPT file can prevent whole import fail.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/news/index.html","id":"edcimport-040","dir":"Changelog","previous_headings":"","what":"EDCimport 0.4.0","title":"EDCimport 0.4.0","text":"CRAN release: 2023-12-11","code":""},{"path":"https://danchaltiel.github.io/EDCimport/news/index.html","id":"new-features-0-4-0","dir":"Changelog","previous_headings":"","what":"New features","title":"EDCimport 0.4.0","text":"New function check_subjid() check vector missing patients (#8). New function assert_no_duplicate() abort table duplicates subject ID column(#9). New function manual_correction() safely hard-code correction waiting TrialMaster database updated. New function edc_options() manage EDCimport global parameterization. New argument edc_swimmerplot(id_lim) subset swimmer plot patients . New option read_trialmaster(use_cache=\"write\") read zip still update cache. can now use syntax read_trialmaster(split_mixed=c(\"col1\", \"col2\")) split datasets need (#10).","code":"options(edc_subjid_ref=enrolres$subjid) check_subjid(treatment$subjid) check_subjid(ae$subjid) tibble(subjid=c(1:10, 1)) %>% assert_no_duplicate() %>% nrow() #Error in `assert_no_duplicate()`: #! Duplicate on column \"subjid\" for value 1."},{"path":"https://danchaltiel.github.io/EDCimport/news/index.html","id":"bug-fixes--improvements-0-4-0","dir":"Changelog","previous_headings":"","what":"Bug fixes & Improvements","title":"EDCimport 0.4.0","text":"Reading read_trialmaster() cache output error parameters (split_mixed, clean_names_fun) different (#4). split_mixed_datasets() now fully case-insensitive. Non-UTF8 characters labels now identified corrected reading (#5).","code":""},{"path":"https://danchaltiel.github.io/EDCimport/news/index.html","id":"minor-breaking-changes-0-4-0","dir":"Changelog","previous_headings":"","what":"Minor breaking changes","title":"EDCimport 0.4.0","text":"read_trialmaster(use_cache=\"write\") now default. Reading cache stable yet, opt-rather opt-. read_trialmaster(extend_lookup=TRUE) now default. Options edc_id, edc_crfname, edc_verbose respectively renamed edc_cols_id, edc_cols_crfname, edc_read_verbose clarity.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/news/index.html","id":"edcimport-030-20230519","dir":"Changelog","previous_headings":"","what":"EDCimport 0.3.0 2023/05/19","title":"EDCimport 0.3.0 2023/05/19","text":"CRAN release: 2023-05-19","code":""},{"path":"https://danchaltiel.github.io/EDCimport/news/index.html","id":"new-features-0-3-0","dir":"Changelog","previous_headings":"","what":"New features","title":"EDCimport 0.3.0 2023/05/19","text":"New function edc_swimmerplot() show swimmer plot dates database easily find outliers. New features read_trialmaster(): clean_names_fun=some_fun clean names tables. instance, clean_names_fun=janitor::clean_names() turn default SAS uppercase column names valid R snake-case column names. split_mixed=TRUE split tables contain long short data regarding patient ID one long table one short table. See ?split_mixed_datasets() details. extend_lookup=TRUE improve lookup table additional information. See ?extend_lookup() details. key_columns=get_key_cols() can change default column names patient ID CRF name (used new features). Standalone functions extend_lookup() split_mixed_datasets(). New helper unify(), turns vector duplicate values vector length 1.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/news/index.html","id":"bug-fixes-0-3-0","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"EDCimport 0.3.0 2023/05/19","text":"Reading errors now handled read_trialmaster() instead failing. one XPT file corrupted, resulting object contain error message instead dataset. find_keyword() now robust non-UTF8 characters labels. Option edc_lookup now set even reading cache. SAS formats containing = now work intended.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/news/index.html","id":"edcimport-021-20221101","dir":"Changelog","previous_headings":"","what":"EDCimport 0.2.1 2022/11/01","title":"EDCimport 0.2.1 2022/11/01","text":"CRAN release: 2022-12-02 Import data TrialMaster using tm = read_trialmaster(\"path//archive.zip\"). Search keyword column name label using find_keyword(\"date\", data=tm$.lookup). can also generate lookup table arbitrary list dataframe using build_lookup(my_data). Load datasets global environment using load_list(tm) avoid typing tm$ everywhere. Browse available global options using ?EDCimport_options.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/news/index.html","id":"edcimport-010","dir":"Changelog","previous_headings":"","what":"EDCimport 0.1.0","title":"EDCimport 0.1.0","text":"Draft version","code":""}]
