[{"path":"https://danchaltiel.github.io/EDCimport/articles/postprocessing.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"2 - Post processing","text":"Caution reading , read vignette(\"reading\") learn import database. importing database EDCimport, end edc_database object, can loaded global environment using load_database(). However, EDCimport provides functions improve database loading .","code":""},{"path":"https://danchaltiel.github.io/EDCimport/articles/postprocessing.html","id":"harmonize-subject-id-across-the-database","dir":"Articles","previous_headings":"","what":"Harmonize Subject ID across the database","title":"2 - Post processing","text":"Subject ID column, usually SUBJID CDISC data, primary key, shared almost datasets. Using edc_unify_subjid(), can harmonize column across whole database, becomes factor, consistant datasets. preprocess, can even customize . especially convenient joining data checking missing patients. Note SUBJID column numeric preprocess empty, SUBJID casted numeric.","code":"library(EDCimport) db1 = edc_example() load_database(db1) enrol$subjid %>% class() #> [1] \"integer\" enrol$subjid %>% head() #> [1] 1 2 3 4 5 6  db2 = edc_example() %>%    edc_unify_subjid(preprocess=~paste0(\"#\", .x)) load_database(db2) enrol$subjid %>% class() #> [1] \"factor\" enrol$subjid %>% head() #> [1] #1 #2 #3 #4 #5 #6 #> 50 Levels: #1 #2 #3 #4 #5 #6 #7 #8 #9 #10 #11 #12 #13 #14 #15 #16 #17 ... #50 #missing patients in table `ae` ae$subjid %>%    forcats::fct_count() %>%    dplyr::filter(n==0)  #> # A tibble: 2 × 2 #>   f         n #>   <fct> <int> #> 1 #35       0 #> 2 #37       0"},{"path":"https://danchaltiel.github.io/EDCimport/articles/postprocessing.html","id":"clean-dataset-names","dir":"Articles","previous_headings":"","what":"Clean dataset names","title":"2 - Post processing","text":"database messy EDC software, filled special characters camelCase column names? Fear ! edc_clean_names() can clean dataset names . default, converts names lowercase letters, numbers, underscores . example, since edc_example() already provides clean column names, let’s convert columns uppercase:","code":"library(EDCimport) db = edc_example() %>%    edc_clean_names(toupper) load_database(db) names(enrol) #> [1] \"SUBJID\"     \"AGE\"        \"BIRTH_DATE\" \"ARM\"        \"CRFNAME\"    #> [6] \"CRFSTAT\""},{"path":"https://danchaltiel.github.io/EDCimport/articles/postprocessing.html","id":"split-some-dataset-to-shortlong","dir":"Articles","previous_headings":"","what":"Split some dataset to short+long","title":"2 - Post processing","text":"Note one bit complex, bear , ’ll try make understandable. CRF form contains repeated non-repeated measures, export usually duplicates non-repeated measure. results “mixed” data format, combining “long” “short” structures. (usually call latter “wide”, case really.) example, dataset long_mixed edc_example(), two long-format variables (one value per observation) one wide-format variable (one value per subject). complex CRFs lengthy forms, mixed structure can complicate analysis, repeated non-repeated data may unrelated. edc_split_mixed(), can split dataset two, one short one long:","code":"head(long_mixed) #> # A tibble: 6 × 6 #>   SUBJID CRFNAME                    LONG1 LONG2 SHORT CRFSTAT    #>    <int> <chr>                      <dbl> <dbl> <chr> <chr>      #> 1      1 both short and long data  1.33   11.0  B     Complete   #> 2      1 both short and long data -0.869  10.9  B     Complete   #> 3      2 both short and long data  0.0555 10.0  C     Complete   #> 4      2 both short and long data  0.0491 10.1  C     Incomplete #> 5      3 both short and long data -0.578   9.28 D     Complete   #> 6      3 both short and long data -0.999   9.80 D     Complete db = edc_example() %>%    edc_split_mixed(long_mixed) load_database(db) head(long_mixed_short) #one row per subject #> # A tibble: 6 × 3 #>   subjid crfname                  short #>    <int> <chr>                    <chr> #> 1      1 both short and long data B     #> 2      2 both short and long data C     #> 3      3 both short and long data D     #> 4      4 both short and long data E     #> 5      5 both short and long data F     #> 6      6 both short and long data G head(long_mixed_long)  #one row per observation #> # A tibble: 6 × 4 #>   subjid   long1 long2 crfstat    #>    <int>   <dbl> <dbl> <chr>      #> 1      1  1.33   11.0  Complete   #> 2      1 -0.869  10.9  Complete   #> 3      2  0.0555 10.0  Complete   #> 4      2  0.0491 10.1  Incomplete #> 5      3 -0.578   9.28 Complete   #> 6      3 -0.999   9.80 Complete"},{"path":"https://danchaltiel.github.io/EDCimport/articles/postprocessing.html","id":"you-can-combine","dir":"Articles","previous_headings":"","what":"You can combine!","title":"2 - Post processing","text":"Obviously, functions can piped one another: Don’t hesitate submit feature request think another function can useful others!","code":"db = edc_example() %>%    edc_split_mixed(long_mixed)  %>%    edc_unify_subjid(preprocess=~paste0(\"#\", .x))%>%    edc_clean_names(toupper)  load_database(db)"},{"path":"https://danchaltiel.github.io/EDCimport/articles/reading.html","id":"read-your-database","dir":"Articles","previous_headings":"","what":"Read your database","title":"1 - Read your database","text":"reading vignette, chances requested export EDC software provided directory filled files datasets. Wouldn’t tedious load files one one? Lucky , EDCimport knows better way! Depending type files export directory, use: read_all_sas(), read .sas7bdat files read_all_xpt(), read .xpt files read_all_csv(), read .csv files read_trialmaster() read TrialMaster zip archive. Formats imported metadata file, format_file, can either: procformat.sas file, containing whole PROC FORMAT catalog file (.sas7bcat) data file (.csv .sas7bdat) containing 3 columns: SAS format name (repeated), level, associated label. Use options(edc_var_format_name=\"xxx\", edc_var_level=\"xxx\", edc_var_label=\"xxx\") specify names columns. can load datasets global environment load_database().","code":"library(EDCimport) db = read_all_sas(\"path/to/my/files/folder\", format_file=\"procformat.sas\") print(db) load_database(db) #this also removes `db` to save some RAM mean(dataset1$column5)"},{"path":"https://danchaltiel.github.io/EDCimport/articles/reading.html","id":"explore-your-database","dir":"Articles","previous_headings":"","what":"Explore your database","title":"1 - Read your database","text":"Knowing CRF hand always easy task, EDCimport provide useful tools: edc_lookup(), remember available datasets. edc_find_column() edc_find_value(), search database column/label actual value.","code":"db = edc_example() load_database(db) edc_lookup() #> ── Lookup table - EDCimport example (extraction of 2024-01-01) - EDCimport v0.5. #>   dataset     nrow  ncol  n_id rows_per_id crfname                  #>   <chr>      <dbl> <dbl> <int>       <dbl> <chr>                    #> 1 ae           175     7    48         3.6 Adverse events           #> 2 long_pure    150     4    50         3   long data                #> 3 data1        100     7    50         2   data1                    #> 4 long_mixed   100     6    50         2   both short and long data #> 5 enrol         50     6    50         1   enrol                    #> 6 data2         50     6    50         1   data2                    #> 7 data3         50     7    50         1   data3                    #> 8 short         50     5    50         1   short data edc_find_column(\"date\") #> # A tibble: 11 × 5 #>    dataset crfname names      labels           prop_na #>    <chr>   <chr>   <chr>      <chr>              <dbl> #>  1 data1   data1   date1      Date at visit 1        0 #>  2 data1   data1   date2      Date at visit 2        0 #>  3 data1   data1   date3      Date at visit 3        0 #>  4 enrol   enrol   birth_date Date of birth          0 #>  5 data2   data2   date4      Date at visit 4        0 #>  6 data2   data2   date5      Date at visit 5        0 #>  7 data2   data2   date6      Date at visit 6        0 #>  8 data3   data3   date7      Date at visit 7        0 #>  9 data3   data3   date8      Date at visit 8        0 #> 10 data3   data3   date9      Date at visit 9        0 #> 11 data3   data3   date10     Date at visit 10       0 edc_find_value(\"immune\") #> # A tibble: 7 × 5 #>   subjid dataset column column_label value                   #>   <chr>  <chr>   <chr>  <chr>        <chr>                   #> 1 9      ae      aesoc  AE SOC       Immune system disorders #> 2 24     ae      aesoc  AE SOC       Immune system disorders #> 3 26     ae      aesoc  AE SOC       Immune system disorders #> 4 31     ae      aesoc  AE SOC       Immune system disorders #> 5 46     ae      aesoc  AE SOC       Immune system disorders #> 6 46     ae      aesoc  AE SOC       Immune system disorders #> 7 49     ae      aesoc  AE SOC       Immune system disorders"},{"path":"https://danchaltiel.github.io/EDCimport/articles/reading.html","id":"shiny-browser","dir":"Articles","previous_headings":"","what":"Shiny browser","title":"1 - Read your database","text":"easiest way explore database running edc_viewer(), run local shiny application:","code":"db = edc_example() load_database(db) #this also removes `db` to save some RAM edc_viewer()"},{"path":"https://danchaltiel.github.io/EDCimport/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Dan Chaltiel. Author, maintainer.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Chaltiel D (2025). EDCimport: Import Data EDC Software. R package version 0.5.2.9033, https://danchaltiel.github.io/EDCimport/, https://github.com/DanChaltiel/EDCimport.","code":"@Manual{,   title = {EDCimport: Import Data from EDC Software},   author = {Dan Chaltiel},   year = {2025},   note = {R package version 0.5.2.9033, https://danchaltiel.github.io/EDCimport/},   url = {https://github.com/DanChaltiel/EDCimport}, }"},{"path":[]},{"path":"https://danchaltiel.github.io/EDCimport/index.html","id":"introduction-","dir":"","previous_headings":"","what":"Introduction 📦","title":"Import Data from EDC Software","text":"EDCimport package designed simplify import management Electronic Data Capture (EDC) exports, particularly clinical research settings. opinionated framework, providing multiple streamlined tools importing, cleaning, checking datasets. [!WARNING] package experimental active developement. Retrocompatibility priority moment. reproducibility, use renv set package version.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/index.html","id":"installation-️","dir":"","previous_headings":"","what":"Installation 🛠️","title":"Import Data from EDC Software","text":"","code":"# Install last version available on CRAN install.packages(\"EDCimport\")  # Install development version on Github pak::pak(\"DanChaltiel/EDCimport\")"},{"path":[]},{"path":"https://danchaltiel.github.io/EDCimport/index.html","id":"load-the-data","dir":"","previous_headings":"Features 🚀","what":"Load the data","title":"Import Data from EDC Software","text":"Use one read_all_sas(), read_all_xpt(), read_all_csv(), read_trialmaster(), depending type files export directory. can load datasets global environment load_database().","code":"library(EDCimport) db = read_all_sas(\"path/to/my/files/folder\") print(db) load_database(db) #this also removes `db` to save some RAM mean(dataset1$column5)"},{"path":"https://danchaltiel.github.io/EDCimport/index.html","id":"database-management-tools","dir":"","previous_headings":"Features 🚀","what":"Database management tools","title":"Import Data from EDC Software","text":"EDCimport includes set useful tools help using imported database. See References complete list.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/index.html","id":"database-summary","dir":"","previous_headings":"Features 🚀 > Database management tools","what":"Database summary","title":"Import Data from EDC Software","text":"edc_lookup() returns dataframe containing number rows, columns, patients, CRF name dataset.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/index.html","id":"search-the-whole-database","dir":"","previous_headings":"Features 🚀 > Database management tools","what":"Search the whole database","title":"Import Data from EDC Software","text":"find_keyword() runs global search database given keyword (regex). instance, say looking “date ECG” don’t know , can run find_keyword(\"date\") find_keyword(\"ecg\"). won’t look actual data, though, take much computing power.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/index.html","id":"get-the-last-news-date-of-each-subject","dir":"","previous_headings":"Features 🚀 > Database management tools","what":"Get the last news date of each subject","title":"Import Data from EDC Software","text":"lastnews_table() finds last date subject throughout whole database inform date original dataset column. arguments avoid selecting irrelevant dates. useful get actual followup time fitting survival analyses.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/index.html","id":"data-checking-system","dir":"","previous_headings":"Features 🚀 > Database management tools","what":"Data checking system","title":"Import Data from EDC Software","text":"edc_data_warn() throws warning inconsistency found dataset. interface allows perform multiple checks get report CSV file.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/index.html","id":"join-helpers","dir":"","previous_headings":"Features 🚀 > Database management tools","what":"Join helpers","title":"Import Data from EDC Software","text":"primary key almost always Subject ID, join helpers added reduce code clutter. Currently, edc_left_join(), edc_right_join(), edc_full_join() supported.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/index.html","id":"shiny-browser","dir":"","previous_headings":"Features 🚀 > Database management tools","what":"Shiny browser","title":"Import Data from EDC Software","text":"edc_viewer() runs shiny application browses whole database. HTML interface quicker less cluttered RStudio. also allows filtering Subject ID.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/index.html","id":"swimmer-plot","dir":"","previous_headings":"Features 🚀 > Database management tools","what":"Swimmer Plot","title":"Import Data from EDC Software","text":"edc_swimmerplot() creates swimmer plot date variables whole database. useful find inconsistencies outliers, especially plotly interactive output.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/EDCimport-package.html","id":null,"dir":"Reference","previous_headings":"","what":"EDCimport: Import Data from EDC Software — EDCimport-package","title":"EDCimport: Import Data from EDC Software — EDCimport-package","text":"convenient toolbox import data exported Electronic Data Capture (EDC) software 'TrialMaster'.","code":""},{"path":[]},{"path":"https://danchaltiel.github.io/EDCimport/reference/EDCimport-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"EDCimport: Import Data from EDC Software — EDCimport-package","text":"Maintainer: Dan Chaltiel dan.chaltiel@gmail.com (ORCID)","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/assert_no_duplicate.html","id":null,"dir":"Reference","previous_headings":"","what":"Assert that a dataframe has one row per patient — assert_no_duplicate","title":"Assert that a dataframe has one row per patient — assert_no_duplicate","text":"Check duplicate column holding patient ID pipeable style.  Mostly useful joining two datasets.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/assert_no_duplicate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Assert that a dataframe has one row per patient — assert_no_duplicate","text":"","code":"assert_no_duplicate(df, by = NULL, id_col = get_subjid_cols())"},{"path":"https://danchaltiel.github.io/EDCimport/reference/assert_no_duplicate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Assert that a dataframe has one row per patient — assert_no_duplicate","text":"df dataframe (optional) grouping columns id_col name columns holding patient ID","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/assert_no_duplicate.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Assert that a dataframe has one row per patient — assert_no_duplicate","text":"df dataset, unchanged","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/assert_no_duplicate.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Assert that a dataframe has one row per patient — assert_no_duplicate","text":"","code":"if (FALSE) { # \\dontrun{ #without duplicate => no error, continue the pipeline tibble(subjid=c(1:10)) %>% assert_no_duplicate() %>% nrow()  #with duplicate => throws an error tibble(subjid=c(1:10, 1:2)) %>% assert_no_duplicate() %>% nrow()  #By groups df = tibble(subjid=rep(1:10, 4), visit=rep(c(\"V1\", \"V2\"), 2, each=10),              group=rep(c(\"A\", \"B\"), each=20)) df %>% assert_no_duplicate() #error df %>% assert_no_duplicate(by=c(visit, group)) #no error } # }"},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_clean_names.html","id":null,"dir":"Reference","previous_headings":"","what":"Clean up the names of all datasets — edc_clean_names","title":"Clean up the names of all datasets — edc_clean_names","text":"Clean names datasets database. default, converts names lowercase letters, numbers, underscores .","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_clean_names.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Clean up the names of all datasets — edc_clean_names","text":"","code":"edc_clean_names(database, clean_fun = NULL)"},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_clean_names.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Clean up the names of all datasets — edc_clean_names","text":"database edc_database object, read_trialmaster() EDCimport reading functions. clean_fun cleaning function applied column names.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_clean_names.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Clean up the names of all datasets — edc_clean_names","text":"edc_database object","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_clean_names.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Clean up the names of all datasets — edc_clean_names","text":"","code":"#db = read_trialmaster(\"filename.zip\", pw=\"xx\") db = edc_example() %>%    edc_clean_names() names(db$enrol) #> [1] \"subjid\"     \"age\"        \"birth_date\" \"arm\"        \"crfname\"    #> [6] \"crfstat\""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_crf_plot.html","id":null,"dir":"Reference","previous_headings":"","what":"Show the current CRF status distribution — edc_crf_plot","title":"Show the current CRF status distribution — edc_crf_plot","text":"Generate barplot showing distribution CRF status (Complete, Incomplete, ...) dataset database.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_crf_plot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Show the current CRF status distribution — edc_crf_plot","text":"","code":"edc_crf_plot(   crfstat_col = \"CRFSTAT\",   ...,   details = FALSE,   pal = edc_pal_crf(),   reverse = FALSE,   x_label = \"{dataset}\",   treat_as_worst = NULL,   datasets = get_datasets(),   lookup = edc_lookup() )  edc_pal_crf()"},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_crf_plot.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Show the current CRF status distribution — edc_crf_plot","text":"ggsci:::ggsci_db$lancet[[\"lanonc\"]] %>% dput()","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_crf_plot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Show the current CRF status distribution — edc_crf_plot","text":"crfstat_col column name CRF status ... unused details whether show CRF status levels. FALSE (default), recode status \"Complete\", \"Incomplete\", \"Data\". pal palette, defaulting helper EDCimport:::edc_pal_crf(). names give CRF status levels, \"best\" \"worst\". plot ordered \"worst\" level. reverse whether reverse CRF status level order. x_label glue pattern determining tick label x axis. Available variables ones edc_lookup(): c(\"dataset\", \"nrow\", \"ncol\", \"n_id\", \"rows_per_id\", \"crfname\"). treat_as_worst regex levels treated worst ordering. datasets, lookup internal","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_crf_plot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Show the current CRF status distribution — edc_crf_plot","text":"ggplot","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_crf_plot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Show the current CRF status distribution — edc_crf_plot","text":"","code":"if (FALSE) { # \\dontrun{ #import a TM database and use load_database(), then: edc_crf_plot() + ggtitle(date_extraction) edc_crf_plot(reverse=TRUE) edc_crf_plot(details=TRUE, treat_as_worst=\"No Data\") edc_crf_plot(x_label=\"{crfname} (N={n_id}, n={nrow})\")  p = edc_crf_plot(details=TRUE) p$data$crfstat %>% unique() #> [1] \"Incomplete\"        \"No Data Locked\"    \"No Data\"           \"Signed\"            #> [5] \"Partial Monitored\" \"Monitored\"         \"Complete Locked\"   \"Complete\"  } # }"},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_data_warn.html","id":null,"dir":"Reference","previous_headings":"","what":"Standardized warning system — edc_data_warn","title":"Standardized warning system — edc_data_warn","text":"checking data, filter dataset get problematic rows.  , use either: edc_data_warn() generate standardized warning can forwarded datamanager edc_data_stop() abort script problem serious Database issues traced separate file, identifying row number, file shared data-manager.  Use edc_data_warnings() generate table file.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_data_warn.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Standardized warning system — edc_data_warn","text":"","code":"edc_data_warn(   df,   message,   ...,   issue_n = \"xx\",   max_subjid = 5,   csv_path = FALSE,   col_subjid = get_subjid_cols() )  edc_data_stop(df, message, ..., issue_n, max_subjid, csv_path, col_subjid)  edc_data_warnings()"},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_data_warn.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Standardized warning system — edc_data_warn","text":"df filtered dataframe message message. Can use cli formats. df can accessed using .data special keyword (see example) ... unused issue_n identifying row number max_subjid max number subject ID show message csv_path path save df csv file can shared DM details. col_subjid column name subject ID. Set NULL ignore.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_data_warn.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Standardized warning system — edc_data_warn","text":"df invisibly","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_data_warn.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Standardized warning system — edc_data_warn","text":"","code":"library(dplyr) #>  #> Attaching package: ‘dplyr’ #> The following objects are masked from ‘package:stats’: #>  #>     filter, lag #> The following objects are masked from ‘package:base’: #>  #>     intersect, setdiff, setequal, union db = edc_example() #> Warning: Option \"edc_lookup\" has been overwritten. load_database(db) enrol %>%    filter(age>70) %>%    edc_data_warn(\"Age should not be >70\", issue_n=1) #> Warning: Datasets from this lookup are not available in the global environment. #> ℹ Did you forget to use `EDCimport::load_database(db)` to load the tables? #> This warning is displayed once per session. #> Warning: Issue #01: Age should not be >70 (2 patients: #9 and #12)  enrol %>%    filter(age<25) %>%    edc_data_warn(\"Age should not be <25\", issue_n=2) #> Warning: Issue #02: Age should not be <25 (1 patient: #18)  data1 %>%    filter(n()>1, .by=subjid) %>%    edc_data_warn(\"There are duplicated patients in `data1` ({nrow(.data)} rows)\", issue_n=3) #> Warning: Issue #03: There are duplicated patients in `data1` (100 rows) (50 patients: #> #1, #2, #3, #4, #5, …)  enrol %>%    filter(age<25) %>%    edc_data_warn(\"Age should not be <25\", issue_n=NULL) #> Warning: Age should not be <25 (1 patient: #18)    edc_data_warnings() #> # A tibble: 4 × 4 #>   issue_n message                                             subjid     fun     #>   <chr>   <chr>                                               <list>     <chr>   #> 1 01      Age should not be >70                               <chr [2]>  cli_wa… #> 2 02      Age should not be <25                               <chr [1]>  cli_wa… #> 3 03      There are duplicated patients in `data1` (100 rows) <chr [50]> cli_wa… #> 4 NA      Age should not be <25                               <chr [1]>  cli_wa…  if (FALSE) { # \\dontrun{ enrol %>%    filter(age<25) %>%    edc_data_warn(\"Age should not be <25\", csv_path=\"check/check_age_25.csv\")    enrol %>%    filter(age<25) %>%    edc_data_stop(\"Age should *never* be <25\") } # }"},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_database.html","id":null,"dir":"Reference","previous_headings":"","what":"EDCimport Database — edc_database","title":"EDCimport Database — edc_database","text":"class object represents database, result EDCimport reading function. print() method.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_database.html","id":"functions-returning-edc-database-objects","dir":"Reference","previous_headings":"","what":"Functions returning edc_database objects","title":"EDCimport Database — edc_database","text":"per now, reading functions : read_trialmaster(), read_all_sas(), read_all_xpt(), read_all_csv().","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_database.html","id":"structure","dir":"Reference","previous_headings":"","what":"Structure","title":"EDCimport Database — edc_database","text":"usually usefull query , edc_database object named list containing: datasets source files datetime_extraction date_extraction inferred date data extraction .lookup temporary copy lookup table","code":""},{"path":[]},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_db_to_excel.html","id":null,"dir":"Reference","previous_headings":"","what":"Save the database as an Excel file — edc_db_to_excel","title":"Save the database as an Excel file — edc_db_to_excel","text":"RStudio good showing data, can convenient browse database using MS Excel. function turns whole TM export (named list datasets) Excel workbook, one tab dataset. Use edc_db_to_excel() create file edc_browse_excel() open .","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_db_to_excel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Save the database as an Excel file — edc_db_to_excel","text":"","code":"edc_db_to_excel(   filename = tempfile(fileext = \".xlsx\"),   ...,   datasets = get_datasets(),   overwrite = FALSE,   open = FALSE )  edc_browse_excel()"},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_db_to_excel.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Save the database as an Excel file — edc_db_to_excel","text":"filename path Excel output file. Default temporary file. Use special value TRUE save \"data/database_{date_extraction}.xlsx\". ... unused datasets named list dataframes. Default TM export. overwrite whether overwrite existing file. Default FALSE. open whether open Excel file afterward. Default FALSE.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_db_to_excel.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Save the database as an Excel file — edc_db_to_excel","text":"nothing","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_db_to_excel.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Save the database as an Excel file — edc_db_to_excel","text":"","code":"if (FALSE) { # \\dontrun{   db = edc_example()   load_database(db)     edc_db_to_excel() #default arguments are usually OK   edc_db_to_excel(filename=TRUE) } # }"},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_example.html","id":null,"dir":"Reference","previous_headings":"","what":"Example database — edc_example","title":"Example database — edc_example","text":"list tables simulates extraction clinical database. Used EDCimport examples tests.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_example.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Example database — edc_example","text":"","code":"edc_example(N = 50, seed = 42, outdated = FALSE)"},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_example.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Example database — edc_example","text":"N number patients seed random seed outdated whether simulate times data extraction date","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_example.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Example database — edc_example","text":"list tables class edc_database.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_find_value.html","id":null,"dir":"Reference","previous_headings":"","what":"Search the whole database — edc_find_value","title":"Search the whole database — edc_find_value","text":"Find keyword columns values, datasets database.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_find_value.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Search the whole database — edc_find_value","text":"","code":"edc_find_value(keyword, ignore_case = TRUE, data = get_datasets())  edc_find_column(keyword, ignore_case = TRUE, data = edc_lookup())"},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_find_value.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Search the whole database — edc_find_value","text":"keyword keyword search . Regular expressions supported edc_find_column. ignore_case Logical. TRUE (default), search ignore case differences. data Either lookup table (edc_find_column) list datasets (edc_find_value()).","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_find_value.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Search the whole database — edc_find_value","text":"tibble","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_find_value.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Search the whole database — edc_find_value","text":"","code":"db = edc_example() #> Warning: Option \"edc_lookup\" has been overwritten. load_database(db)  edc_find_value(\"respi\") #> Warning: Could not find 8/8 datasets from the lookup, did you forget to call #> `load_database()` on your import? #> ℹ \"ae\", \"long_pure\", \"data1\", \"long_mixed\", \"enrol\", \"data2\", \"data3\", and #>   \"short\" #> Error in mutate(., column_label = unlist(data_labels[column]) %0% NA): ℹ In argument: `column_label = unlist(data_labels[column]) %0% NA`. #> Caused by error: #> ! object 'column' not found edc_find_value(2010) #> Warning: Could not find 8/8 datasets from the lookup, did you forget to call #> `load_database()` on your import? #> ℹ \"ae\", \"long_pure\", \"data1\", \"long_mixed\", \"enrol\", \"data2\", \"data3\", and #>   \"short\" #> Error in mutate(., column_label = unlist(data_labels[column]) %0% NA): ℹ In argument: `column_label = unlist(data_labels[column]) %0% NA`. #> Caused by error: #> ! object 'column' not found  edc_find_column(\"ad\") #> # A tibble: 1 × 4 #>   dataset crfname        names labels   #>   <chr>   <chr>          <chr> <chr>    #> 1 ae      Adverse events aegr  AE grade edc_find_column(\"date\")  #> # A tibble: 11 × 4 #>    dataset crfname names      labels           #>    <chr>   <chr>   <chr>      <chr>            #>  1 data1   data1   date1      Date at visit 1  #>  2 data1   data1   date2      Date at visit 2  #>  3 data1   data1   date3      Date at visit 3  #>  4 enrol   enrol   birth_date Date of birth    #>  5 data2   data2   date4      Date at visit 4  #>  6 data2   data2   date5      Date at visit 5  #>  7 data2   data2   date6      Date at visit 6  #>  8 data3   data3   date7      Date at visit 7  #>  9 data3   data3   date8      Date at visit 8  #> 10 data3   data3   date9      Date at visit 9  #> 11 data3   data3   date10     Date at visit 10 #with regex edc_find_column(\"\\\\d\") #> # A tibble: 16 × 4 #>    dataset    crfname                  names  labels           #>    <chr>      <chr>                    <chr>  <chr>            #>  1 long_pure  long data                val1a  val1a            #>  2 long_pure  long data                val2a  val2a            #>  3 data1      data1                    date1  Date at visit 1  #>  4 data1      data1                    date2  Date at visit 2  #>  5 data1      data1                    date3  Date at visit 3  #>  6 long_mixed both short and long data long1  long1            #>  7 long_mixed both short and long data long2  long2            #>  8 data2      data2                    date4  Date at visit 4  #>  9 data2      data2                    date5  Date at visit 5  #> 10 data2      data2                    date6  Date at visit 6  #> 11 data3      data3                    date7  Date at visit 7  #> 12 data3      data3                    date8  Date at visit 8  #> 13 data3      data3                    date9  Date at visit 9  #> 14 data3      data3                    date10 Date at visit 10 #> 15 short      short data               val1   val1             #> 16 short      short data               val2   val2             edc_find_column(\"\\\\(\") #you need to escape special characters #> # A tibble: 1 × 4 #>   dataset crfname names labels      #>   <chr>   <chr>   <chr> <chr>       #> 1 enrol   enrol   age   Age (years)"},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_inform_code.html","id":null,"dir":"Reference","previous_headings":"","what":"Shows how many code you wrote — edc_inform_code","title":"Shows how many code you wrote — edc_inform_code","text":"Shows many code wrote","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_inform_code.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Shows how many code you wrote — edc_inform_code","text":"","code":"edc_inform_code(main = \"main.R\", Rdir = \"R/\")"},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_inform_code.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Shows how many code you wrote — edc_inform_code","text":"main main R file, sources ones Rdir R directory, sourced R files located","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_inform_code.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Shows how many code you wrote — edc_inform_code","text":"Nothing","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_left_join.html","id":null,"dir":"Reference","previous_headings":"","what":"Join within the EDCimport framework — edc_left_join","title":"Join within the EDCimport framework — edc_left_join","text":"Perform join default Subject ID default suffix name y dataset. See [dplyr::mutate-joins] description join logic.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_left_join.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Join within the EDCimport framework — edc_left_join","text":"","code":"edc_left_join(   x,   y,   by = NULL,   suffix = NULL,   cols = everything(),   remove_dups = TRUE )"},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_left_join.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Join within the EDCimport framework — edc_left_join","text":"x, y Data frames join key join . Defaults get_subjid_cols() suffix disambiguation suffix. Defaults actual name y dataset. cols columns select y joining. remove_dups Whether remove columns y already exist x.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_left_join.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Join within the EDCimport framework — edc_left_join","text":"dataframe","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_left_join.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Join within the EDCimport framework — edc_left_join","text":"","code":"db = edc_example() #> Warning: Option \"edc_lookup\" has been overwritten. load_database(db) data1$common = data2$common = \"Common\" x = enrol %>%    edc_left_join(data2) %>%    edc_right_join(data1)    #crfname get a suffix, common  names(x) #>  [1] \"subjid\"                            \"age\"                               #>  [3] \"birth_date\"                        \"arm\"                               #>  [5] \"crfname\"                           \"crfstat\"                           #>  [7] \"date4\"                             \"date5\"                             #>  [9] \"date6\"                             \"crfname_<tibble[,6]>\"              #> [11] \"common\"                            \"date1\"                             #> [13] \"date2\"                             \"date3\"                             #> [15] \"x\"                                 \"crfname_<tibble[,6]>_<tibble[,6]>\""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_lookup.html","id":null,"dir":"Reference","previous_headings":"","what":"Retrieve the lookup table from options — edc_lookup","title":"Retrieve the lookup table from options — edc_lookup","text":"Retrieve lookup table options","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_lookup.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Retrieve the lookup table from options — edc_lookup","text":"","code":"edc_lookup(..., check = TRUE)"},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_lookup.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Retrieve the lookup table from options — edc_lookup","text":"... passed dplyr::arrange() check whether check internal consistency","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_lookup.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Retrieve the lookup table from options — edc_lookup","text":"lookup dataframe summarizing database import","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_lookup.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Retrieve the lookup table from options — edc_lookup","text":"","code":"db = edc_example() #> Warning: Option \"edc_lookup\" has been overwritten. load_database(db) edc_lookup() #> ── Lookup table - EDCimport example (extraction of 2024-01-01) - EDCimport v0.5. #>   dataset     nrow  ncol  n_id rows_per_id crfname                  #>   <chr>      <dbl> <dbl> <int>       <dbl> <chr>                    #> 1 ae           175     7    48         3.6 Adverse events           #> 2 long_pure    150     4    50         3   long data                #> 3 data1        100     7    50         2   data1                    #> 4 long_mixed   100     6    50         2   both short and long data #> 5 enrol         50     6    50         1   enrol                    #> 6 data2         50     6    50         1   data2                    #> 7 data3         50     7    50         1   data3                    #> 8 short         50     5    50         1   short data               edc_lookup(dataset) #> ── Lookup table - EDCimport example (extraction of 2024-01-01) - EDCimport v0.5. #>   dataset     nrow  ncol  n_id rows_per_id crfname                  #>   <chr>      <dbl> <dbl> <int>       <dbl> <chr>                    #> 1 ae           175     7    48         3.6 Adverse events           #> 2 data1        100     7    50         2   data1                    #> 3 data2         50     6    50         1   data2                    #> 4 data3         50     7    50         1   data3                    #> 5 enrol         50     6    50         1   enrol                    #> 6 long_mixed   100     6    50         2   both short and long data #> 7 long_pure    150     4    50         3   long data                #> 8 short         50     5    50         1   short data"},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_options.html","id":null,"dir":"Reference","previous_headings":"","what":"Set global options for EDCimport — edc_options","title":"Set global options for EDCimport — edc_options","text":"Use function manage EDCimport parameters globally taking advantage autocompletion.  Use edc_peek_options() see option currently set edc_reset_options() set options back default.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_options.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set global options for EDCimport — edc_options","text":"","code":"edc_options(   ...,   trialmaster_pw,   path_7zip,   edc_lookup,   edc_subjid_ref,   edc_plotly,   edc_fct_yesno,   edc_cols_subjid,   edc_cols_meta,   edc_cols_id,   edc_cols_crfname,   edc_meta_cols_pct,   edc_warn_max_subjid,   edc_read_verbose,   edc_correction_verbose,   edc_get_key_cols_verbose,   edc_lookup_overwrite_warn,   .local = FALSE )"},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_options.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set global options for EDCimport — edc_options","text":"... unused trialmaster_pw password trialmaster zip archive. instance, can use edc_options(trialmaster_pw=\"my_pwd\") console per session, write password clear R code path_7zip path 7zip executable. Default \"C:/Program Files/7-Zip/\". edc_lookup (Internal) reference lookup table (usually .lookup). usually changed manually. edc_subjid_ref used edc_warn_patient_diffs vector reference subject IDs. usually write edc_options(edc_subjid_ref=enrolres$subjid). edc_plotly used edc_swimmerplot whether use plotly visualize plot. edc_fct_yesno used fct_yesno list values considered Yes/values. Defaults get_yesno_lvl(). edc_cols_subjid, edc_cols_meta name columns holding subject id (default c(\"ptno\", \"subjid\")) CRF form name (default c(\"crfname\")). case-insensitive. edc_cols_id, edc_cols_crfname deprecated edc_meta_cols_pct minimal proportion datasets column reach considered \"meta\" edc_warn_max_subjid max number subject IDs show edc_data_warn edc_read_verbose, edc_correction_verbose, edc_get_key_cols_verbose verbosity output functions read_trialmaster read_all_xpt, manual_correction. example, set edc_options(edc_read_verbose=0) silence first 2. edc_lookup_overwrite_warn default TRUE. Whether warning overwriting .lookup (like reading 2 databases successively) .local TRUE, effect apply local frame (internally using rlang::local_options())","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_options.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Set global options for EDCimport — edc_options","text":"Nothing, called side effects","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_patient_gridplot.html","id":null,"dir":"Reference","previous_headings":"","what":"Patient gridplot — edc_patient_gridplot","title":"Patient gridplot — edc_patient_gridplot","text":"Draw gridplot giving, patient dataset, whether patient present dataset. Data drawn get_datasets.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_patient_gridplot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Patient gridplot — edc_patient_gridplot","text":"","code":"edc_patient_gridplot(   sort_rows = TRUE,   sort_cols = TRUE,   gradient = FALSE,   axes_flip = FALSE,   show_grid = TRUE,   preprocess = NULL,   palette = c(Yes = \"#00468BFF\", No = \"#ED0000FF\"),   datasets = get_datasets(),   lookup = edc_lookup() )"},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_patient_gridplot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Patient gridplot — edc_patient_gridplot","text":"sort_rows whether sort patients \"present datasets\" \"present least datasets\" sort_cols whether sort datasets \"containing patients\" \"containing least patients\" gradient whether add color gradient repeating measures axes_flip whether flip axes, patients Y axis datasets X axis show_grid whether show grid preprocess function preprocess patient ID, e.g. .numeric, custom function string replacement palette colors use datasets, lookup internal","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_patient_gridplot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Patient gridplot — edc_patient_gridplot","text":"ggplot object","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_patient_gridplot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Patient gridplot — edc_patient_gridplot","text":"","code":"if (FALSE) { # \\dontrun{   tm = read_trialmaster(\"path/to/archive.zip\")   load_database(db)   edc_patient_gridplot(sort_rows=FALSE, sort_cols=FALSE)   edc_patient_gridplot(axes_flip=TRUE, show_grid=TRUE,                        preprocess=~str_remove(.x, \"\\\\D*\")) #remove all non-digits } # }"},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_peek_options.html","id":null,"dir":"Reference","previous_headings":"","what":"See which EDCimport option is currently set. — edc_peek_options","title":"See which EDCimport option is currently set. — edc_peek_options","text":"See EDCimport option currently set.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_peek_options.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"See which EDCimport option is currently set. — edc_peek_options","text":"","code":"edc_peek_options(keep_null = FALSE)"},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_peek_options.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"See which EDCimport option is currently set. — edc_peek_options","text":"keep_null set TRUE get list","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_peek_options.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"See which EDCimport option is currently set. — edc_peek_options","text":"named list EDCimport options","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_population_plot.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot the populations — edc_population_plot","title":"Plot the populations — edc_population_plot","text":"RCT, usually several populations analysis, function allow show patient population graphically.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_population_plot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot the populations — edc_population_plot","text":"","code":"edc_population_plot(x, id_per_row = 50, ref = \"first\")"},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_population_plot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot the populations — edc_population_plot","text":"x named list subject ID, numeric factor. id_per_row number patients per rows. ref whole population. Default first member x.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_population_plot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot the populations — edc_population_plot","text":"ggplot","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_population_plot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot the populations — edc_population_plot","text":"","code":"#in real word code, use filter and pull to get these vectors pop_total = c(1:180) %>% setdiff(55) #screen failure, no patient 55 pop_itt = pop_total %>% setdiff(10) #patient 10 has had the wrong treatment pop_safety = pop_total %>% setdiff(c(40,160)) #patients 40 and 160 didn't receive any treatment pop_m_itt = pop_total %>% setdiff(c(40,160,80)) #patient 80 had a wrong inclusion criterion pop_evaluable = pop_total %>% setdiff(c(40,160,101,147,186)) #patients with no recist evaluation  l = list(   \"Total population\"=pop_total,   \"ITT population\"=pop_itt,   \"Safety population\"=pop_safety,   \"mITT population\"=pop_m_itt,   \"Evaluable population\"=pop_evaluable ) edc_population_plot(l)  edc_population_plot(l[-1], ref=pop_total)  edc_population_plot(l, ref=1:200)  edc_population_plot(l, id_per_row=60)"},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_reset_options.html","id":null,"dir":"Reference","previous_headings":"","what":"Reset all EDCimport options. — edc_reset_options","title":"Reset all EDCimport options. — edc_reset_options","text":"Reset EDCimport options.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_reset_options.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reset all EDCimport options. — edc_reset_options","text":"","code":"edc_reset_options(   except = c(\"edc_lookup\", \"trialmaster_pw\", \"path_7zip\"),   quiet = FALSE )"},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_reset_options.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reset all EDCimport options. — edc_reset_options","text":"except options reset default quiet set TRUE remove message.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_reset_options.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Reset all EDCimport options. — edc_reset_options","text":"Nothing, called side effects","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_split_mixed.html","id":null,"dir":"Reference","previous_headings":"","what":"Split mixed datasets — edc_split_mixed","title":"Split mixed datasets — edc_split_mixed","text":"Split mixed tables, .e. tables hold long data (N values per patient) short data (one value per patient, duplicated N lines), one long table one short table.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_split_mixed.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Split mixed datasets — edc_split_mixed","text":"","code":"edc_split_mixed(   database,   datasets = everything(),   ...,   ignore_cols = NULL,   verbose = FALSE )"},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_split_mixed.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Split mixed datasets — edc_split_mixed","text":"database edc_database object, read_trialmaster() EDCimport reading functions. datasets datasets split database ... used, ensure arguments named ignore_cols columns ignore long tables. Default getOption(\"edc_cols_crfname\", \"CRFNAME\"). Case-insensitive. Avoid splitting tables useless columns. verbose whether print informations process.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_split_mixed.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Split mixed datasets — edc_split_mixed","text":"edc_database object","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_split_mixed.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Split mixed datasets — edc_split_mixed","text":"","code":"#db = read_trialmaster(\"filename.zip\", pw=\"xx\") db = edc_example() %>%    edc_split_mixed(c(ae, starts_with(\"long\")),                    ignore_cols=\"crfstat\") #> Warning: Option \"edc_lookup\" has been overwritten.    names(db) #>  [1] \"enrol\"               \"data1\"               \"data2\"               #>  [4] \"data3\"               \"short\"               \"long_pure\"           #>  [7] \"long_mixed\"          \"ae\"                  \"datetime_extraction\" #> [10] \"date_extraction\"     \".lookup\"             \"ae_short\"            #> [13] \"ae_long\"             \"long_mixed_short\"    \"long_mixed_long\"     edc_lookup() #> ── Lookup table (extraction of 2024-01-01)  ──────────────────────────────────── #>    dataset           nrow  ncol  n_id rows_per_id crfname                  #>    <chr>            <dbl> <dbl> <int>       <dbl> <chr>                    #>  1 ae                 175     7    48         3.6 Adverse events           #>  2 ae_long            175     5    48         3.6 Adverse events           #>  3 ae_short            48     3    48         1   Adverse events           #>  4 long_pure          150     4    50         3   long data                #>  5 data1              100     7    50         2   data1                    #>  6 long_mixed         100     6    50         2   both short and long data #>  7 long_mixed_long    100     4    50         2   both short and long data #>  8 enrol               50     6    50         1   enrol                    #>  9 data2               50     6    50         1   data2                    #> 10 data3               50     7    50         1   data3                    #> 11 short               50     5    50         1   short data               #> 12 long_mixed_short    50     3    50         1   both short and long data  db$ae #`aesoc`, `aegr`, and `sae` are long, but `n_ae` is short #> # A tibble: 175 × 7 #>    subjid crfname        aesoc                          aegr  n_ae sae   crfstat #>     <int> <chr>          <chr>                         <int> <int> <fct> <chr>   #>  1      1 Adverse events Endocrine disorders               2     5 No    Incomp… #>  2      1 Adverse events Gastrointestinal disorders        2     5 No    Comple… #>  3      1 Adverse events Reproductive system and brea…     2     5 No    Comple… #>  4      1 Adverse events Renal and urinary disorders       3     5 No    Comple… #>  5      1 Adverse events Neoplasms benign, malignant …     1     5 No    Comple… #>  6      2 Adverse events Vascular disorders                3     5 No    Incomp… #>  7      2 Adverse events Nervous system disorders          3     5 No    Comple… #>  8      2 Adverse events Injury, poisoning and proced…     1     5 No    Comple… #>  9      2 Adverse events Hepatobiliary disorders           1     5 No    Comple… #> 10      2 Adverse events Injury, poisoning and proced…     2     5 No    Comple… #> # ℹ 165 more rows  db$ae_short #> # A tibble: 48 × 3 #>    subjid crfname         n_ae #>     <int> <chr>          <int> #>  1      1 Adverse events     5 #>  2      2 Adverse events     5 #>  3      3 Adverse events     2 #>  4      4 Adverse events     4 #>  5      5 Adverse events     3 #>  6      6 Adverse events     3 #>  7      7 Adverse events     4 #>  8      8 Adverse events     1 #>  9      9 Adverse events     4 #> 10     10 Adverse events     4 #> # ℹ 38 more rows db$ae_long #> # A tibble: 175 × 5 #>    subjid aesoc                                               aegr sae   crfstat #>     <int> <chr>                                              <int> <fct> <chr>   #>  1      1 Endocrine disorders                                    2 No    Incomp… #>  2      1 Gastrointestinal disorders                             2 No    Comple… #>  3      1 Reproductive system and breast disorders               2 No    Comple… #>  4      1 Renal and urinary disorders                            3 No    Comple… #>  5      1 Neoplasms benign, malignant and unspecified (incl…     1 No    Comple… #>  6      2 Vascular disorders                                     3 No    Incomp… #>  7      2 Nervous system disorders                               3 No    Comple… #>  8      2 Injury, poisoning and procedural complications         1 No    Comple… #>  9      2 Hepatobiliary disorders                                1 No    Comple… #> 10      2 Injury, poisoning and procedural complications         2 No    Comple… #> # ℹ 165 more rows"},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_swimmerplot.html","id":null,"dir":"Reference","previous_headings":"","what":"Swimmer plot of all dates columns — edc_swimmerplot","title":"Swimmer plot of all dates columns — edc_swimmerplot","text":"Join tables id date columns build ggplot (plotly plotly=TRUE) showing dates patients. allows outliers easily identified.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_swimmerplot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Swimmer plot of all dates columns — edc_swimmerplot","text":"","code":"edc_swimmerplot(   ...,   group = NULL,   origin = NULL,   id_lim = NULL,   exclude = NULL,   id = get_subjid_cols(),   time_unit = c(\"days\", \"weeks\", \"months\", \"years\"),   aes_color = c(\"variable\", \"label\"),   plotly = getOption(\"edc_plotly\", FALSE),   .lookup = \"deprecated\" )"},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_swimmerplot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Swimmer plot of all dates columns — edc_swimmerplot","text":"... used group grouping variable, given \"dataset$column\" origin variable consider time 0, given \"dataset$column\" id_lim numeric vector length 2 providing minimum maximum id subset . exclude character vector variables exclude, form dataset$column. Can regex, $ symbols count. Case-insensitive. id patient identifier. coerced numeric possible. time_unit origin!=NULL, unit measure time. One c(\"days\", \"weeks\", \"months\", \"years\"). aes_color either variable (\"{dataset} - {column}\") label (column label) plotly whether use {plotly} get interactive plot .lookup deprecated","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_swimmerplot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Swimmer plot of all dates columns — edc_swimmerplot","text":"either plotly ggplot","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_swimmerplot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Swimmer plot of all dates columns — edc_swimmerplot","text":"","code":"#db = read_trialmaster(\"filename.zip\", pw=\"xx\") db = edc_example() #> Warning: Option \"edc_lookup\" has been overwritten. load_database(db) p = edc_swimmerplot(id_lim=c(5,45)) #> Warning: Could not find 8/8 datasets from the lookup, did you forget to call #> `load_database()` on your import? #> ℹ \"ae\", \"long_pure\", \"data1\", \"long_mixed\", \"enrol\", \"data2\", \"data3\", and #>   \"short\" #> Error: None of the datasets contains an identifier column #> ℹ `id`=\"subjid\" p2 = edc_swimmerplot(origin=\"enrol$birth_date\", time_unit=\"weeks\",                       exclude=c(\"DATA1$DATE2\", \"data3$.*\")) #> Warning: Could not find 8/8 datasets from the lookup, did you forget to call #> `load_database()` on your import? #> ℹ \"ae\", \"long_pure\", \"data1\", \"long_mixed\", \"enrol\", \"data2\", \"data3\", and #>   \"short\" #> Error: None of the datasets contains an identifier column #> ℹ `id`=\"subjid\" p3 = edc_swimmerplot(group=\"enrol$arm\", aes_color=\"label\") #> Warning: Could not find 8/8 datasets from the lookup, did you forget to call #> `load_database()` on your import? #> ℹ \"ae\", \"long_pure\", \"data1\", \"long_mixed\", \"enrol\", \"data2\", \"data3\", and #>   \"short\" #> Error: None of the datasets contains an identifier column #> ℹ `id`=\"subjid\" if (FALSE) { # \\dontrun{ #save the plotly plot as HTML to share it save_plotly(p, \"edc_swimmerplot.html\") } # }"},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_unify_subjid.html","id":null,"dir":"Reference","previous_headings":"","what":"Harmonize the subject ID of the database — edc_unify_subjid","title":"Harmonize the subject ID of the database — edc_unify_subjid","text":"Turns subject ID columns datasets factor containing levels subjects database. Avoid problems joining tables, checks can performed levels.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_unify_subjid.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Harmonize the subject ID of the database — edc_unify_subjid","text":"","code":"edc_unify_subjid(database, preprocess = NULL, col_subjid = NULL)"},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_unify_subjid.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Harmonize the subject ID of the database — edc_unify_subjid","text":"database edc_database object, read_trialmaster() EDCimport reading functions. preprocess optional function modify subject ID column. Default .numeric() applicable identity() otherwise. See examples. col_subjid names columns holding subject ID (character)","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_unify_subjid.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Harmonize the subject ID of the database — edc_unify_subjid","text":"database, subject id modified","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_unify_subjid.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Harmonize the subject ID of the database — edc_unify_subjid","text":"","code":"db = edc_example() #> Warning: Option \"edc_lookup\" has been overwritten. db$enrol = head(db$enrol, 10) db$enrol$subjid %>% head() #> [1] 1 2 3 4 5 6 db = edc_unify_subjid(db) db$enrol$subjid %>% head() #> [1] 1 2 3 4 5 6 #> 50 Levels: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 ... 50 db = edc_unify_subjid(db, preprocess=function(x) paste0(\"#\", x)) db$enrol$subjid %>% head() #> [1] #1 #2 #3 #4 #5 #6 #> 50 Levels: #1 #2 #3 #4 #5 #6 #7 #8 #9 #10 #11 #12 #13 #14 #15 #16 #17 ... #50"},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_viewer.html","id":null,"dir":"Reference","previous_headings":"","what":"Shiny data explorer — edc_viewer","title":"Shiny data explorer — edc_viewer","text":"Run Shiny application allows browse datasets.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_viewer.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Shiny data explorer — edc_viewer","text":"","code":"edc_viewer(background = TRUE, port = 1209)"},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_viewer.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Shiny data explorer — edc_viewer","text":"background Whether app run background process. port TCP port application listen .","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_warn_extraction_date.html","id":null,"dir":"Reference","previous_headings":"","what":"Warn if extraction is too old — edc_warn_extraction_date","title":"Warn if extraction is too old — edc_warn_extraction_date","text":"Warn extraction old","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_warn_extraction_date.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Warn if extraction is too old — edc_warn_extraction_date","text":"","code":"edc_warn_extraction_date(max_days = 30)"},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_warn_extraction_date.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Warn if extraction is too old — edc_warn_extraction_date","text":"max_days max acceptable age data","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_warn_extraction_date.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Warn if extraction is too old — edc_warn_extraction_date","text":"nothing","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_warn_extraction_date.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Warn if extraction is too old — edc_warn_extraction_date","text":"","code":"db = edc_example() #> Warning: Option \"edc_lookup\" has been overwritten. load_database(db) edc_warn_extraction_date() #> Error in edc_warn_extraction_date(): object 'datetime_extraction' not found"},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_warn_patient_diffs.html","id":null,"dir":"Reference","previous_headings":"","what":"Check the validity of the subject ID column — edc_warn_patient_diffs","title":"Check the validity of the subject ID column — edc_warn_patient_diffs","text":"Compare subject ID vector study's reference subject ID (usually something like enrolres$subjid), warn patient missing extra. check_subjid() old, deprecated name.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_warn_patient_diffs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check the validity of the subject ID column — edc_warn_patient_diffs","text":"","code":"edc_warn_patient_diffs(   x,   ref = getOption(\"edc_subjid_ref\"),   issue_n = \"xx\",   data_name = NULL,   col_subjid = get_subjid_cols() )"},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_warn_patient_diffs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check the validity of the subject ID column — edc_warn_patient_diffs","text":"x subject ID vector check, dataframe ID column guessed ref reference subject ID. usually set edc_options(edc_subjid_ref=xxx). See example. issue_n identifying row number data_name name data (warning message) col_subjid name subject ID column x dataframe.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_warn_patient_diffs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check the validity of the subject ID column — edc_warn_patient_diffs","text":"nothing, called errors/warnings","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_warn_patient_diffs.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check the validity of the subject ID column — edc_warn_patient_diffs","text":"","code":"db = edc_example() #> Warning: Option \"edc_lookup\" has been overwritten. load_database(db) options(edc_subjid_ref=enrol$subjid) #usually, you set something like: #options(edc_subjid_ref=enrolres$subjid) edc_warn_patient_diffs(data1) data1 %>% dplyr::filter(subjid>1) %>% edc_warn_patient_diffs(issue_n=NULL) #> Warning: `.` has patient discrepancies: #> ℹ Missing: 1 patient: #1 edc_warn_patient_diffs(c(data1$subjid, 99, 999)) #> Warning: Issue #xx: `c(data1$subjid, 99, 999)` has patient discrepancies: #> ℹ Extra: 2 patients: #99 and #999"},{"path":"https://danchaltiel.github.io/EDCimport/reference/fct_yesno.html","id":null,"dir":"Reference","previous_headings":"","what":"Format factor levels as Yes/No — fct_yesno","title":"Format factor levels as Yes/No — fct_yesno","text":"Format factor levels arbitrary values Yes/(Yes always first) leaving untouched vectors contain information.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/fct_yesno.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Format factor levels as Yes/No — fct_yesno","text":"","code":"fct_yesno(   x,   input = list(yes = c(\"Yes\", \"Oui\"), no = c(\"No\", \"Non\")),   output = c(\"Yes\", \"No\"),   strict = FALSE,   mutate_character = TRUE,   fail = TRUE )"},{"path":"https://danchaltiel.github.io/EDCimport/reference/fct_yesno.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Format factor levels as Yes/No — fct_yesno","text":"x vector type/class. input list values considered \"yes\" \"\". output output factor levels. strict whether match input strictly use stringr::str_detect find . mutate_character whether turn characters factor. fail whether fail levels recoded yes/.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/fct_yesno.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Format factor levels as Yes/No — fct_yesno","text":"factor, x untouched.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/fct_yesno.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Format factor levels as Yes/No — fct_yesno","text":"","code":"fct_yesno(c(\"No\", \"Yes\")) #levels are in order #> [1] No  Yes #> Levels: Yes No  set.seed(42) N=6 x = tibble(   a=sample(c(\"Yes\", \"No\"), size=N, replace=TRUE),   b=sample(c(\"Oui\", \"Non\"), size=N, replace=TRUE),   c=sample(0:1, size=N, replace=TRUE),   d=sample(c(TRUE, FALSE), size=N, replace=TRUE),   e=sample(c(\"1-Yes\", \"0-No\"), size=N, replace=TRUE),      y=sample(c(\"aaa\", \"bbb\", \"ccc\"), size=N, replace=TRUE),   z=1:N, )   x           #> # A tibble: 6 × 7 #>   a     b         c d     e     y         z #>   <chr> <chr> <int> <lgl> <chr> <chr> <int> #> 1 Yes   Non       0 FALSE 1-Yes bbb       1 #> 2 Yes   Non       1 FALSE 0-No  ccc       2 #> 3 Yes   Oui       0 TRUE  1-Yes bbb       3 #> 4 Yes   Non       0 TRUE  1-Yes aaa       4 #> 5 No    Oui       1 TRUE  1-Yes bbb       5 #> 6 No    Non       1 TRUE  1-Yes bbb       6 #y and z are left untouched (or throw an error if fail=TRUE)    sapply(x, fct_yesno, fail=FALSE) #>      a   b   c   d   e   y     z   #> [1,] \"1\" \"2\" \"2\" \"2\" \"1\" \"bbb\" \"1\" #> [2,] \"1\" \"2\" \"1\" \"2\" \"2\" \"ccc\" \"2\" #> [3,] \"1\" \"1\" \"2\" \"1\" \"1\" \"bbb\" \"3\" #> [4,] \"1\" \"2\" \"2\" \"1\" \"1\" \"aaa\" \"4\" #> [5,] \"2\" \"1\" \"1\" \"1\" \"1\" \"bbb\" \"5\" #> [6,] \"2\" \"2\" \"1\" \"1\" \"1\" \"bbb\" \"6\"  # as \"1-Yes\" is not in `input`, x$e is untouched/fails if strict=TRUE fct_yesno(x$e) #> [1] Yes No  Yes Yes Yes Yes #> Levels: Yes No fct_yesno(x$e, strict=TRUE, fail=FALSE)  #> [1] \"1-Yes\" \"0-No\"  \"1-Yes\" \"1-Yes\" \"1-Yes\" \"1-Yes\" fct_yesno(x$e, output=c(\"Ja\", \"Nein\")) #> [1] Ja   Nein Ja   Ja   Ja   Ja   #> Levels: Ja Nein"},{"path":"https://danchaltiel.github.io/EDCimport/reference/get_common_cols.html","id":null,"dir":"Reference","previous_headings":"","what":"Get columns that are common to multiple datasets — get_common_cols","title":"Get columns that are common to multiple datasets — get_common_cols","text":"Attempt list columns database group ones common datasets. Useful find keys pivot summarise data.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/get_common_cols.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get columns that are common to multiple datasets — get_common_cols","text":"","code":"get_common_cols(lookup = edc_lookup(), min_datasets = 3)  # S3 method for class 'common_cols' summary(object, ...)"},{"path":"https://danchaltiel.github.io/EDCimport/reference/get_common_cols.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get columns that are common to multiple datasets — get_common_cols","text":"lookup lookup table, default edc_lookup() min_datasets minimal number datasets considered object object class \"common_cols\" ... unused","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/get_common_cols.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get columns that are common to multiple datasets — get_common_cols","text":"tibble class \"common_cols\"","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/get_common_cols.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get columns that are common to multiple datasets — get_common_cols","text":"","code":"db = edc_example() #> Warning: Option \"edc_lookup\" has been overwritten. load_database(db) x = get_common_cols(min_datasets=1) x #> # A tibble: 28 × 7 #>    column     name_in datasets  n_datasets pct_datasets datasets_in datasets_out #>    <chr>      <list>  <list>         <int>        <dbl> <chr>       <chr>        #>  1 crfname    <lgl>   <chr [8]>          8        1     ae, long_p… \"\"           #>  2 subjid     <lgl>   <chr [8]>          8        1     ae, long_p… \"\"           #>  3 crfstat    <lgl>   <chr [7]>          7        0.875 ae, data1,… \"long_pure\"  #>  4 aegr       <lgl>   <chr [1]>          1        0.125 ae          \"long_pure,… #>  5 aesoc      <lgl>   <chr [1]>          1        0.125 ae          \"long_pure,… #>  6 age        <lgl>   <chr [1]>          1        0.125 enrol       \"ae, long_p… #>  7 arm        <lgl>   <chr [1]>          1        0.125 enrol       \"ae, long_p… #>  8 birth_date <lgl>   <chr [1]>          1        0.125 enrol       \"ae, long_p… #>  9 date1      <lgl>   <chr [1]>          1        0.125 data1       \"ae, long_p… #> 10 date10     <lgl>   <chr [1]>          1        0.125 data3       \"ae, long_p… #> # ℹ 18 more rows summary(x) #> # A tibble: 3 × 7 #>   pct_datasets n_datasets n_distinct_datasets n_columns columns    datasets    #>   <chr>             <int>               <int>     <int> <list>     <list>      #> 1 100%                  8                   1         2 <chr [2]>  <list [2]>  #> 2 88%                   7                   1         1 <chr [1]>  <list [1]>  #> 3 12%                   1                   8        25 <chr [25]> <list [25]> #> # ℹ 1 more variable: columns_str <chr>"},{"path":"https://danchaltiel.github.io/EDCimport/reference/get_datasets.html","id":null,"dir":"Reference","previous_headings":"","what":"Retrieve the datasets as a list of data.frames — get_datasets","title":"Retrieve the datasets as a list of data.frames — get_datasets","text":"Get datasets lookup table list data.frames.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/get_datasets.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Retrieve the datasets as a list of data.frames — get_datasets","text":"","code":"get_datasets(lookup = edc_lookup(), envir = parent.frame())"},{"path":"https://danchaltiel.github.io/EDCimport/reference/get_datasets.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Retrieve the datasets as a list of data.frames — get_datasets","text":"lookup lookup table envir (internal use)","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/get_datasets.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Retrieve the datasets as a list of data.frames — get_datasets","text":"list datasets","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/lastnews_table.html","id":null,"dir":"Reference","previous_headings":"","what":"Get a table with the latest date for each patient — lastnews_table","title":"Get a table with the latest date for each patient — lastnews_table","text":"function search date columns every tables returns latest date patient variable comes . Useful survival analysis get right censoring time.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/lastnews_table.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get a table with the latest date for each patient — lastnews_table","text":"","code":"lastnews_table(   except = NULL,   with_ties = FALSE,   show_delta = FALSE,   numeric_id = TRUE,   prefer = NULL,   regex = FALSE,   warn_if_future = TRUE )"},{"path":"https://danchaltiel.github.io/EDCimport/reference/lastnews_table.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get a table with the latest date for each patient — lastnews_table","text":"except datasets/columns searched. Example: scheduled visit patient may died attending considered. with_ties case tie, whether return first origin (FALSE) origins share tie (TRUE). show_delta whether compute difference last prefer date actual last date numeric_id set FALSE patient ID column numeric prefer preferred origins event tie. Usually followup table. regex whether consider except prefer regex. warn_if_future whether show warning dates extraction date. Can also csv file path save warning csv (see csv_path argument edc_data_warn).","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/lastnews_table.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get a table with the latest date for each patient — lastnews_table","text":"dataframe","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/lastnews_table.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get a table with the latest date for each patient — lastnews_table","text":"","code":"db = edc_example() #> Warning: Option \"edc_lookup\" has been overwritten. load_database(db) lastnews_table() #> # A tibble: 50 × 5 #>    subjid last_date           origin_data origin_col origin_label     #>     <dbl> <dttm>              <chr>       <chr>      <chr>            #>  1      1 2010-08-01 18:59:37 data2       date4      Date at visit 4  #>  2      2 2010-07-31 15:32:45 data2       date4      Date at visit 4  #>  3      3 2010-07-22 11:24:37 data2       date5      Date at visit 5  #>  4      4 2010-07-23 20:38:32 data3       date10     Date at visit 10 #>  5      5 2010-07-15 07:09:47 data3       date10     Date at visit 10 #>  6      6 2010-07-20 12:27:00 data3       date10     Date at visit 10 #>  7      7 2010-07-28 16:24:09 data3       date9      Date at visit 9  #>  8      8 2010-07-19 15:24:18 data3       date9      Date at visit 9  #>  9      9 2010-08-11 03:48:27 data3       date9      Date at visit 9  #> 10     10 2010-07-30 20:41:23 data3       date10     Date at visit 10 #> # ℹ 40 more rows lastnews_table(except=\"db3\") #> # A tibble: 50 × 5 #>    subjid last_date           origin_data origin_col origin_label     #>     <dbl> <dttm>              <chr>       <chr>      <chr>            #>  1      1 2010-08-01 18:59:37 data2       date4      Date at visit 4  #>  2      2 2010-07-31 15:32:45 data2       date4      Date at visit 4  #>  3      3 2010-07-22 11:24:37 data2       date5      Date at visit 5  #>  4      4 2010-07-23 20:38:32 data3       date10     Date at visit 10 #>  5      5 2010-07-15 07:09:47 data3       date10     Date at visit 10 #>  6      6 2010-07-20 12:27:00 data3       date10     Date at visit 10 #>  7      7 2010-07-28 16:24:09 data3       date9      Date at visit 9  #>  8      8 2010-07-19 15:24:18 data3       date9      Date at visit 9  #>  9      9 2010-08-11 03:48:27 data3       date9      Date at visit 9  #> 10     10 2010-07-30 20:41:23 data3       date10     Date at visit 10 #> # ℹ 40 more rows lastnews_table(except=\"db3$date9\") #> # A tibble: 50 × 5 #>    subjid last_date           origin_data origin_col origin_label     #>     <dbl> <dttm>              <chr>       <chr>      <chr>            #>  1      1 2010-08-01 18:59:37 data2       date4      Date at visit 4  #>  2      2 2010-07-31 15:32:45 data2       date4      Date at visit 4  #>  3      3 2010-07-22 11:24:37 data2       date5      Date at visit 5  #>  4      4 2010-07-23 20:38:32 data3       date10     Date at visit 10 #>  5      5 2010-07-15 07:09:47 data3       date10     Date at visit 10 #>  6      6 2010-07-20 12:27:00 data3       date10     Date at visit 10 #>  7      7 2010-07-28 16:24:09 data3       date9      Date at visit 9  #>  8      8 2010-07-19 15:24:18 data3       date9      Date at visit 9  #>  9      9 2010-08-11 03:48:27 data3       date9      Date at visit 9  #> 10     10 2010-07-30 20:41:23 data3       date10     Date at visit 10 #> # ℹ 40 more rows lastnews_table(prefer=\"date10\", show_delta=TRUE)  #> # A tibble: 50 × 8 #>    subjid last_date           origin_data origin_col origin_label     #>     <dbl> <dttm>              <chr>       <chr>      <chr>            #>  1      1 2010-08-01 18:59:37 data3       date10     Date at visit 10 #>  2      2 2010-07-31 15:32:45 data3       date10     Date at visit 10 #>  3      3 2010-07-22 11:24:37 data3       date10     Date at visit 10 #>  4      4 2010-07-23 20:38:32 data3       date10     Date at visit 10 #>  5      5 2010-07-15 07:09:47 data3       date10     Date at visit 10 #>  6      6 2010-07-20 12:27:00 data3       date10     Date at visit 10 #>  7      7 2010-07-28 16:24:09 data3       date9      Date at visit 9  #>  8      8 2010-07-19 15:24:18 data3       date9      Date at visit 9  #>  9      9 2010-08-11 03:48:27 data3       date9      Date at visit 9  #> 10     10 2010-07-30 20:41:23 data3       date10     Date at visit 10 #> # ℹ 40 more rows #> # ℹ 3 more variables: preferred_last_date <dttm>, preferred_origin <chr>, #> #   delta <drtn> lastnews_table() %>%    dplyr::count(origin = glue::glue(\"{origin_data}${origin_col}\"),    sort=TRUE) #> # A tibble: 5 × 2 #>   origin           n #>   <glue>       <int> #> 1 data3$date10    36 #> 2 data3$date9     10 #> 3 data2$date4      2 #> 4 data2$date5      1 #> 5 data3$date8      1  csv_file = tempfile(fileext=\".csv\") lastnews_table(prefer=\"date9\", warn_if_future=csv_file)  #> # A tibble: 50 × 5 #>    subjid last_date           origin_data origin_col origin_label     #>     <dbl> <dttm>              <chr>       <chr>      <chr>            #>  1      1 2010-08-01 18:59:37 data2       date4      Date at visit 4  #>  2      2 2010-07-31 15:32:45 data2       date4      Date at visit 4  #>  3      3 2010-07-22 11:24:37 data2       date5      Date at visit 5  #>  4      4 2010-07-23 20:38:32 data3       date10     Date at visit 10 #>  5      5 2010-07-15 07:09:47 data3       date10     Date at visit 10 #>  6      6 2010-07-20 12:27:00 data3       date10     Date at visit 10 #>  7      7 2010-07-28 16:24:09 data3       date9      Date at visit 9  #>  8      8 2010-07-19 15:24:18 data3       date9      Date at visit 9  #>  9      9 2010-08-11 03:48:27 data3       date9      Date at visit 9  #> 10     10 2010-07-30 20:41:23 data3       date10     Date at visit 10 #> # ℹ 40 more rows"},{"path":"https://danchaltiel.github.io/EDCimport/reference/load_database.html","id":null,"dir":"Reference","previous_headings":"","what":"Load a list in an environment — load_database","title":"Load a list in an environment — load_database","text":"Load list environment","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/load_database.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Load a list in an environment — load_database","text":"","code":"load_database(db, env = parent.frame(), remove = TRUE)"},{"path":"https://danchaltiel.github.io/EDCimport/reference/load_database.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Load a list in an environment — load_database","text":"db edc_database object (fair, list ) env environment onto list loaded remove TRUE, db removed environment afterward","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/load_database.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Load a list in an environment — load_database","text":"nothing, called side-effect","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/load_database.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Load a list in an environment — load_database","text":"","code":"db = edc_example() #> Warning: Option \"edc_lookup\" has been overwritten. load_database(db, remove=FALSE) print(db) #> ── EDCimport database ────────────────────────────────────────────────────────── #> Contains 8 tables: `enrol`, `data1`, `data2`, …, `long_mixed`, and `ae` #> ℹ Use `EDCimport::load_database(db)` to load the tables in the global #>   environment. #> ℹ Use `EDCimport::edc_lookup()` to see the summary table. print(lengths(db)) #>               enrol               data1               data2               data3  #>                   6                   7                   6                   7  #>               short           long_pure          long_mixed                  ae  #>                   5                   4                   6                   7  #> datetime_extraction     date_extraction             .lookup  #>                   1                   1                   9"},{"path":"https://danchaltiel.github.io/EDCimport/reference/manual_correction.html","id":null,"dir":"Reference","previous_headings":"","what":"Manual correction — manual_correction","title":"Manual correction — manual_correction","text":"finding wrong unexpected values exported dataset, can useful temporarily correct hard-coding value. However, manual correction undone soon central database updated correction. manual_correction() applies correction specific dataset column location throws error correction already place. check applies per R session can source script without errors. reset_manual_correction() resets checks. instance, called read_trialmaster().","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/manual_correction.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Manual correction — manual_correction","text":"","code":"manual_correction(   data,   col,   rows,   wrong,   correct,   verbose = getOption(\"edc_correction_verbose\", TRUE) )  reset_manual_correction()"},{"path":"https://danchaltiel.github.io/EDCimport/reference/manual_correction.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Manual correction — manual_correction","text":"data, col, rows rows column dataframe error lies wrong actual wrong value correct temporary correction value verbose whether print informations ()","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/manual_correction.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Manual correction — manual_correction","text":"Nothing, used side effects","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/manual_correction.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Manual correction — manual_correction","text":"","code":"library(dplyr) x = iris %>% mutate(id=row_number(), .before=1) %>% as_tibble() x$Sepal.Length[c(1,3,5)] #> [1] 5.1 4.7 5.0  #1st correction is silent manual_correction(x, Sepal.Length, rows=c(1,3,5),                   wrong=c(5.1, 4.7, 5.0), correct=c(5, 4, 3)) #> Manual correction of \"x$Sepal.Length\": #> ℹ Old: 5.1, 4.7, and 5 #> ℹ New: 5, 4, and 3 x$Sepal.Length[c(1,3,5)] #> [1] 5 4 3  #further correction is silent manual_correction(x, Sepal.Length, rows=c(1,3,5),                   wrong=c(5.1, 4.7, 5.0), correct=c(5, 4, 3))                     #if the database is corrected, an error is thrown if (FALSE) { # \\dontrun{ reset_manual_correction() x$Sepal.Length[c(1,3,5)] = c(5, 4, 3) #mimics db correction manual_correction(x, Sepal.Length, rows=c(1,3,5),                   wrong=c(5.1, 4.7, 5.0), correct=c(5, 4, 3)) } # }"},{"path":"https://danchaltiel.github.io/EDCimport/reference/read_all_csv.html","id":null,"dir":"Reference","previous_headings":"","what":"Read all .csv files in a directory — read_all_csv","title":"Read all .csv files in a directory — read_all_csv","text":"Read .csv files directory, labels specified.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/read_all_csv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Read all .csv files in a directory — read_all_csv","text":"","code":"read_all_csv(   path,   ...,   labels_from = NULL,   clean_names_fun = NULL,   read_fun = \"guess\",   subdirectories = FALSE,   datetime_extraction = \"guess\",   verbose = getOption(\"edc_read_verbose\", 1) )"},{"path":"https://danchaltiel.github.io/EDCimport/reference/read_all_csv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Read all .csv files in a directory — read_all_csv","text":"path [character(1)] path directory containing .csv files. ... unused labels_from [misc] list path file containing labels. clean_names_fun [function] function clean column names, e.g. tolower, janitor::clean_names(),... read_fun [function] function read files path, e.g. read.csv(), read.csv2(),... subdirectories [logical(1)] whether read subdirectories. datetime_extraction [dateish(1)] datetime database extraction (database lock). \"guess\", datetime inferred files modification time. verbose [logical(1)] level verbosity","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/read_all_csv.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Read all .csv files in a directory — read_all_csv","text":"list containing one dataframe .csv file folder, extraction date (datetime_extraction), summary imported tables (.lookup).","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/read_all_csv.html","id":"labels-file","dir":"Reference","previous_headings":"","what":"Labels file","title":"Read all .csv files in a directory — read_all_csv","text":"labels_from contain information column labels. data file (.csv) containing 2 columns: one column name associated label. Use options(edc_col_name=\"xxx\", edc_col_label=\"xxx\") specify names columns.","code":""},{"path":[]},{"path":"https://danchaltiel.github.io/EDCimport/reference/read_all_sas.html","id":null,"dir":"Reference","previous_headings":"","what":"Read all .sas7bdat files in a directory — read_all_sas","title":"Read all .sas7bdat files in a directory — read_all_sas","text":"Read .sas7bdat files directory. Formats can applied procformat.sas SAS file, .","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/read_all_sas.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Read all .sas7bdat files in a directory — read_all_sas","text":"","code":"read_all_sas(   path,   ...,   format_file = \"procformat.sas\",   clean_names_fun = NULL,   subdirectories = FALSE,   datetime_extraction = \"guess\",   verbose = getOption(\"edc_read_verbose\", 1) )"},{"path":"https://danchaltiel.github.io/EDCimport/reference/read_all_sas.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Read all .sas7bdat files in a directory — read_all_sas","text":"path [character(1)] path directory containing .sas7bdat files. ... unused format_file [character(1)] path file used apply formats. See details. Use NULL apply formats. clean_names_fun [function] function clean column names, e.g. tolower, janitor::clean_names(),... subdirectories [logical(1)] whether read subdirectories datetime_extraction [POSIXt(1)] datetime data extraction. Default common date last modification directory. verbose [numeric(1)] one c(0, 1, 2). higher, information printed.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/read_all_sas.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Read all .sas7bdat files in a directory — read_all_sas","text":"list containing one dataframe .xpt file folder, extraction date (datetime_extraction), summary imported tables (.lookup).","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/read_all_sas.html","id":"format-file","dir":"Reference","previous_headings":"","what":"Format file","title":"Read all .sas7bdat files in a directory — read_all_sas","text":"format_file contain information SAS formats. can either procformat.sas file, containing whole PROC FORMAT catalog file (.sas7bcat) data file (.csv .sas7bdat) containing 3 columns: SAS format name (repeated), level, associated label. Use options(edc_var_format_name=\"xxx\", edc_var_level=\"xxx\", edc_var_label=\"xxx\") specify names columns.","code":""},{"path":[]},{"path":"https://danchaltiel.github.io/EDCimport/reference/read_all_xpt.html","id":null,"dir":"Reference","previous_headings":"","what":"Read all .xpt files in a directory — read_all_xpt","title":"Read all .xpt files in a directory — read_all_xpt","text":"Read .xpt files directory (unzipped TrialMaster archive).  7zip installed, probably rather use read_trialmaster() instead.  procformat.sas file exists directory, formats applied.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/read_all_xpt.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Read all .xpt files in a directory — read_all_xpt","text":"","code":"read_all_xpt(   path,   ...,   format_file = \"procformat.sas\",   clean_names_fun = NULL,   datetime_extraction = \"guess\",   subdirectories = FALSE,   verbose = getOption(\"edc_read_verbose\", 1),   directory = \"deprecated\",   key_columns = \"deprecated\" )"},{"path":"https://danchaltiel.github.io/EDCimport/reference/read_all_xpt.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Read all .xpt files in a directory — read_all_xpt","text":"path [character(1)] path directory containing .xpt files. ... unused format_file [character(1)] path file used apply formats. See details. Use NULL apply formats. clean_names_fun [function] function clean column names, e.g. tolower, janitor::clean_names(),... datetime_extraction [POSIXt(1)] datetime data extraction. Default common date last modification directory. subdirectories [logical(1)] whether read subdirectories verbose [numeric(1)] one c(0, 1, 2). higher, information printed. directory deprecated favour path key_columns deprecated","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/read_all_xpt.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Read all .xpt files in a directory — read_all_xpt","text":"list containing one dataframe .xpt file folder, extraction date (datetime_extraction), summary imported tables (.lookup).","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/read_all_xpt.html","id":"format-file","dir":"Reference","previous_headings":"","what":"Format file","title":"Read all .xpt files in a directory — read_all_xpt","text":"format_file contain information SAS formats. can either procformat.sas file, containing whole PROC FORMAT data file (.csv .sas7bdat) containing 3 columns: SAS format name (repeated), level, associated label. Use options(edc_var_format_name=\"xxx\", edc_var_level=\"xxx\", edc_var_label=\"xxx\") specify names columns.","code":""},{"path":[]},{"path":"https://danchaltiel.github.io/EDCimport/reference/read_trialmaster.html","id":null,"dir":"Reference","previous_headings":"","what":"Read the .zip archive of a TrialMaster export — read_trialmaster","title":"Read the .zip archive of a TrialMaster export — read_trialmaster","text":"Import .zip archive TrialMaster trial export list dataframes. archive filename leaved untouched contains project name date extraction.  Generate .rds cache file future reads.  7zip installed available, use read_all_xpt() instead. TM export type SAS Xport, checkbox \"Include Codelists\" ticked.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/read_trialmaster.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Read the .zip archive of a TrialMaster export — read_trialmaster","text":"","code":"read_trialmaster(   archive,   ...,   use_cache = \"write\",   clean_names_fun = NULL,   subdirectories = FALSE,   pw = getOption(\"trialmaster_pw\"),   verbose = getOption(\"edc_read_verbose\", 1),   key_columns = \"deprecated\" )"},{"path":"https://danchaltiel.github.io/EDCimport/reference/read_trialmaster.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Read the .zip archive of a TrialMaster export — read_trialmaster","text":"archive [character(1)] path archive ... unused use_cache [mixed(1): \"write\"] controls .rds cache. TRUE, read cache extract archive create cache. FALSE extract archive without creating cache file. Can also \"read\" \"write\". clean_names_fun [function] function clean column names, e.g. tolower, janitor::clean_names(),... subdirectories [logical(1)] whether read subdirectories pw [character(1)] password archive protected. avoid writing passwords plain text, probably better use options(trialmaster_pw=\"xxx\") instead though. verbose [numeric(1)] one c(0, 1, 2). higher, information printed. key_columns deprecated","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/read_trialmaster.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Read the .zip archive of a TrialMaster export — read_trialmaster","text":"list containing one dataframe .xpt file folder, extraction date (datetime_extraction), summary imported tables (.lookup).","code":""},{"path":[]},{"path":"https://danchaltiel.github.io/EDCimport/reference/reexports.html","id":null,"dir":"Reference","previous_headings":"","what":"Objects exported from other packages — reexports","title":"Objects exported from other packages — reexports","text":"objects imported packages. Follow links see documentation. dplyr %>% tibble tibble","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/save_plotly.html","id":null,"dir":"Reference","previous_headings":"","what":"Save a plotly to an HTML file — save_plotly","title":"Save a plotly to an HTML file — save_plotly","text":"Save plotly HTML file","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/save_plotly.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Save a plotly to an HTML file — save_plotly","text":"","code":"save_plotly(p, file, ...)"},{"path":"https://danchaltiel.github.io/EDCimport/reference/save_plotly.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Save a plotly to an HTML file — save_plotly","text":"p plot object (plotly ggplot) file file path save HTML file ... passed htmlwidgets::saveWidget","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/save_plotly.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Save a plotly to an HTML file — save_plotly","text":"nothing, used side effect","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/save_plotly.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Save a plotly to an HTML file — save_plotly","text":"","code":"if (FALSE) { # \\dontrun{ db = edc_example() load_database(db) p = edc_swimmerplot(id_lim=c(5,45)) save_plotly(p, \"graph/swimplots/edc_swimmerplot.html\", title=\"My Swimmerplot\") } # }"},{"path":"https://danchaltiel.github.io/EDCimport/reference/save_sessioninfo.html","id":null,"dir":"Reference","previous_headings":"","what":"Save sessionInfo() output — save_sessioninfo","title":"Save sessionInfo() output — save_sessioninfo","text":"Save sessionInfo() output text file.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/save_sessioninfo.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Save sessionInfo() output — save_sessioninfo","text":"","code":"save_sessioninfo(path = \"check/session_info.txt\", with_date = TRUE)"},{"path":"https://danchaltiel.github.io/EDCimport/reference/save_sessioninfo.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Save sessionInfo() output — save_sessioninfo","text":"path target path write file with_date whether insert date file extension","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/save_sessioninfo.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Save sessionInfo() output — save_sessioninfo","text":"nothing","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/save_sessioninfo.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Save sessionInfo() output — save_sessioninfo","text":"","code":"if (FALSE) { # \\dontrun{    save_sessioninfo() } # }"},{"path":"https://danchaltiel.github.io/EDCimport/reference/search_for_newer_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Search for newer data — search_for_newer_data","title":"Search for newer data — search_for_newer_data","text":"Search folders TrialMaster database recent current extraction present. default, search \"data\" folder OS usual \"Downloads\" folder. newer database found, user asked want move \"data\" folder.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/search_for_newer_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Search for newer data — search_for_newer_data","text":"","code":"search_for_newer_data(   archive,   ...,   source = path_home(\"Downloads\"),   target = \"data\",   ask = TRUE,   advice = TRUE )"},{"path":"https://danchaltiel.github.io/EDCimport/reference/search_for_newer_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Search for newer data — search_for_newer_data","text":"archive TM archive path, giving project name date ... unused source path vector searched, default \"data\" usual \"Downloads\" folder target path files copied ask whether ask user move file \"data\" advice whether advice move instead, ask==FALSE","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/search_for_newer_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Search for newer data — search_for_newer_data","text":"path newer file, invisibly.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/search_for_newer_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Search for newer data — search_for_newer_data","text":"","code":"if (FALSE) { # \\dontrun{   archive = \"data/MYPROJECT_ExportTemplate_xxx_SAS_XPORT_2024_06_01_12_00.zip\"   #tm = read_trialmaster(archive)   search_for_newer_data(archive) } # }"},{"path":"https://danchaltiel.github.io/EDCimport/reference/select_distinct.html","id":null,"dir":"Reference","previous_headings":"","what":"Select only distinct columns — select_distinct","title":"Select only distinct columns — select_distinct","text":"Select columns one level given grouping scope. Useful dealing mixed datasets containing long data repeated short data.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/select_distinct.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Select only distinct columns — select_distinct","text":"","code":"select_distinct(df, .by)"},{"path":"https://danchaltiel.github.io/EDCimport/reference/select_distinct.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Select only distinct columns — select_distinct","text":"df dataframe .optional grouping columns","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/select_distinct.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Select only distinct columns — select_distinct","text":"df less columns","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/select_distinct.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Select only distinct columns — select_distinct","text":"","code":"db = edc_example() #> Warning: Option \"edc_lookup\" has been overwritten. db$ae %>% colnames() #> [1] \"subjid\"  \"crfname\" \"aesoc\"   \"aegr\"    \"n_ae\"    \"sae\"     \"crfstat\" #`crfname` has one level for the whole dataset db$ae %>% select_distinct() %>% colnames() #> [1] \"crfname\" #`n_ae` has one level per patient db$ae %>% select_distinct(.by=subjid) %>% colnames() #> [1] \"subjid\"  \"crfname\" \"n_ae\""},{"path":"https://danchaltiel.github.io/EDCimport/reference/table_format.html","id":null,"dir":"Reference","previous_headings":"","what":"Identify if a dataframe has a long or a wide format — table_format","title":"Identify if a dataframe has a long or a wide format — table_format","text":"dataset either wide format long format (link). function identifies format dataframe respect subject ID. dataframe wide long columns, considered \"mixed\".","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/table_format.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Identify if a dataframe has a long or a wide format — table_format","text":"","code":"table_format(   df,   id = get_subjid_cols(),   ...,   ignore_cols = get_meta_cols(0.95),   na_rm = FALSE,   warn = TRUE )"},{"path":"https://danchaltiel.github.io/EDCimport/reference/table_format.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Identify if a dataframe has a long or a wide format — table_format","text":"df dataframe id identifying subject ID ... used ignore_cols columns ignore. na_rm whether consider missing values warn whether warn ID found","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/table_format.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Identify if a dataframe has a long or a wide format — table_format","text":"string value c(\"wide\", \"long\", \"mixed)","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/table_format.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Identify if a dataframe has a long or a wide format — table_format","text":"","code":"db = edc_example() #> Warning: Option \"edc_lookup\" has been overwritten. sapply(db, table_format, warn=FALSE)  #> $enrol #> [1] \"wide\" #>  #> $data1 #> [1] \"mixed\" #>  #> $data2 #> [1] \"wide\" #>  #> $data3 #> [1] \"wide\" #>  #> $short #> [1] \"wide\" #>  #> $long_pure #> [1] \"long\" #>  #> $long_mixed #> [1] \"mixed\" #>  #> $ae #> [1] \"mixed\" #>  #> $datetime_extraction #> NULL #>  #> $date_extraction #> NULL #>  #> $.lookup #> NULL #>"},{"path":"https://danchaltiel.github.io/EDCimport/reference/unify.html","id":null,"dir":"Reference","previous_headings":"","what":"Unify a vector — unify","title":"Unify a vector — unify","text":"Turn vector length N vector length 1 checking one unique value. Useful safely flatten duplicated table. preserves label attribute set.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/unify.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Unify a vector — unify","text":"","code":"unify(x)"},{"path":"https://danchaltiel.github.io/EDCimport/reference/unify.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Unify a vector — unify","text":"x vector","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/unify.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Unify a vector — unify","text":"vector length 1","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/unify.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Unify a vector — unify","text":"","code":"unify(c(1,1,1,1)) #> [1] 1 #unify(c(1,1,2,1)) #warning  library(dplyr) x=tibble(id=rep(letters[1:5],10), value=rep(1:5,10)) x %>% group_by(id) %>% summarise(value=unify(value)) #safer than `value=value[1]` #> # A tibble: 5 × 2 #>   id    value #>   <chr> <int> #> 1 a         1 #> 2 b         2 #> 3 c         3 #> 4 d         4 #> 5 e         5 x$value[2]=1 #x %>% group_by(id) %>% summarise(value=unify(value)) #warning about that non-unique value"},{"path":[]},{"path":"https://danchaltiel.github.io/EDCimport/news/index.html","id":"new-features-0-6-0","dir":"Changelog","previous_headings":"","what":"New features","title":"EDCimport 0.6.0 (dev)","text":"New functions edc_patient_gridplot(), creates ggplot matrix giving presence patients datasets (#77) Improved lastnews_table(): allow regex except & prefer, improved warning message, allow saving warning csv (#78) New argument lastnews_table(show_delta=TRUE), computes difference last prefer date actual last date (#81) New functions edc_left_join(), edc_right_join(), edc_full_join(), perform joins defaults subject ID primary key (#82) New function edc_viewer(), run shiny application easily browsing database (#83) New function edc_find_value(), searches whole database value, edc_find_column() searches column names labels. New argument subdirectories reading functions (read_trialmaster(), read_all_xpt(), read_all_sas(), read_all_csv()), control whether read sub-directories. Note now, subdirectories read overwrite root files.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/news/index.html","id":"internal-improvements-0-6-0","dir":"Changelog","previous_headings":"","what":"Internal improvements","title":"EDCimport 0.6.0 (dev)","text":"read_trialmaster() won’t read cache installed EDCimport version different cache’s","code":""},{"path":"https://danchaltiel.github.io/EDCimport/news/index.html","id":"deprecations-0-6-0","dir":"Changelog","previous_headings":"","what":"Deprecations","title":"EDCimport 0.6.0 (dev)","text":"load_list(), renamed load_database() find_keyword(), renamed edc_find_column()","code":""},{"path":"https://danchaltiel.github.io/EDCimport/news/index.html","id":"breaking-changes-0-6-0","dir":"Changelog","previous_headings":"","what":"Breaking changes","title":"EDCimport 0.6.0 (dev)","text":"don’t think enough people using necessary go deprecation process. split_mixed_datasets becomes edc_split_mixed() Unexported internal functions: build_lookup(), extend_lookup(), get_key_cols(), get_subjid_cols(), get_crfname_cols(), get_meta_cols(), load_as_list(), save_list()","code":""},{"path":"https://danchaltiel.github.io/EDCimport/news/index.html","id":"edcimport-052","dir":"Changelog","previous_headings":"","what":"EDCimport 0.5.2","title":"EDCimport 0.5.2","text":"CRAN release: 2024-11-14 Fixed bug lastnews_table() subjid numeric Fixed bug read_all_sas() causing metadata (e.g. date_extraction) converted dataframes","code":""},{"path":"https://danchaltiel.github.io/EDCimport/news/index.html","id":"edcimport-051","dir":"Changelog","previous_headings":"","what":"EDCimport 0.5.1","title":"EDCimport 0.5.1","text":"CRAN release: 2024-10-31 Internal fix CRAN check","code":""},{"path":"https://danchaltiel.github.io/EDCimport/news/index.html","id":"edcimport-050","dir":"Changelog","previous_headings":"","what":"EDCimport 0.5.0","title":"EDCimport 0.5.0","text":"CRAN release: 2024-10-24","code":""},{"path":[]},{"path":"https://danchaltiel.github.io/EDCimport/news/index.html","id":"read-functions-0-5-0","dir":"Changelog","previous_headings":"New features","what":"Read functions","title":"EDCimport 0.5.0","text":"New function read_all_sas() read database .sas7bdat files. New function read_all_csv() read database .csv files.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/news/index.html","id":"sanity-checks-alerts-0-5-0","dir":"Changelog","previous_headings":"New features","what":"Sanity checks alerts","title":"EDCimport 0.5.0","text":"New functions edc_data_warn() edc_data_stop(), alert data inconsistencies (#29, #39, #43). New function edc_data_warnings(), get dataframe warnings thrown edc_data_warn(). New function edc_warn_extraction_date(), alert data old.","code":"ae %>% filter(grade<1 | grade>5) %>% edc_data_stop(\"AE of invalid grade\") ae %>% filter(is.na(grade)) %>% edc_data_warn(\"Grade is missing\", issue_n=13) #> Warning: Issue #13: Grade is missing (8 patients: #21, #28, #39, #95, #97, ...)"},{"path":"https://danchaltiel.github.io/EDCimport/news/index.html","id":"miscellaneous-utils-0-5-0","dir":"Changelog","previous_headings":"New features","what":"Miscellaneous utils","title":"EDCimport 0.5.0","text":"New function select_distinct() select columns one level given grouping scope (#57). New function edc_population_plot() visualize patient analysis population (#56). New function edc_db_to_excel() export whole database Excel file, easier browse RStudio’s table viewer (#55). Use edc_browse_excel() browse file without knowing name. New function edc_inform_code() show much code project contains (#49). New function search_for_newer_data() search path (e.g. Downloads) newer data archive (#46). New function edc_crf_plot() show current database completion status (#48). New function save_sessioninfo(), save sessionInfo() text file (#42). New function fct_yesno(), easily format Yes/columns (#19, #23, #40). New function lastnews_table() find last date information entered patient (#37). Useful survival analyses. New function edc_unify_subjid(), structure subject IDs datasets database (#30). New function save_plotly(), save plotly HTML file (#15). New experimental functions table_format(), get_common_cols() get_meta_cols() might become useful find keys pivot summarise data.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/news/index.html","id":"bug-fixes--improvements-0-5-0","dir":"Changelog","previous_headings":"","what":"Bug fixes & Improvements","title":"EDCimport 0.5.0","text":"get_datasets() now work even dataset named base function (#67). read_trialmaster() output readable error password entered although one needed. read_trialmaster(split_mixed=\"TRUE\") work intended. assert_no_duplicate() now argument check duplicate groups, example visit (#17). find_keyword() robust inform proportion missing possible. edc_lookup() now retrieve lookup table. Use build_lookup() build one table list. extend_lookup() fail anymore database faulty table.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/news/index.html","id":"deprecations-0-5-0","dir":"Changelog","previous_headings":"","what":"Deprecations","title":"EDCimport 0.5.0","text":"get_key_cols() replaced get_subjid_cols() get_crfname_cols(). check_subjid() replaced edc_warn_patient_diffs(). can either take vector dataframe input, message informative.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/news/index.html","id":"edcimport-041","dir":"Changelog","previous_headings":"","what":"EDCimport 0.4.1","title":"EDCimport 0.4.1","text":"CRAN release: 2023-12-19","code":""},{"path":"https://danchaltiel.github.io/EDCimport/news/index.html","id":"bug-fixes--improvements-0-4-1","dir":"Changelog","previous_headings":"","what":"Bug fixes & Improvements","title":"EDCimport 0.4.1","text":"Changes testing environment package can installed CRAN despite firewall policies forbidding password-protected archive downloading. Fixed bug corrupted XPT file can prevent whole import fail.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/news/index.html","id":"edcimport-040","dir":"Changelog","previous_headings":"","what":"EDCimport 0.4.0","title":"EDCimport 0.4.0","text":"CRAN release: 2023-12-11","code":""},{"path":"https://danchaltiel.github.io/EDCimport/news/index.html","id":"new-features-0-4-0","dir":"Changelog","previous_headings":"","what":"New features","title":"EDCimport 0.4.0","text":"New function check_subjid() check vector missing patients (#8). New function assert_no_duplicate() abort table duplicates subject ID column(#9). New function manual_correction() safely hard-code correction waiting TrialMaster database updated. New function edc_options() manage EDCimport global parameterization. New argument edc_swimmerplot(id_lim) subset swimmer plot patients . New option read_trialmaster(use_cache=\"write\") read zip still update cache. can now use syntax read_trialmaster(split_mixed=c(\"col1\", \"col2\")) split datasets need (#10).","code":"options(edc_subjid_ref=enrolres$subjid) check_subjid(treatment$subjid) check_subjid(ae$subjid) tibble(subjid=c(1:10, 1)) %>% assert_no_duplicate() %>% nrow() #Error in `assert_no_duplicate()`: #! Duplicate on column \"subjid\" for value 1."},{"path":"https://danchaltiel.github.io/EDCimport/news/index.html","id":"bug-fixes--improvements-0-4-0","dir":"Changelog","previous_headings":"","what":"Bug fixes & Improvements","title":"EDCimport 0.4.0","text":"Reading read_trialmaster() cache output error parameters (split_mixed, clean_names_fun) different (#4). split_mixed_datasets() now fully case-insensitive. Non-UTF8 characters labels now identified corrected reading (#5).","code":""},{"path":"https://danchaltiel.github.io/EDCimport/news/index.html","id":"minor-breaking-changes-0-4-0","dir":"Changelog","previous_headings":"","what":"Minor breaking changes","title":"EDCimport 0.4.0","text":"read_trialmaster(use_cache=\"write\") now default. Reading cache stable yet, opt-rather opt-. read_trialmaster(extend_lookup=TRUE) now default. Options edc_id, edc_crfname, edc_verbose respectively renamed edc_cols_id, edc_cols_crfname, edc_read_verbose clarity.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/news/index.html","id":"edcimport-030-20230519","dir":"Changelog","previous_headings":"","what":"EDCimport 0.3.0 2023/05/19","title":"EDCimport 0.3.0 2023/05/19","text":"CRAN release: 2023-05-19","code":""},{"path":"https://danchaltiel.github.io/EDCimport/news/index.html","id":"new-features-0-3-0","dir":"Changelog","previous_headings":"","what":"New features","title":"EDCimport 0.3.0 2023/05/19","text":"New function edc_swimmerplot() show swimmer plot dates database easily find outliers. New features read_trialmaster(): clean_names_fun=some_fun clean names tables. instance, clean_names_fun=janitor::clean_names() turn default SAS uppercase column names valid R snake-case column names. split_mixed=TRUE split tables contain long short data regarding patient ID one long table one short table. See ?split_mixed_datasets() details. extend_lookup=TRUE improve lookup table additional information. See ?extend_lookup() details. key_columns=get_key_cols() can change default column names patient ID CRF name (used new features). Standalone functions extend_lookup() split_mixed_datasets(). New helper unify(), turns vector duplicate values vector length 1.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/news/index.html","id":"bug-fixes-0-3-0","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"EDCimport 0.3.0 2023/05/19","text":"Reading errors now handled read_trialmaster() instead failing. one XPT file corrupted, resulting object contain error message instead dataset. find_keyword() now robust non-UTF8 characters labels. Option edc_lookup now set even reading cache. SAS formats containing = now work intended.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/news/index.html","id":"edcimport-021-20221101","dir":"Changelog","previous_headings":"","what":"EDCimport 0.2.1 2022/11/01","title":"EDCimport 0.2.1 2022/11/01","text":"CRAN release: 2022-12-02 Import data TrialMaster using tm = read_trialmaster(\"path//archive.zip\"). Search keyword column name label using find_keyword(\"date\", data=tm$.lookup). can also generate lookup table arbitrary list dataframe using build_lookup(my_data). Load datasets global environment using load_list(tm) avoid typing tm$ everywhere. Browse available global options using ?EDCimport_options.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/news/index.html","id":"edcimport-010","dir":"Changelog","previous_headings":"","what":"EDCimport 0.1.0","title":"EDCimport 0.1.0","text":"Draft version","code":""}]
