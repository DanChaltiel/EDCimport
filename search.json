[{"path":"https://danchaltiel.github.io/EDCimport/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Dan Chaltiel. Author, maintainer.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Chaltiel D (2024). EDCimport: Import Data EDC Software. R package version 0.4.1.9001, https://danchaltiel.github.io/EDCimport/, https://github.com/DanChaltiel/EDCimport.","code":"@Manual{,   title = {EDCimport: Import Data from EDC Software},   author = {Dan Chaltiel},   year = {2024},   note = {R package version 0.4.1.9001, https://danchaltiel.github.io/EDCimport/},   url = {https://github.com/DanChaltiel/EDCimport}, }"},{"path":"https://danchaltiel.github.io/EDCimport/index.html","id":"edcimport","dir":"","previous_headings":"","what":"Import Data from EDC Software","title":"Import Data from EDC Software","text":"EDCimport package designed easily import data EDC software TrialMaster.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Import Data from EDC Software","text":"also need 7-zip installed, preferably added PATH. [!WARNING] package developed work Windows unlikely work OS. welcome submit PR manage get work Mac Linux.","code":"# Install last version available on CRAN (once published) install.packages(\"EDCimport\")  # Install development version on Github devtools::install_github(\"DanChaltiel/EDCimport\")"},{"path":"https://danchaltiel.github.io/EDCimport/index.html","id":"load-the-data","dir":"","previous_headings":"Installation","what":"Load the data","title":"Import Data from EDC Software","text":"Inside TrialMaster, request export type SAS Xport, checkbox “Include Codelists” ticked. export generate .zip archive. , simply use read_trialmaster() archive password () retrieve data archive: resulting object tm list containing datasets, plus metadatas. can now use load_list() import list global environment use tables: many options available (e.g. colnames cleaning & table splitting), see ?read_trialmaster details.","code":"library(EDCimport) tm = read_trialmaster(\"path/to/my/archive.zip\", pw=\"foobar\") load_list(tm) #this also removes `tm` to save memory mean(dataset1$column5)"},{"path":"https://danchaltiel.github.io/EDCimport/index.html","id":"database-management-tools","dir":"","previous_headings":"Installation","what":"Database management tools","title":"Import Data from EDC Software","text":"EDCimport include set useful tools help using imported database. See References complete list.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/index.html","id":"database-summary","dir":"","previous_headings":"Installation > Database management tools","what":"Database summary","title":"Import Data from EDC Software","text":"Reading database using read_trialmaster() generates .lookup dataframe, contains dataset number rows, columns, patients, CRF name. .lookup used many tools inside EDCimport, careful modify delete .","code":""},{"path":"https://danchaltiel.github.io/EDCimport/index.html","id":"search-the-whole-database","dir":"","previous_headings":"Installation > Database management tools","what":"Search the whole database","title":"Import Data from EDC Software","text":"Using find_keyword(), can run global search database. instance, say remember dataset column located “date ECG”. find_keyword() search every column name label give answer:","code":"find_keyword(\"date\") #> # A tibble: 10 x 3 #>    dataset names   labels                       #>    <chr>   <chr>   <chr>                        #>  1 pat     PTRNDT  Randomization Date           #>  2 pat     RGSTDT  Registration Date            #>  3 site    INVDAT  Deactivation date            #>  4 site    TRGTDT  Target Enroll Date           #>  5 trial   TRSPDT  End Date                     #>  6 trial   TRSTDT  Start Date                   #>  7 visit   VISIT2  Visit Date                   #>  8 visit   EEXPVDT Earliest Expected Visit Date #>  9 vs      ECGDAT  Date of ECG                  #> 10 vs      VISITDT Visit Date"},{"path":"https://danchaltiel.github.io/EDCimport/index.html","id":"swimmer-plot","dir":"","previous_headings":"Installation","what":"Swimmer Plot","title":"Import Data from EDC Software","text":"edc_swimmerplot() function create swimmer plot date variables whole database. 2 arguments interest: group, grouping variable (e.g. treatment arm) origin, date variable acting time zero (e.g. date enrollment) outputs plotly interactive graph can select dates interest zoom mouse.  Note modification made running read_trialmaster() taken account. instance, mutating column .Date() one tables add new group plot.","code":"edc_swimmerplot() edc_swimmerplot(group=\"enrolres$arm\") edc_swimmerplot(origin=\"enrolres$enroldt\")"},{"path":"https://danchaltiel.github.io/EDCimport/reference/EDCimport-package.html","id":null,"dir":"Reference","previous_headings":"","what":"EDCimport: Import Data from EDC Software — EDCimport-package","title":"EDCimport: Import Data from EDC Software — EDCimport-package","text":"convenient toolbox import data exported Electronic Data Capture (EDC) software 'TrialMaster'.","code":""},{"path":[]},{"path":"https://danchaltiel.github.io/EDCimport/reference/EDCimport-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"EDCimport: Import Data from EDC Software — EDCimport-package","text":"Maintainer: Dan Chaltiel dan.chaltiel@gmail.com (ORCID)","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/assert_no_duplicate.html","id":null,"dir":"Reference","previous_headings":"","what":"Assert that a dataset has one row per patient — assert_no_duplicate","title":"Assert that a dataset has one row per patient — assert_no_duplicate","text":"Check duplicate column holding patient ID pipeable style.  Mostly useful joining two datasets.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/assert_no_duplicate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Assert that a dataset has one row per patient — assert_no_duplicate","text":"","code":"assert_no_duplicate(df, id_col = get_key_cols())"},{"path":"https://danchaltiel.github.io/EDCimport/reference/assert_no_duplicate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Assert that a dataset has one row per patient — assert_no_duplicate","text":"df dataset id_col (optional) name columns holding patient ID","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/assert_no_duplicate.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Assert that a dataset has one row per patient — assert_no_duplicate","text":"df dataset, unchanged","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/assert_no_duplicate.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Assert that a dataset has one row per patient — assert_no_duplicate","text":"","code":"#without duplicate => no error, continue the pipeline tibble(subjid=c(1:10)) %>% assert_no_duplicate() %>% nrow() #> [1] 10  #with duplicate => throws an error #tibble(subjid=c(1:10, 1:2)) %>% assert_no_duplicate() %>% nrow()"},{"path":"https://danchaltiel.github.io/EDCimport/reference/check_subjid.html","id":null,"dir":"Reference","previous_headings":"","what":"Check the completion of the subject ID column — check_subjid","title":"Check the completion of the subject ID column — check_subjid","text":"Compare subject ID vector study's reference subject ID (usually something like enrolres$subjid).","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/check_subjid.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check the completion of the subject ID column — check_subjid","text":"","code":"check_subjid(x, ref = getOption(\"edc_subjid_ref\"))"},{"path":"https://danchaltiel.github.io/EDCimport/reference/check_subjid.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check the completion of the subject ID column — check_subjid","text":"x subject ID column check ref reference subject ID. usually set edc_options(edc_subjid_ref=xxx). See example.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/check_subjid.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check the completion of the subject ID column — check_subjid","text":"nothing, called warnings","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/check_subjid.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check the completion of the subject ID column — check_subjid","text":"","code":"tm = edc_example() load_list(tm) options(edc_subjid_ref=db0$SUBJID) #usually, you set something like: #options(edc_subjid_ref=enrolres$subjid) check_subjid(db1$SUBJID) check_subjid(db1$SUBJID %>% setdiff(2)) #> Warning: Missing subject ID in `db1$SUBJID %>% setdiff(2)`: 2 check_subjid(c(db1$SUBJID, 99)) #> Warning: Additional subject ID `c(db1$SUBJID, 99)`: 99"},{"path":"https://danchaltiel.github.io/EDCimport/reference/data_example.html","id":null,"dir":"Reference","previous_headings":"","what":"Example databases — data_example","title":"Example databases — data_example","text":"List tables used EDCimport examples: edc_example() can used result read_trialmaster() edc_example_plot() can used test edc_swimmerplot() edc_example_mixed() can used test split_mixed_datasets()","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/data_example.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Example databases — data_example","text":"","code":"edc_example_mixed(N = 100)  edc_example_plot(N = 50, seed = 42)  edc_example(N = 50, seed = 42)"},{"path":"https://danchaltiel.github.io/EDCimport/reference/data_example.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Example databases — data_example","text":"N number patients seed random seed","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/data_example.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Example databases — data_example","text":"list tables","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_options.html","id":null,"dir":"Reference","previous_headings":"","what":"Set global options for EDCimport — edc_options","title":"Set global options for EDCimport — edc_options","text":"Use function manage EDCimport parameters globally taking advantage autocompletion.  Use edc_peek_options() see option currently set edc_reset_options() set options back default.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_options.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set global options for EDCimport — edc_options","text":"","code":"edc_options(   ...,   trialmaster_pw,   path_7zip,   edc_lookup,   edc_subjid_ref,   edc_plotly,   edc_cols_id,   edc_cols_crfname,   edc_read_verbose,   edc_correction_verbose,   edc_get_key_cols_verbose,   edc_lookup_overwrite_warn,   .local = FALSE )"},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_options.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set global options for EDCimport — edc_options","text":"... unused trialmaster_pw password trialmaster zip archive. instance, can use edc_options(trialmaster_pw=\"my_pwd\") console per session, write password clear R code path_7zip path 7zip executable. Default \"C:/Program Files/7-Zip/\". edc_lookup (Internal) reference lookup table (usually .lookup). usually changed manually. edc_subjid_ref used check_subjid vector reference subject IDs. usually write edc_options(edc_subjid_ref=enrolres$subjid). edc_plotly used edc_swimmerplot whether use plotly visualize plot. edc_cols_id, edc_cols_crfname used get_key_cols name columns holding subject id (default c(\"ptno\", \"subjid\")) CRF form name (default c(\"crfname\")). case-insensitive. edc_read_verbose, edc_correction_verbose, edc_get_key_cols_verbose verbosity output functions read_trialmaster read_tm_all_xpt, manual_correction, get_key_cols. example, set edc_options(edc_read_verbose=0) silence first 2. edc_lookup_overwrite_warn default TRUE. Whether warning overwriting .lookup (like reading 2 databases successively) .local TRUE, effect apply local frame (internally using rlang::local_options())","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_options.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Set global options for EDCimport — edc_options","text":"Nothing, called side effects","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_peek_options.html","id":null,"dir":"Reference","previous_headings":"","what":"See which EDCimport option is currently set. — edc_peek_options","title":"See which EDCimport option is currently set. — edc_peek_options","text":"See EDCimport option currently set.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_peek_options.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"See which EDCimport option is currently set. — edc_peek_options","text":"","code":"edc_peek_options(keep_null = FALSE)"},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_peek_options.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"See which EDCimport option is currently set. — edc_peek_options","text":"keep_null set TRUE get list","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_peek_options.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"See which EDCimport option is currently set. — edc_peek_options","text":"named list EDCimport options","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_reset_options.html","id":null,"dir":"Reference","previous_headings":"","what":"Reset all EDCimport options. — edc_reset_options","title":"Reset all EDCimport options. — edc_reset_options","text":"Reset EDCimport options.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_reset_options.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Reset all EDCimport options. — edc_reset_options","text":"","code":"edc_reset_options(   except = c(\"edc_lookup\", \"trialmaster_pw\", \"path_7zip\"),   quiet = FALSE )"},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_reset_options.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Reset all EDCimport options. — edc_reset_options","text":"except options reset default quiet set TRUE remove message.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_reset_options.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Reset all EDCimport options. — edc_reset_options","text":"Nothing, called side effects","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_swimmerplot.html","id":null,"dir":"Reference","previous_headings":"","what":"Swimmer plot of all dates columns — edc_swimmerplot","title":"Swimmer plot of all dates columns — edc_swimmerplot","text":"Join tables .lookup$dataset id","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_swimmerplot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Swimmer plot of all dates columns — edc_swimmerplot","text":"","code":"edc_swimmerplot(   .lookup = getOption(\"edc_lookup\"),   ...,   id = get_key_cols()$patient_id,   group = NULL,   origin = NULL,   id_lim = NULL,   exclude = NULL,   time_unit = c(\"days\", \"weeks\", \"months\", \"years\"),   aes_color = c(\"variable\", \"label\"),   plotly = getOption(\"edc_plotly\", FALSE) )"},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_swimmerplot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Swimmer plot of all dates columns — edc_swimmerplot","text":".lookup lookup table, default getOption(\"edc_lookup\") ... used id patient identifier. coerced numeric. group grouping variable, given \"dataset$column\" origin variable consider time 0, given \"dataset$column\" id_lim numeric vector length 2 providing minimum maximum id subset . exclude character vector variables exclude, form dataset$column. Can regex, $ symbols count. Case-insensitive. time_unit origin!=NULL, unit measure time. One c(\"days\", \"weeks\", \"months\", \"years\"). aes_color either variable (\"{dataset} - {column}\") label (column label) plotly whether use {plotly} get interactive plot","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_swimmerplot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Swimmer plot of all dates columns — edc_swimmerplot","text":"either plotly ggplot","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/edc_swimmerplot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Swimmer plot of all dates columns — edc_swimmerplot","text":"","code":"#tm = read_trialmaster(\"filename.zip\", pw=\"xx\") tm = edc_example_plot() #> Warning: Option \"edc_lookup\" has been overwritten. load_list(tm) p = edc_swimmerplot(.lookup, id_lim=c(5,45)) p2 = edc_swimmerplot(.lookup, origin=\"db0$date_naissance\", time_unit=\"weeks\",                       exclude=c(\"DB1$DATE2\", \"db3$.*\")) p3 = edc_swimmerplot(.lookup, group=\"db0$group\", aes_color=\"label\") if (FALSE) { #save the plotly plot as HTML to share it htmlwidgets::saveWidget(p, \"edc_swimmerplot.html\", selfcontained=TRUE) }"},{"path":"https://danchaltiel.github.io/EDCimport/reference/extend_lookup.html","id":null,"dir":"Reference","previous_headings":"","what":"Extend the lookup table — extend_lookup","title":"Extend the lookup table — extend_lookup","text":"utility extends lookup table include: n_id number patients present dataset rows_per_id mean number row per patient crfname actual name dataset","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/extend_lookup.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extend the lookup table — extend_lookup","text":"","code":"extend_lookup(   lookup,   ...,   key_columns = get_key_cols(lookup),   datasets = get_datasets(lookup) )"},{"path":"https://danchaltiel.github.io/EDCimport/reference/extend_lookup.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extend the lookup table — extend_lookup","text":"lookup [data.frame(1)] lookup table ... unused key_columns [list(n)] experts datasets [data.frame(n)] experts ","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/extend_lookup.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extend the lookup table — extend_lookup","text":"lookup, extended","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/extend_lookup.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extend the lookup table — extend_lookup","text":"","code":"#tm = read_trialmaster(\"filename.zip\", pw=\"xx\") tm = edc_example_mixed() #> Warning: Option \"edc_lookup\" has been overwritten. load_list(tm) .lookup #> # A tibble: 3 × 5 #>   dataset     nrow  ncol names        labels       #>   <chr>      <dbl> <dbl> <named list> <named list> #> 1 short        100     4 <chr [4]>    <chr [4]>    #> 2 long_mixed   200     5 <chr [5]>    <chr [5]>    #> 3 long_pure    300     4 <chr [4]>    <chr [4]>    .lookup = extend_lookup(.lookup) #> Error in filter(., map_lgl(dataset, ~!inherits(datasets[[.x]], \"error\"))): ℹ In argument: `map_lgl(dataset, ~!inherits(datasets[[.x]], \"error\"))`. #> Caused by error in `map_lgl()`: #> ℹ In index: 1. #> Caused by error in `map()`: #> ℹ In index: 1. #> ℹ With name: short. #> Caused by error in `get()`: #> ! object 'short' not found .lookup #> # A tibble: 3 × 5 #>   dataset     nrow  ncol names        labels       #>   <chr>      <dbl> <dbl> <named list> <named list> #> 1 short        100     4 <chr [4]>    <chr [4]>    #> 2 long_mixed   200     5 <chr [5]>    <chr [5]>    #> 3 long_pure    300     4 <chr [4]>    <chr [4]>"},{"path":"https://danchaltiel.github.io/EDCimport/reference/find_keyword.html","id":null,"dir":"Reference","previous_headings":"","what":"Find a keyword in the whole database — find_keyword","title":"Find a keyword in the whole database — find_keyword","text":"Find keyword names labels list datasets.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/find_keyword.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Find a keyword in the whole database — find_keyword","text":"","code":"find_keyword(keyword, data = getOption(\"edc_lookup\"), ignore_case = TRUE)"},{"path":"https://danchaltiel.github.io/EDCimport/reference/find_keyword.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Find a keyword in the whole database — find_keyword","text":"keyword keyword search . Can handle regular expressions (see examples). data lookup dataframe search keyword. Can set using edc_options(edc_lookup=my_data), done automatically calling read_trialmaster(). ignore_case case differences ignored match? Default TRUE.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/find_keyword.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Find a keyword in the whole database — find_keyword","text":"tibble","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/find_keyword.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Find a keyword in the whole database — find_keyword","text":"","code":"if (FALSE) { path = system.file(\"extdata/Example_Export_SAS_XPORT_2022_08_25_15_16.zip\",                     package=\"EDCimport\", mustWork=TRUE) w = read_trialmaster(path, verbose=FALSE)  find_keyword(\"patient\")  #with regex find_keyword(\"patient$\") find_keyword(\"\\\\d\") find_keyword(\"(Trial|Form) Name\") find_keyword(\"\\\\(\") #you need to escape special characters }"},{"path":"https://danchaltiel.github.io/EDCimport/reference/get_datasets.html","id":null,"dir":"Reference","previous_headings":"","what":"Retrieve the datasets as a list of data.frames — get_datasets","title":"Retrieve the datasets as a list of data.frames — get_datasets","text":"Get datasets lookup table list data.frames.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/get_datasets.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Retrieve the datasets as a list of data.frames — get_datasets","text":"","code":"get_datasets(lookup = getOption(\"edc_lookup\"), envir = parent.frame())"},{"path":"https://danchaltiel.github.io/EDCimport/reference/get_datasets.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Retrieve the datasets as a list of data.frames — get_datasets","text":"lookup lookup table envir (internal use)","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/get_datasets.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Retrieve the datasets as a list of data.frames — get_datasets","text":"list datasets","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/get_key_cols.html","id":null,"dir":"Reference","previous_headings":"","what":"Important column names — get_key_cols","title":"Important column names — get_key_cols","text":"Retrieve names patient_id (usually \"SUBJID\" \"PATNO\") crfname (usually \"CRFNAME\") actual names datasets","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/get_key_cols.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Important column names — get_key_cols","text":"","code":"get_key_cols(lookup = getOption(\"edc_lookup\"))"},{"path":"https://danchaltiel.github.io/EDCimport/reference/get_key_cols.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Important column names — get_key_cols","text":"lookup lookup table","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/get_key_cols.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Important column names — get_key_cols","text":"list(2) characters names patient_id crfname","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/get_lookup.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate a lookup table — get_lookup","title":"Generate a lookup table — get_lookup","text":"Generate lookup table","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/get_lookup.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate a lookup table — get_lookup","text":"","code":"get_lookup(data_list)"},{"path":"https://danchaltiel.github.io/EDCimport/reference/get_lookup.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate a lookup table — get_lookup","text":"data_list list containing least 1 dataframe","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/get_lookup.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate a lookup table — get_lookup","text":"dataframe summarizing column names labels","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/get_lookup.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate a lookup table — get_lookup","text":"","code":"x = edc_example() #> Warning: Option \"edc_lookup\" has been overwritten. x$.lookup=NULL lk = get_lookup(x) lk #> # A tibble: 4 × 5 #>   dataset  nrow  ncol names        labels       #>   <chr>   <dbl> <dbl> <named list> <named list> #> 1 db0        50     5 <chr [5]>    <chr [5]>    #> 2 db2        50     5 <chr [5]>    <chr [5]>    #> 3 db3        50     6 <chr [6]>    <chr [6]>    #> 4 db1       100     6 <chr [6]>    <chr [6]>    lk %>% tidyr::unnest(c(names, labels)) #> # A tibble: 22 × 5 #>    dataset  nrow  ncol names          labels          #>    <chr>   <dbl> <dbl> <chr>          <chr>           #>  1 db0        50     5 SUBJID         Subject ID      #>  2 db0        50     5 age            Age (years)     #>  3 db0        50     5 date_naissance Date of birth   #>  4 db0        50     5 group          Treatment       #>  5 db0        50     5 crfname        Form name       #>  6 db2        50     5 SUBJID         Subject ID      #>  7 db2        50     5 date4          Date at visit 4 #>  8 db2        50     5 date5          Date at visit 5 #>  9 db2        50     5 date6          Date at visit 6 #> 10 db2        50     5 crfname        Form name       #> # ℹ 12 more rows"},{"path":"https://danchaltiel.github.io/EDCimport/reference/load_as_list.html","id":null,"dir":"Reference","previous_headings":"","what":"Load a .RData file as a list — load_as_list","title":"Load a .RData file as a list — load_as_list","text":"Instead loading .RData file global environment, extract every object list.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/load_as_list.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Load a .RData file as a list — load_as_list","text":"","code":"load_as_list(filename)"},{"path":"https://danchaltiel.github.io/EDCimport/reference/load_as_list.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Load a .RData file as a list — load_as_list","text":"filename filename, .RData extension.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/load_as_list.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Load a .RData file as a list — load_as_list","text":"list","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/load_as_list.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Load a .RData file as a list — load_as_list","text":"","code":"x = list(a=1, b=mtcars) save_list(x, \"test.RData\") y = load_as_list(\"test.RData\") print(y$a) #> [1] 1"},{"path":"https://danchaltiel.github.io/EDCimport/reference/load_list.html","id":null,"dir":"Reference","previous_headings":"","what":"Load a list in an environment — load_list","title":"Load a list in an environment — load_list","text":"Load list environment","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/load_list.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Load a list in an environment — load_list","text":"","code":"load_list(x, env = parent.frame(), remove = TRUE)"},{"path":"https://danchaltiel.github.io/EDCimport/reference/load_list.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Load a list in an environment — load_list","text":"x list env environment onto list loaded remove TRUE, x removed environment afterward","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/load_list.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Load a list in an environment — load_list","text":"nothing, called side-effect","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/load_list.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Load a list in an environment — load_list","text":"","code":"x=list(a=1, b=mtcars) load_list(x, remove=FALSE) print(a) #> [1] 1 print(nrow(b)) #> [1] 32"},{"path":"https://danchaltiel.github.io/EDCimport/reference/manual_correction.html","id":null,"dir":"Reference","previous_headings":"","what":"Manual correction — manual_correction","title":"Manual correction — manual_correction","text":"finding wrong unexpected values exported table, can useful temporarily correct hard-coding value. However, manual correction undone soon central database updated correction. manual_correction() applies correction specific table column location throws error correction already place. check applies per R session can source script without errors. reset_manual_correction() resets checks. instance, called read_trialmaster().","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/manual_correction.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Manual correction — manual_correction","text":"","code":"manual_correction(   data,   col,   rows,   wrong,   correct,   verbose = getOption(\"edc_correction_verbose\", TRUE) )  reset_manual_correction()"},{"path":"https://danchaltiel.github.io/EDCimport/reference/manual_correction.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Manual correction — manual_correction","text":"data, col, rows rows column dataframe error lies wrong actual wrong value correct temporary correction value verbose whether print informations ()","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/manual_correction.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Manual correction — manual_correction","text":"Nothing, used side effects","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/manual_correction.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Manual correction — manual_correction","text":"","code":"library(dplyr) #>  #> Attaching package: ‘dplyr’ #> The following objects are masked from ‘package:stats’: #>  #>     filter, lag #> The following objects are masked from ‘package:base’: #>  #>     intersect, setdiff, setequal, union x = iris %>% mutate(id=row_number(), .before=1) %>% as_tibble() x$Sepal.Length[c(1,3,5)] #> [1] 5.1 4.7 5.0  #1st correction is silent manual_correction(x, Sepal.Length, rows=c(1,3,5),                   wrong=c(5.1, 4.7, 5.0), correct=c(5, 4, 3)) #> Manual correction of \"x$Sepal.Length\": #> ℹ Old: 5.1, 4.7, and 5 #> ℹ New: 5, 4, and 3 x$Sepal.Length[c(1,3,5)] #> [1] 5 4 3  #further correction is silent manual_correction(x, Sepal.Length, rows=c(1,3,5),                   wrong=c(5.1, 4.7, 5.0), correct=c(5, 4, 3))                     #if the database is corrected, an error is thrown if (FALSE) { reset_manual_correction() x$Sepal.Length[c(1,3,5)] = c(5, 4, 3) #mimics db correction manual_correction(x, Sepal.Length, rows=c(1,3,5),                   wrong=c(5.1, 4.7, 5.0), correct=c(5, 4, 3)) }"},{"path":"https://danchaltiel.github.io/EDCimport/reference/read_tm_all_xpt.html","id":null,"dir":"Reference","previous_headings":"","what":"Read all .xpt files in a directory — read_tm_all_xpt","title":"Read all .xpt files in a directory — read_tm_all_xpt","text":"Read .xpt files directory (unzipped TrialMaster archive).  7zip installed, probably rather use read_trialmaster() instead.  procformat.sas file exists directory, formats applied.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/read_tm_all_xpt.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Read all .xpt files in a directory — read_tm_all_xpt","text":"","code":"read_tm_all_xpt(   directory,   ...,   format_file = \"procformat.sas\",   clean_names_fun = NULL,   split_mixed = FALSE,   extend_lookup = TRUE,   datetime_extraction = NULL,   verbose = getOption(\"edc_read_verbose\", 1),   key_columns = \"deprecated\" )"},{"path":"https://danchaltiel.github.io/EDCimport/reference/read_tm_all_xpt.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Read all .xpt files in a directory — read_tm_all_xpt","text":"directory [character(1)] path unzipped archive using SAS_XPORT format. read extraction date directory name. ... unused format_file [character(1)] path procformat.sas file used apply formats. Use NULL apply formats. clean_names_fun [function] function clean column names, e.g. tolower, janitor::clean_names(),... split_mixed [logical(1): FALSE] whether split mixed datasets. See split_mixed_datasets. extend_lookup [character(1): FALSE] whether enrich lookup table. See extend_lookup. datetime_extraction [POSIXt(1)] datetime data extraction. Default common date last modification directory. verbose [logical(1)] one c(0, 1, 2). higher, information printed. key_columns deprecated","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/read_tm_all_xpt.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Read all .xpt files in a directory — read_tm_all_xpt","text":"list containing one dataframe .xpt file folder, extraction date (datetime_extraction), summary imported tables (.lookup). set yet, option edc_lookup automatically set .lookup.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/read_trialmaster.html","id":null,"dir":"Reference","previous_headings":"","what":"Read the .zip archive of a TrialMaster export — read_trialmaster","title":"Read the .zip archive of a TrialMaster export — read_trialmaster","text":"Import .zip archive TrialMaster trial export list dataframes. archive filename leaved untouched contains project name date extraction.  Generate .rds cache file future reads.  7zip installed available, use read_tm_all_xpt() instead.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/read_trialmaster.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Read the .zip archive of a TrialMaster export — read_trialmaster","text":"","code":"read_trialmaster(   archive,   ...,   use_cache = \"write\",   clean_names_fun = NULL,   split_mixed = FALSE,   extend_lookup = TRUE,   pw = getOption(\"trialmaster_pw\"),   verbose = getOption(\"edc_read_verbose\", 1),   key_columns = \"deprecated\" )"},{"path":"https://danchaltiel.github.io/EDCimport/reference/read_trialmaster.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Read the .zip archive of a TrialMaster export — read_trialmaster","text":"archive [character(1)] path archive ... unused use_cache [mixed(1): \"write\"] controls .rds cache. TRUE, read cache extract archive create cache. FALSE extract archive without creating cache file. Can also \"read\" \"write\". clean_names_fun [function] function clean column names, e.g. tolower, janitor::clean_names(),... split_mixed [logical(1): FALSE] whether split mixed datasets. See split_mixed_datasets. extend_lookup [character(1): FALSE] whether enrich lookup table. See extend_lookup. pw [character(1)] password archive protected. avoid writing passwords plain text, probably better use options(trialmaster_pw=\"xxx\") instead though. verbose [logical(1)] one c(0, 1, 2). higher, information printed. key_columns deprecated","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/read_trialmaster.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Read the .zip archive of a TrialMaster export — read_trialmaster","text":"list containing one dataframe .xpt file folder, extraction date (datetime_extraction), summary imported tables (.lookup). set yet, option edc_lookup automatically set .lookup.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/reexports.html","id":null,"dir":"Reference","previous_headings":"","what":"Objects exported from other packages — reexports","title":"Objects exported from other packages — reexports","text":"objects imported packages. Follow links see documentation. dplyr %>%, %>% tibble tibble","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/save_list.html","id":null,"dir":"Reference","previous_headings":"","what":"Save a list as .RData file — save_list","title":"Save a list as .RData file — save_list","text":"Save list .RData file","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/save_list.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Save a list as .RData file — save_list","text":"","code":"save_list(x, filename)"},{"path":"https://danchaltiel.github.io/EDCimport/reference/save_list.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Save a list as .RData file — save_list","text":"x list filename filename, .RData extension.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/save_list.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Save a list as .RData file — save_list","text":"nothing, called side-effect","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/save_list.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Save a list as .RData file — save_list","text":"","code":"x=list(a=1, b=mtcars) save_list(x, \"test.RData\") load(\"test.RData\") file.remove(\"test.RData\") #> [1] TRUE print(a) #> [1] 1 print(nrow(b)) #> [1] 32"},{"path":"https://danchaltiel.github.io/EDCimport/reference/split_mixed_datasets.html","id":null,"dir":"Reference","previous_headings":"","what":"Split mixed datasets — split_mixed_datasets","title":"Split mixed datasets — split_mixed_datasets","text":"Split mixed tables, .e. tables hold long data (N values per patient) short data (one value per patient, duplicated N lines), one long table one short table.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/split_mixed_datasets.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Split mixed datasets — split_mixed_datasets","text":"","code":"split_mixed_datasets(   datasets = get_datasets(),   id = get_key_cols()$patient_id,   ...,   ignore_cols = getOption(\"edc_cols_crfname\", \"CRFNAME\"),   output_code = FALSE,   verbose = TRUE )"},{"path":"https://danchaltiel.github.io/EDCimport/reference/split_mixed_datasets.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Split mixed datasets — split_mixed_datasets","text":"datasets dataframe list dataframes split. Default datasets .lookup. id patient identifier, probably \"SUBJID\". shared datasets. Case-insensitive. ... used ignore_cols columns ignore considering table long. Default getOption(\"edc_cols_crfname\", \"CRFNAME\"). Case-insensitive. output_code whether print code explicitly write. Can also file path. verbose whether print informations process.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/split_mixed_datasets.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Split mixed datasets — split_mixed_datasets","text":"list new long short tables. Use load_list() load global environment.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/split_mixed_datasets.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Split mixed datasets — split_mixed_datasets","text":"","code":"#tm = read_trialmaster(\"filename.zip\", pw=\"xx\") tm = edc_example_mixed() #> Warning: Option \"edc_lookup\" has been overwritten. names(tm) #> [1] \"short\"               \"long_pure\"           \"long_mixed\"          #> [4] \"date_extraction\"     \"datetime_extraction\" \".lookup\"             #load_list(tm) print(tm$long_mixed) #`val1` and `val2` are long but `val3` is short #> # A tibble: 200 × 5 #>    SUBJID crfname       val1  val2 val3  #>     <int> <chr>        <dbl> <dbl> <chr> #>  1      1 long_mixed  0.877  10.0  B     #>  2      1 long_mixed -1.77   11.9  B     #>  3      2 long_mixed -0.0457 10.8  C     #>  4      2 long_mixed -0.395   9.81 C     #>  5      3 long_mixed -0.128  10.5  D     #>  6      3 long_mixed  1.10   11.8  D     #>  7      4 long_mixed -1.26   10.2  E     #>  8      4 long_mixed -0.265   9.43 E     #>  9      5 long_mixed  2.55   11.5  F     #> 10      5 long_mixed -1.48   11.9  F     #> # ℹ 190 more rows  mixed_data = split_mixed_datasets(tm, id=\"subjid\", verbose=TRUE) #> ✔ There was 1 short table: #>   \"short\" #> ✔ There was 1 pure long table: #>   \"long_pure\" #> ✔ There was 1 mixed (short+long) table: #>   \"long_mixed\" #> → Use `EDCimport::load_list()` on the result to get separated long and short #>   data. load_list(mixed_data) print(long_mixed_short)  #> # A tibble: 100 × 3 #>    SUBJID crfname    val3  #>     <int> <chr>      <chr> #>  1      1 long_mixed B     #>  2      2 long_mixed C     #>  3      3 long_mixed D     #>  4      4 long_mixed E     #>  5      5 long_mixed F     #>  6      6 long_mixed G     #>  7      7 long_mixed H     #>  8      8 long_mixed I     #>  9      9 long_mixed J     #> 10     10 long_mixed K     #> # ℹ 90 more rows print(long_mixed_long)  #> # A tibble: 200 × 3 #>    SUBJID    val1  val2 #>     <int>   <dbl> <dbl> #>  1      1  0.877  10.0  #>  2      1 -1.77   11.9  #>  3      2 -0.0457 10.8  #>  4      2 -0.395   9.81 #>  5      3 -0.128  10.5  #>  6      3  1.10   11.8  #>  7      4 -1.26   10.2  #>  8      4 -0.265   9.43 #>  9      5  2.55   11.5  #> 10      5 -1.48   11.9  #> # ℹ 190 more rows  #alternatively, get the code and only use the datasets you need split_mixed_datasets(tm, id=\"SUBJID\", output_code=TRUE) #> ✔ There was 1 short table: #>   \"short\" #> ✔ There was 1 pure long table: #>   \"long_pure\" #> ✔ There was 1 mixed (short+long) table: #>   \"long_mixed\" #> → Copy the following code in your script to separate long and short data: #> ## `long_mixed` (dim=200x5) ----  #>  #> long_mixed_short = long_mixed %>%  #>   select(SUBJID, crfname, val3) %>%  #>   group_by(SUBJID) %>%  #>   summarise(across(everything(), unify)) #dim=100x3  #>  #>  long_mixed_long = long_mixed %>%  #>   select(SUBJID, val1, val2) #dim=200x3  filename = tempfile(\"mixed_code\", fileext=\".R\") split_mixed_datasets(tm, id=\"SUBJID\", output_code=filename) #> ✔ There was 1 short table: #>   \"short\" #> ✔ There was 1 pure long table: #>   \"long_pure\" #> ✔ There was 1 mixed (short+long) table: #>   \"long_mixed\" #> → Copy the code from /tmp/Rtmpr9Jo6G/mixed_code17f54818f975.R in your script to #>   separate long and short data: #>   `utils::browseURL(/tmp/Rtmpr9Jo6G/mixed_code17f54818f975.R)` readLines(filename) #> [1] \"## `long_mixed` (dim=200x5) ---- \"                    #> [2] \"\"                                                     #> [3] \"long_mixed_short = long_mixed %>% \"                   #> [4] \"  select(SUBJID, crfname, val3) %>% \"                 #> [5] \"  group_by(SUBJID) %>% \"                              #> [6] \"  summarise(across(everything(), unify)) #dim=100x3 \" #> [7] \"\"                                                     #> [8] \" long_mixed_long = long_mixed %>% \"                   #> [9] \"  select(SUBJID, val1, val2) #dim=200x3 \""},{"path":"https://danchaltiel.github.io/EDCimport/reference/unify.html","id":null,"dir":"Reference","previous_headings":"","what":"Unify a vector — unify","title":"Unify a vector — unify","text":"Turn vector length N vector length 1 checking one unique value. Useful safely flatten duplicated table. preserves label attribute set.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/unify.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Unify a vector — unify","text":"","code":"unify(x)"},{"path":"https://danchaltiel.github.io/EDCimport/reference/unify.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Unify a vector — unify","text":"x vector","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/unify.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Unify a vector — unify","text":"vector length 1","code":""},{"path":"https://danchaltiel.github.io/EDCimport/reference/unify.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Unify a vector — unify","text":"","code":"unify(c(1,1,1,1)) #> [1] 1 #unify(c(1,1,2,1)) #warning  library(dplyr) x=tibble(id=rep(letters[1:5],10), value=rep(1:5,10)) x %>% group_by(id) %>% summarise(value=unify(value)) #safer than `value=value[1]` #> # A tibble: 5 × 2 #>   id    value #>   <chr> <int> #> 1 a         1 #> 2 b         2 #> 3 c         3 #> 4 d         4 #> 5 e         5 x$value[2]=1 #x %>% group_by(id) %>% summarise(value=unify(value)) #warning about that non-unique value"},{"path":"https://danchaltiel.github.io/EDCimport/news/index.html","id":"edcimport-041","dir":"Changelog","previous_headings":"","what":"EDCimport 0.4.1","title":"EDCimport 0.4.1","text":"CRAN release: 2023-12-19","code":""},{"path":"https://danchaltiel.github.io/EDCimport/news/index.html","id":"bug-fixes--improvements-0-4-1","dir":"Changelog","previous_headings":"","what":"Bug fixes & Improvements","title":"EDCimport 0.4.1","text":"Changes testing environment package can installed CRAN despite firewall policies forbidding password-protected archive downloading. Fixed bug corrupted XPT file can prevent whole import fail.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/news/index.html","id":"edcimport-040","dir":"Changelog","previous_headings":"","what":"EDCimport 0.4.0","title":"EDCimport 0.4.0","text":"CRAN release: 2023-12-11","code":""},{"path":"https://danchaltiel.github.io/EDCimport/news/index.html","id":"new-features-0-4-0","dir":"Changelog","previous_headings":"","what":"New features","title":"EDCimport 0.4.0","text":"New function check_subjid() check vector missing patients (#8). New function assert_no_duplicate() abort table duplicates subject ID column(#9). New function manual_correction() safely hard-code correction waiting TrialMaster database updated. New function edc_options() manage EDCimport global parameterization. New argument edc_swimmerplot(id_lim) subset swimmer plot patients . New option read_trialmaster(use_cache=\"write\") read zip still update cache. can now use syntax read_trialmaster(split_mixed=c(\"col1\", \"col2\")) split datasets need (#10).","code":"options(edc_subjid_ref=enrolres$subjid) check_subjid(treatment$subjid) check_subjid(ae$subjid) tibble(subjid=c(1:10, 1)) %>% assert_no_duplicate() %>% nrow() #Error in `assert_no_duplicate()`: #! Duplicate on column \"subjid\" for value 1."},{"path":"https://danchaltiel.github.io/EDCimport/news/index.html","id":"bug-fixes--improvements-0-4-0","dir":"Changelog","previous_headings":"","what":"Bug fixes & Improvements","title":"EDCimport 0.4.0","text":"Reading read_trialmaster() cache output error parameters (split_mixed, clean_names_fun) different (#4). split_mixed_datasets() now fully case-insensitive. Non-UTF8 characters labels now identified corrected reading (#5).","code":""},{"path":"https://danchaltiel.github.io/EDCimport/news/index.html","id":"minor-breaking-changes-0-4-0","dir":"Changelog","previous_headings":"","what":"Minor breaking changes","title":"EDCimport 0.4.0","text":"read_trialmaster(use_cache=\"write\") now default. Reading cache stable yet, opt-rather opt-. read_trialmaster(extend_lookup=TRUE) now default. Options edc_id, edc_crfname, edc_verbose respectively renamed edc_cols_id, edc_cols_crfname, edc_read_verbose clarity.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/news/index.html","id":"edcimport-030-20230519","dir":"Changelog","previous_headings":"","what":"EDCimport 0.3.0 2023/05/19","title":"EDCimport 0.3.0 2023/05/19","text":"CRAN release: 2023-05-19","code":""},{"path":"https://danchaltiel.github.io/EDCimport/news/index.html","id":"new-features-0-3-0","dir":"Changelog","previous_headings":"","what":"New features","title":"EDCimport 0.3.0 2023/05/19","text":"New function edc_swimmerplot() show swimmer plot dates database easily find outliers. New features read_trialmaster(): clean_names_fun=some_fun clean names tables. instance, clean_names_fun=janitor::clean_names() turn default SAS uppercase column names valid R snake-case column names. split_mixed=TRUE split tables contain long short data regarding patient ID one long table one short table. See ?split_mixed_datasets() details. extend_lookup=TRUE improve lookup table additional information. See ?extend_lookup() details. key_columns=get_key_cols() can change default column names patient ID CRF name (used new features). Standalone functions extend_lookup() split_mixed_datasets(). New helper unify(), turns vector duplicate values vector length 1.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/news/index.html","id":"bug-fixes-0-3-0","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"EDCimport 0.3.0 2023/05/19","text":"Reading errors now handled read_trialmaster() instead failing. one XPT file corrupted, resulting object contain error message instead dataset. find_keyword() now robust non-UTF8 characters labels. Option edc_lookup now set even reading cache. SAS formats containing = now work intended.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/news/index.html","id":"edcimport-021-20221101","dir":"Changelog","previous_headings":"","what":"EDCimport 0.2.1 2022/11/01","title":"EDCimport 0.2.1 2022/11/01","text":"CRAN release: 2022-12-02 Import data TrialMaster using tm = read_trialmaster(\"path//archive.zip\"). Search keyword column name label using find_keyword(\"date\", data=tm$.lookup). can also generate lookup table arbitrary list dataframe using get_lookup(my_data). Load datasets global environment using load_list(tm) avoid typing tm$ everywhere. Browse available global options using ?EDCimport_options.","code":""},{"path":"https://danchaltiel.github.io/EDCimport/news/index.html","id":"edcimport-010","dir":"Changelog","previous_headings":"","what":"EDCimport 0.1.0","title":"EDCimport 0.1.0","text":"Draft version","code":""}]
